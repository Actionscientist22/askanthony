WEBVTT

1
00:00:05.000 --> 00:00:09.980
Anthony Taylor: Alright. Welcome back to Nlp day 3.

2
00:00:14.650 --> 00:00:15.720
Anthony Taylor: Hi! Gang!

3
00:00:18.650 --> 00:00:19.680
Anthony Taylor: I know

4
00:00:21.040 --> 00:00:22.140
Anthony Taylor: what is today.

5
00:00:22.150 --> 00:00:24.700
Anthony Taylor: Monday. I know. Thursday was tough.

6
00:00:25.650 --> 00:00:27.640
Anthony Taylor: Okay. Where's Clayton?

7
00:00:27.940 --> 00:00:30.339
Anthony Taylor: Oh, are they still in a room?

8
00:00:31.970 --> 00:00:34.789
Anthony Taylor: Come on, guys, class starts get out of the

9
00:00:45.040 --> 00:00:45.860
Anthony Taylor: okay.

10
00:00:53.040 --> 00:00:55.250
Anthony Taylor: Welcome back

11
00:00:56.180 --> 00:00:57.100
Anthony Taylor: alright.

12
00:00:57.210 --> 00:00:58.740
Anthony Taylor: So I I know.

13
00:01:02.500 --> 00:01:06.529
Anthony Taylor: I know Thursday was tough. What? What's wrong? Clean.

14
00:01:09.770 --> 00:01:10.300
Clayton Graves: Right.

15
00:01:10.300 --> 00:01:11.100
Anthony Taylor: Still talk.

16
00:01:11.290 --> 00:01:16.989
Clayton Graves: Yeah, my yeah, I I've had both the guys looking at it. They're not seeing anything wrong. But my

17
00:01:17.960 --> 00:01:20.359
Clayton Graves: attrition accuracy is terrible.

18
00:01:20.770 --> 00:01:22.410
Clayton Graves: absolutely awesome.

19
00:01:22.440 --> 00:01:24.439
Clayton Graves: and I can't figure out why.

20
00:01:25.690 --> 00:01:26.050
Anthony Taylor: Okay.

21
00:01:26.050 --> 00:01:28.088
michael mcpherson: Alright. Well, we can look at it.

22
00:01:29.060 --> 00:01:31.979
michael mcpherson: Check to see if you're feeding your department.

23
00:01:33.350 --> 00:01:35.970
michael mcpherson: data frame into your attrition model.

24
00:01:38.560 --> 00:01:39.080
Clayton Graves: Definitely.

25
00:01:39.080 --> 00:01:40.099
Anthony Taylor: Do what makes it.

26
00:01:40.240 --> 00:01:41.270
Clayton Graves: Definitely, not.

27
00:01:41.790 --> 00:01:44.969
michael mcpherson: Cause that had me had me locked up for like

28
00:01:45.110 --> 00:01:46.500
michael mcpherson: 5 h.

29
00:01:51.330 --> 00:01:56.830
Clayton Graves: Yeah, I've I've had 2 very much smarter than me, gentlemen, looking over my code for

30
00:01:56.980 --> 00:01:58.110
Clayton Graves: the last 25 min.

31
00:01:58.430 --> 00:02:01.060
Anthony Taylor: Where did you find 2 people smarter than you, Clayton?

32
00:02:02.340 --> 00:02:03.590
Anthony Taylor: Oh, oh.

33
00:02:03.590 --> 00:02:04.600
Clayton Graves: You're in this class.

34
00:02:04.600 --> 00:02:06.109
Anthony Taylor: Nice. Oh, okay.

35
00:02:08.591 --> 00:02:11.350
Anthony Taylor: okay, alright. Let's move forward.

36
00:02:11.901 --> 00:02:14.290
Anthony Taylor: We'll talk. We can talk more after

37
00:02:16.460 --> 00:02:20.220
Anthony Taylor: Alright. So Thursday was pretty crazy. Today's a little crazier

38
00:02:20.705 --> 00:02:24.350
Anthony Taylor: but not harder. It's just some pretty deep concepts.

39
00:02:26.030 --> 00:02:33.649
Anthony Taylor: we're gonna get. We're gonna so like, we've really been like hands in there building stuff. Today's a little less of that.

40
00:02:33.690 --> 00:02:35.079
Anthony Taylor: It's more.

41
00:02:35.990 --> 00:02:37.000
Anthony Taylor: Just trust me.

42
00:02:37.990 --> 00:02:39.690
Anthony Taylor: But it's gonna be fun.

43
00:02:40.010 --> 00:02:40.710
Anthony Taylor: Okay.

44
00:02:40.880 --> 00:02:45.739
Anthony Taylor: So we're gonna do some Nlp pre processing to large Kobara

45
00:02:45.920 --> 00:02:46.980
Anthony Taylor: or up

46
00:02:47.560 --> 00:02:49.099
Anthony Taylor: corpus I

47
00:02:49.660 --> 00:02:50.800
Anthony Taylor: of text.

48
00:02:51.320 --> 00:02:54.960
Anthony Taylor: Alright, we're going to demonstrate how to classify text into topics

49
00:02:55.020 --> 00:02:57.109
Anthony Taylor: using. Get this

50
00:02:57.150 --> 00:02:59.980
Anthony Taylor: unsupervised learning

51
00:03:00.620 --> 00:03:02.700
Anthony Taylor: for Nlp, that's kind of interesting

52
00:03:03.669 --> 00:03:08.699
Anthony Taylor: understand? Demonstrating how to use Lstm Rn. In. So we've done an A in.

53
00:03:08.730 --> 00:03:10.970
Anthony Taylor: we've done Cnn.

54
00:03:13.160 --> 00:03:16.469
Anthony Taylor: R. And N. Is not Republican news network.

55
00:03:17.780 --> 00:03:18.950
Anthony Taylor: Okay.

56
00:03:19.000 --> 00:03:21.120
Anthony Taylor: just not. It's recursing.

57
00:03:22.050 --> 00:03:25.300
Anthony Taylor: Alright, and it's intense.

58
00:03:25.720 --> 00:03:29.630
Anthony Taylor: Okay, but we're gonna talk about all of it. It's gonna be very exciting.

59
00:03:31.240 --> 00:03:32.520
Anthony Taylor: So

60
00:03:35.640 --> 00:03:36.640
Anthony Taylor: here we go?

61
00:03:41.040 --> 00:03:46.239
Anthony Taylor: and and yes, I am going to refer to my notes a lot on this one I have not.

62
00:03:47.700 --> 00:03:49.090
Anthony Taylor: and, I repeat.

63
00:03:49.220 --> 00:03:50.749
Anthony Taylor: I have not

64
00:03:51.120 --> 00:03:52.640
Anthony Taylor: used this month.

65
00:03:53.490 --> 00:03:58.910
Anthony Taylor: Alright. And this goes back to what I told you guys before. You're gonna learn all these models.

66
00:03:59.400 --> 00:04:01.270
Anthony Taylor: You may or may not ever use

67
00:04:01.370 --> 00:04:02.480
Anthony Taylor: very many of them

68
00:04:02.540 --> 00:04:03.750
Anthony Taylor: depends on

69
00:04:04.090 --> 00:04:10.509
Anthony Taylor: your work. I have not had a need for this, but it's still pre gangful and conceptually

70
00:04:11.150 --> 00:04:12.160
Anthony Taylor: like everything.

71
00:04:12.300 --> 00:04:17.679
Anthony Taylor: Alright. So imagine if you had a large database

72
00:04:17.910 --> 00:04:19.509
Anthony Taylor: of news articles.

73
00:04:20.680 --> 00:04:25.789
Anthony Taylor: Okay, just huge. Just the Huffington Post, the New York Times.

74
00:04:26.620 --> 00:04:27.710
Anthony Taylor: Okay.

75
00:04:28.040 --> 00:04:29.080
Anthony Taylor: News articles.

76
00:04:29.480 --> 00:04:33.329
Anthony Taylor: And you needed to classify them or label them.

77
00:04:34.860 --> 00:04:35.969
Anthony Taylor: How would you do it?

78
00:04:38.570 --> 00:04:40.910
Anthony Taylor: Go to each one, look at it

79
00:04:41.440 --> 00:04:42.200
Anthony Taylor: later.

80
00:04:43.040 --> 00:04:44.769
Anthony Taylor: but there's a million of them.

81
00:04:46.040 --> 00:04:51.709
Anthony Taylor: We don't want to do that by hand, plus that leaves it up to

82
00:04:51.750 --> 00:04:53.289
Anthony Taylor: people's, you know.

83
00:04:53.600 --> 00:04:55.040
Anthony Taylor: Interpretation?

84
00:04:56.260 --> 00:05:00.260
Anthony Taylor: Right? Maybe somebody would read one article, go? Well, that's entertainment.

85
00:05:01.220 --> 00:05:04.580
Anthony Taylor: Okay, what's the what's that thing that happened today. Bo Diddy.

86
00:05:05.080 --> 00:05:06.249
Anthony Taylor: what's his name?

87
00:05:06.820 --> 00:05:07.850
Anthony Taylor: P. Diddy?

88
00:05:09.920 --> 00:05:11.720
Anthony Taylor: Has anybody been reading the news?

89
00:05:12.120 --> 00:05:16.380
Anthony Taylor: I don't know what the hell is. All I know is is, he's get busted for some.

90
00:05:16.720 --> 00:05:21.659
Anthony Taylor: I'm not sure what. Don't know. If he did, it doesn't matter. Is it entertainment, or is it crime?

91
00:05:23.160 --> 00:05:26.989
Anthony Taylor: Right? So which news story? Which? Where does it go? Where does it fit?

92
00:05:27.810 --> 00:05:29.430
Anthony Taylor: Okay, so

93
00:05:30.050 --> 00:05:32.229
Anthony Taylor: we need to come up with a

94
00:05:33.010 --> 00:05:37.060
Anthony Taylor: more quantitative way to label.

95
00:05:38.340 --> 00:05:39.730
Anthony Taylor: Pretty exciting stuff.

96
00:05:41.302 --> 00:05:43.229
Anthony Taylor: So, topic modeling.

97
00:05:43.380 --> 00:05:51.979
Anthony Taylor: it's used to identify and cut meaningful topics and themes from large values of text. This is the key without prior knowledge.

98
00:05:53.870 --> 00:06:02.159
Anthony Taylor: It's unsupervised. We're not going to label this. We're going to generate our labels just like we did with unsupervised stuff before.

99
00:06:02.400 --> 00:06:06.430
Anthony Taylor: So this is latent. Like, thank you for the phonetic

100
00:06:06.850 --> 00:06:09.949
Anthony Taylor: Jewish lay slay!

101
00:06:10.690 --> 00:06:12.860
Anthony Taylor: Don't tell me, is Reuters, brother.

102
00:06:13.500 --> 00:06:15.269
Anthony Taylor: it's not Derislet.

103
00:06:15.880 --> 00:06:17.429
Anthony Taylor: It's the rich land.

104
00:06:17.750 --> 00:06:20.680
Anthony Taylor: dearie dude, dear, rich man.

105
00:06:20.960 --> 00:06:22.020
Anthony Taylor: allocation!

106
00:06:22.170 --> 00:06:23.729
Anthony Taylor: There is shared

107
00:06:23.990 --> 00:06:25.410
Anthony Taylor: Derisley.

108
00:06:27.240 --> 00:06:28.010
Anthony Taylor: Never mind.

109
00:06:28.493 --> 00:06:32.329
Anthony Taylor: It's used to identify topics within a collection of documents.

110
00:06:32.860 --> 00:06:33.860
Anthony Taylor: Okay?

111
00:06:35.310 --> 00:06:36.580
Anthony Taylor: basically

112
00:06:36.830 --> 00:06:39.490
Anthony Taylor: in a nutshell. Let's see, do we have a picture?

113
00:06:40.230 --> 00:06:42.190
Anthony Taylor: We kind of do, I'll let it. I'll let it keep

114
00:06:44.190 --> 00:06:49.290
Anthony Taylor: So we're gonna use this Lda, that's what we'll call it for short instead of devices.

115
00:06:50.795 --> 00:06:52.520
Anthony Taylor: For each document.

116
00:06:52.670 --> 00:06:58.039
Anthony Taylor: What's the probability of what topic it belongs to? Now keep in mind.

117
00:06:58.070 --> 00:07:00.009
Anthony Taylor: it doesn't know what the topics are.

118
00:07:01.750 --> 00:07:06.890
Anthony Taylor: Okay. So each topic, what's probably each word being associated with that top.

119
00:07:07.090 --> 00:07:09.300
Anthony Taylor: So for instance, if we have

120
00:07:09.410 --> 00:07:13.520
Anthony Taylor: these 10 documents and they're just the headlines.

121
00:07:14.250 --> 00:07:15.290
Anthony Taylor: Okay.

122
00:07:17.480 --> 00:07:18.890
Anthony Taylor: how would

123
00:07:19.940 --> 00:07:22.989
Anthony Taylor: we like, classify. What's this first one? What do you guys think.

124
00:07:25.280 --> 00:07:25.980
Clayton Graves: Porch.

125
00:07:26.650 --> 00:07:28.609
Anthony Taylor: That looks like sports to me.

126
00:07:30.900 --> 00:07:32.969
Anthony Taylor: but there's a word surgery in it.

127
00:07:32.980 --> 00:07:34.360
Anthony Taylor: and injury.

128
00:07:35.800 --> 00:07:37.139
Anthony Taylor: Could it be medical.

129
00:07:38.190 --> 00:07:42.730
Masarirambi, Rodney: Yeah, you could. I mean, you can put into multiple class patients just cause

130
00:07:43.120 --> 00:07:48.120
Masarirambi, Rodney: cause somebody might be looking for it in the medical like search term. So I'd say that

131
00:07:48.170 --> 00:07:51.260
Masarirambi, Rodney: medical and sports would would would be it.

132
00:07:52.260 --> 00:07:54.290
Anthony Taylor: Not a bad choice. What about the next one.

133
00:07:56.510 --> 00:07:57.390
Clayton Graves: Throttle.

134
00:07:59.510 --> 00:08:02.780
Anthony Taylor: What was that travel? Maybe that's not bad.

135
00:08:06.110 --> 00:08:06.450
Clayton Graves: But.

136
00:08:07.270 --> 00:08:08.750
michael mcpherson: Part of the logistics.

137
00:08:10.270 --> 00:08:11.086
Anthony Taylor: Yeah, it could be.

138
00:08:11.290 --> 00:08:11.660
Masarirambi, Rodney: Yeah, yeah.

139
00:08:11.660 --> 00:08:12.930
Anthony Taylor: Logistics

140
00:08:13.683 --> 00:08:14.910
Anthony Taylor: could be.

141
00:08:15.140 --> 00:08:18.170
Anthony Taylor: I mean, is this really any business news?

142
00:08:19.800 --> 00:08:24.280
Anthony Taylor: I don't know. This is even like like serious news. Maybe this is just like.

143
00:08:24.830 --> 00:08:25.860
Anthony Taylor: you know.

144
00:08:26.080 --> 00:08:28.410
Anthony Taylor: pillar, I don't know could be something.

145
00:08:29.080 --> 00:08:31.199
Anthony Taylor: Oh, there you go! This is a good one.

146
00:08:31.300 --> 00:08:33.299
Anthony Taylor: definitely culinary

147
00:08:35.250 --> 00:08:36.480
Anthony Taylor: cultural.

148
00:08:39.080 --> 00:08:40.570
Anthony Taylor: is it Italian?

149
00:08:41.429 --> 00:08:42.400
Anthony Taylor: I don't know.

150
00:08:44.000 --> 00:08:45.800
Mason, Natalie: It's fusion.

151
00:08:46.840 --> 00:08:48.229
Anthony Taylor: Fusion. There you go.

152
00:08:49.360 --> 00:08:56.430
Anthony Taylor: We won't do all these. But let's see, how about this one? Inside the remarkably intricate planning for Biden's meeting with Z.

153
00:08:58.750 --> 00:09:00.000
Anthony Taylor: Politics.

154
00:09:00.670 --> 00:09:02.270
Anthony Taylor: foreign Affairs

155
00:09:04.790 --> 00:09:06.830
Anthony Taylor: logistically expect what? Mike said.

156
00:09:07.970 --> 00:09:10.849
Anthony Taylor: Alright, let's pick something else. One more, and then we'll stop.

157
00:09:11.100 --> 00:09:17.109
Anthony Taylor: Escape the crowds at these affordable alternatives to travel. Hotspots go, clay.

158
00:09:18.800 --> 00:09:19.800
Anthony Taylor: We're Clayton.

159
00:09:20.500 --> 00:09:22.599
Anthony Taylor: There you travel again right?

160
00:09:23.670 --> 00:09:25.050
Anthony Taylor: Definitely. Trap

161
00:09:25.380 --> 00:09:27.360
Anthony Taylor: money could be money.

162
00:09:29.400 --> 00:09:34.879
Anthony Taylor: Alright, alright! So we kind of get it right just in this room. You know.

163
00:09:35.170 --> 00:09:36.660
Anthony Taylor: 19 people.

164
00:09:37.070 --> 00:09:43.679
Anthony Taylor: we came up with different classifications. By reading, our goal is is to fix that. So I mean, multiply this by.

165
00:09:43.940 --> 00:09:46.219
Anthony Taylor: you know, 50,000

166
00:09:46.940 --> 00:09:48.120
Anthony Taylor: titles.

167
00:09:48.370 --> 00:09:52.339
Anthony Taylor: and I mean, imagine the mess we would have if we all went, did it ourselves.

168
00:09:52.670 --> 00:09:54.629
Anthony Taylor: So our goal is to fix that.

169
00:09:54.650 --> 00:09:58.510
Anthony Taylor: So what do we do? Well, first, we gotta prep our test. So

170
00:09:58.530 --> 00:10:04.940
Anthony Taylor: what we're gonna do is basically take all the the, not the document word, but everything on the right side.

171
00:10:05.150 --> 00:10:06.719
Anthony Taylor: We're going to

172
00:10:07.330 --> 00:10:10.620
Anthony Taylor: get rid of anything except

173
00:10:11.020 --> 00:10:12.810
Anthony Taylor: letters and spaces.

174
00:10:14.560 --> 00:10:17.129
Anthony Taylor: That's what this is. And then we're gonna make it all over.

175
00:10:17.900 --> 00:10:18.660
Anthony Taylor: Okay.

176
00:10:19.740 --> 00:10:21.789
Anthony Taylor: then we're gonna loop through

177
00:10:22.200 --> 00:10:26.959
Anthony Taylor: all of those documents and apply this function to the text.

178
00:10:27.580 --> 00:10:32.170
Anthony Taylor: That's pretty straightforward. Yeah, don't worry. You guys. We're gonna do this in the solution, too.

179
00:10:33.130 --> 00:10:33.980
Anthony Taylor: can.

180
00:10:34.190 --> 00:10:35.990
Anthony Taylor: So now we end up with this.

181
00:10:36.280 --> 00:10:37.839
Anthony Taylor: A single list.

182
00:10:39.220 --> 00:10:43.239
Anthony Taylor: with all, each line is basically

183
00:10:43.600 --> 00:10:45.100
Anthony Taylor: clean. You know what?

184
00:10:49.640 --> 00:10:51.160
Anthony Taylor: That's so weird. Look at it.

185
00:10:53.070 --> 00:10:55.530
Anthony Taylor: Those are lower case. Believe it or not.

186
00:10:55.530 --> 00:10:56.429
Baro, Sonja: Supposed to be.

187
00:10:56.430 --> 00:10:57.290
Anthony Taylor: Just like

188
00:10:57.550 --> 00:10:58.980
Anthony Taylor: they're like odd.

189
00:10:59.260 --> 00:11:00.099
Anthony Taylor: but they are.

190
00:11:00.100 --> 00:11:01.460
Baro, Sonja: Day is not.

191
00:11:02.720 --> 00:11:03.750
Anthony Taylor: That's true.

192
00:11:04.000 --> 00:11:04.390
Baro, Sonja: G-.

193
00:11:04.390 --> 00:11:06.609
Anthony Taylor: Yeah, looks like someone tried to hand

194
00:11:06.840 --> 00:11:17.009
Anthony Taylor: like someone went in here and tried to hand fix it. But yeah, all of these should be lower case. But they would represent just like this. Each one is an item in a list.

195
00:11:17.620 --> 00:11:18.490
Anthony Taylor: Okay.

196
00:11:20.160 --> 00:11:24.879
Anthony Taylor: so then we're going to use our count, vector we use that the other day

197
00:11:25.010 --> 00:11:29.090
Anthony Taylor: and stop words English and then fit transform those

198
00:11:29.800 --> 00:11:30.750
Anthony Taylor: lions.

199
00:11:31.220 --> 00:11:35.440
Anthony Taylor: Okay, so we're just gonna tokenize them and remove our stop words.

200
00:11:35.990 --> 00:11:39.679
Anthony Taylor: So we end up with what's called a Dtm.

201
00:11:40.430 --> 00:11:41.340
Anthony Taylor: K.

202
00:11:42.380 --> 00:11:44.689
Anthony Taylor: And the Dtm.

203
00:11:46.060 --> 00:11:49.949
Anthony Taylor: Oh, my God! Something matrix! I can't believe I forgot the name of it. 1 s.

204
00:11:50.230 --> 00:11:51.530
Anthony Taylor: Don't move.

205
00:11:52.980 --> 00:11:54.771
Meredith McCanse (she/her): Document term matrix. It's on the.

206
00:11:55.070 --> 00:11:57.350
Anthony Taylor: Thank you. Oh, thank God!

207
00:12:00.060 --> 00:12:01.239
Anthony Taylor: Which side? 10.

208
00:12:01.240 --> 00:12:01.910
Meredith McCanse (she/her): But 10.

209
00:12:01.910 --> 00:12:03.139
Anthony Taylor: There you go.

210
00:12:03.200 --> 00:12:08.740
Anthony Taylor: Thank you. I'm like, Oh, my God, I've seen it like 50 times today. Okay, so

211
00:12:08.860 --> 00:12:12.439
Anthony Taylor: and we end up with this. And and basically, it's just the word.

212
00:12:12.870 --> 00:12:17.290
Anthony Taylor: okay, that are in, we're 68, total words. Well.

213
00:12:17.580 --> 00:12:20.199
Anthony Taylor: 68 unique words.

214
00:12:20.630 --> 00:12:21.850
Anthony Taylor: And

215
00:12:22.210 --> 00:12:24.899
Anthony Taylor: we're just basically putting a one

216
00:12:25.750 --> 00:12:31.939
Anthony Taylor: in there for each document. So this one has, Brown says, Undergo Watson.

217
00:12:32.320 --> 00:12:33.090
Anthony Taylor: See?

218
00:12:34.270 --> 00:12:35.190
Anthony Taylor: Alright.

219
00:12:36.630 --> 00:12:37.310
Clayton Graves: So it's got.

220
00:12:37.630 --> 00:12:38.270
Anthony Taylor: Use! It.

221
00:12:38.270 --> 00:12:41.220
Clayton Graves: How does that handle duplicate words? If you've got.

222
00:12:41.220 --> 00:12:44.320
Anthony Taylor: It's it's duplicate in one.

223
00:12:44.430 --> 00:12:45.230
Anthony Taylor: Yes.

224
00:12:46.910 --> 00:12:48.220
Anthony Taylor: so if.

225
00:12:48.220 --> 00:12:50.050
Clayton Graves: Browns, and 2 headlines.

226
00:12:54.240 --> 00:12:57.210
Anthony Taylor: My guess is that it would be just what?

227
00:12:58.300 --> 00:13:02.110
Anthony Taylor: Because it it's it's only one and 0. I don't think this is a count.

228
00:13:02.400 --> 00:13:06.769
Anthony Taylor: because it doesn't matter if it's in there twice. What really matters is it in there at all?

229
00:13:07.740 --> 00:13:11.640
Anthony Taylor: But I mean we could try it, maybe see? See what happens.

230
00:13:14.670 --> 00:13:18.310
Anthony Taylor: okay, so oh, wait. That's actually next. So with that.

231
00:13:18.890 --> 00:13:20.800
Anthony Taylor: let me go through this here.

232
00:13:21.110 --> 00:13:25.449
Anthony Taylor: I was hoping they had some of these cool examples in there for you, but they don't.

233
00:13:32.440 --> 00:13:34.750
Anthony Taylor: alright, let's go to here.

234
00:13:36.990 --> 00:13:41.119
Anthony Taylor: We haven't. We do have an interesting problem later, but we'll figure it out

235
00:13:41.560 --> 00:13:51.830
Anthony Taylor: alright. So first we got to import our stuff. There's the only thing that's new in here is we're going to bring in sk learns decomposition. Latin, do I say? Allocation

236
00:13:52.760 --> 00:13:54.720
Anthony Taylor: the richly.

237
00:13:56.910 --> 00:13:58.529
Anthony Taylor: I can speak French now.

238
00:13:59.696 --> 00:14:02.680
Anthony Taylor: We're gonna load this Csv.

239
00:14:03.580 --> 00:14:10.429
Anthony Taylor: so we have a whole bunch. She's 22 too too young to marry a 36 year old. The bachelor investigates

240
00:14:10.880 --> 00:14:13.840
Anthony Taylor: the only shopping guide for cyber. Monday.

241
00:14:14.890 --> 00:14:17.760
Anthony Taylor: The major problem with electric cars.

242
00:14:18.050 --> 00:14:19.050
Anthony Taylor: Okay?

243
00:14:19.838 --> 00:14:26.529
Anthony Taylor: I went through the app. And we're gonna we're gonna take a look at our text.

244
00:14:26.670 --> 00:14:30.040
Anthony Taylor: Just one column, just a headline.

245
00:14:30.450 --> 00:14:31.490
Anthony Taylor: Alright.

246
00:14:31.880 --> 00:14:35.069
Anthony Taylor: we have 2 23,376 of them.

247
00:14:35.290 --> 00:14:40.969
Anthony Taylor: So we're going to. Just so what we're going to do in this one instead of that cool function they showed us in

248
00:14:41.420 --> 00:14:42.234
Anthony Taylor: the

249
00:14:44.400 --> 00:14:45.920
Anthony Taylor: notepad there in the

250
00:14:47.130 --> 00:14:48.280
Anthony Taylor: slideshow.

251
00:14:50.310 --> 00:14:53.890
Anthony Taylor: they we are going to just apply

252
00:14:54.050 --> 00:14:56.080
Anthony Taylor: an anonymous function.

253
00:14:56.170 --> 00:15:00.799
Anthony Taylor: We're just going to do Regex. And basically, if it's not

254
00:15:01.280 --> 00:15:04.330
Anthony Taylor: lower case A to Z up case A to Z or space.

255
00:15:05.110 --> 00:15:06.410
Anthony Taylor: We're just going to get rid of it.

256
00:15:06.830 --> 00:15:07.670
Anthony Taylor: Okay.

257
00:15:08.210 --> 00:15:10.060
Anthony Taylor: Boop, and we end up with that.

258
00:15:10.310 --> 00:15:11.820
Anthony Taylor: We did not lowercase it

259
00:15:11.920 --> 00:15:13.019
Anthony Taylor: just for the record.

260
00:15:14.013 --> 00:15:22.779
Anthony Taylor: Now, we're gonna run our count vectorized. So remember this from the other day. I don't remember if we had these in here. But bottom line is this is the Idf scores.

261
00:15:23.170 --> 00:15:31.059
Anthony Taylor: Okay, document frequent. Well, it's technically just document frequency score. And we're saying, the Max we want is point 9 5,

262
00:15:31.090 --> 00:15:33.750
Anthony Taylor: and the minimum is 10

263
00:15:34.020 --> 00:15:34.970
Anthony Taylor: k.

264
00:15:35.180 --> 00:15:40.201
Anthony Taylor: so that's good. We're gonna use our stop words. Take a peek

265
00:15:41.791 --> 00:15:45.000
Anthony Taylor: and now we're going to grab a headline

266
00:15:45.060 --> 00:15:47.680
Anthony Taylor: or 10 or 23,000

267
00:15:48.210 --> 00:15:49.130
Anthony Taylor: you can.

268
00:15:49.400 --> 00:15:50.760
Anthony Taylor: We're going to fit

269
00:15:50.840 --> 00:15:52.480
Anthony Taylor: to our

270
00:15:52.600 --> 00:15:54.199
Anthony Taylor: count that Derizer.

271
00:15:54.670 --> 00:15:57.539
Anthony Taylor: and see the Dtm date.

272
00:15:57.580 --> 00:15:59.219
Anthony Taylor: So what is this telling?

273
00:15:59.240 --> 00:16:05.930
Anthony Taylor: Well, there's 23,377 rows, and 3,149 unique

274
00:16:06.000 --> 00:16:07.220
Anthony Taylor: words.

275
00:16:08.780 --> 00:16:09.880
Anthony Taylor: Alright.

276
00:16:09.900 --> 00:16:12.250
Anthony Taylor: Everyone agree with that everybody understand me

277
00:16:13.410 --> 00:16:15.400
Anthony Taylor: alright, and actually hold on.

278
00:16:25.250 --> 00:16:26.110
Anthony Taylor: Oh.

279
00:16:27.900 --> 00:16:28.960
Anthony Taylor: alright!

280
00:16:29.000 --> 00:16:37.679
Anthony Taylor: Let's I'm gonna stop here for a second. Just remember where we left off. I want to talk about this, because there's not. There's no slides for this. But I kind of like this.

281
00:16:37.690 --> 00:16:40.159
Anthony Taylor: So what is a topic? What am I talking about?

282
00:16:40.330 --> 00:16:42.160
Anthony Taylor: I said, we're topic modeling.

283
00:16:43.180 --> 00:16:44.150
Anthony Taylor: What is that?

284
00:16:48.440 --> 00:16:50.370
Anthony Taylor: I mean? We kind of talked about it.

285
00:16:51.610 --> 00:16:54.099
Anthony Taylor: Anybody want to describe what a topic is.

286
00:16:54.700 --> 00:16:56.750
Baro, Sonja: Sort of category like

287
00:16:57.310 --> 00:17:00.620
Baro, Sonja: we're trying to fit into

288
00:17:00.850 --> 00:17:04.670
Baro, Sonja: some type of category what the story is about.

289
00:17:06.160 --> 00:17:09.589
Anthony Taylor: Basically, that's what we're looking at. So let's think.

290
00:17:09.630 --> 00:17:12.139
Anthony Taylor: how did we when we were reading?

291
00:17:12.319 --> 00:17:14.120
Anthony Taylor: Let's just go back up and look at these

292
00:17:14.150 --> 00:17:16.869
Anthony Taylor: when we were read. When we read this sentence.

293
00:17:17.540 --> 00:17:19.439
Anthony Taylor: how are we categorizing.

294
00:17:23.599 --> 00:17:24.359
Baro, Sonja: Major.

295
00:17:24.359 --> 00:17:27.469
Anthony Taylor: First off. What's this category? Yeah. Major words right?

296
00:17:27.470 --> 00:17:28.880
Baro, Sonja: Sports, Olympic.

297
00:17:29.890 --> 00:17:31.370
Anthony Taylor: Sports. Olympic. Okay.

298
00:17:31.600 --> 00:17:34.949
Anthony Taylor: right? It has another country in it could be travel again.

299
00:17:35.120 --> 00:17:35.730
Baro, Sonja: Yeah.

300
00:17:35.730 --> 00:17:36.480
Anthony Taylor: Right

301
00:17:36.680 --> 00:17:39.600
Anthony Taylor: welcome to hell. Maybe it's theological.

302
00:17:41.520 --> 00:17:41.950
Baro, Sonja: Yeah.

303
00:17:41.950 --> 00:17:42.899
Anthony Taylor: Yeah, right now.

304
00:17:43.720 --> 00:17:46.320
Anthony Taylor: alright. So we have all this stuff.

305
00:17:46.650 --> 00:17:51.910
Anthony Taylor: But we're taking it apart. And we understand the meanings of these words.

306
00:17:52.950 --> 00:17:53.870
Anthony Taylor: K,

307
00:17:54.220 --> 00:17:57.380
Anthony Taylor: does the computer ever understand the meaning of these words?

308
00:17:58.620 --> 00:17:59.810
Anthony Taylor: It has snow clip.

309
00:18:00.190 --> 00:18:00.940
Anthony Taylor: Matt.

310
00:18:01.410 --> 00:18:04.929
Anthony Taylor: Okay, they're just gonna be numbers. They're gonna be separate words.

311
00:18:05.040 --> 00:18:07.580
Anthony Taylor: Okay. Now, remember when we did

312
00:18:07.770 --> 00:18:08.760
Anthony Taylor: like

313
00:18:11.740 --> 00:18:14.529
Anthony Taylor: describe America. Remember we did that the other day

314
00:18:14.850 --> 00:18:19.209
Anthony Taylor: we wanted the the adjectives that described the word America.

315
00:18:19.580 --> 00:18:23.609
Anthony Taylor: Remember, all we did was use facie to say, Find me an agony.

316
00:18:24.250 --> 00:18:28.340
Anthony Taylor: And when you find it is the next word, America. Yeah. Okay, that's describing America.

317
00:18:29.370 --> 00:18:34.019
Anthony Taylor: So what we kinda did. There is. We took not one word, but 2 words.

318
00:18:35.040 --> 00:18:36.850
Anthony Taylor: and we came up with

319
00:18:37.070 --> 00:18:38.290
Anthony Taylor: a conclusion

320
00:18:38.790 --> 00:18:42.639
Anthony Taylor: alright, because those terms were together.

321
00:18:42.990 --> 00:18:47.879
Anthony Taylor: we were able to teach the computer that that's an adjective that's describing

322
00:18:47.990 --> 00:18:53.500
Anthony Taylor: America. Now, does it understand that it's describing America with that adjective? Absolutely not

323
00:18:53.530 --> 00:18:54.549
Anthony Taylor: has no clue.

324
00:18:54.870 --> 00:18:59.469
Anthony Taylor: but programmatically, our function was able to

325
00:18:59.630 --> 00:19:01.540
Anthony Taylor: identify it in that manner.

326
00:19:01.990 --> 00:19:03.070
Anthony Taylor: Okay?

327
00:19:04.980 --> 00:19:05.840
Anthony Taylor: though.

328
00:19:06.520 --> 00:19:09.209
Anthony Taylor: that was a very explicit rule.

329
00:19:09.300 --> 00:19:10.840
Anthony Taylor: We basically said.

330
00:19:11.210 --> 00:19:12.580
Anthony Taylor: if it's an adjective

331
00:19:12.770 --> 00:19:14.469
Anthony Taylor: before the word America.

332
00:19:14.910 --> 00:19:17.149
Anthony Taylor: I want to see that that's a rule

333
00:19:18.190 --> 00:19:20.720
Anthony Taylor: that's not an algorithm. It's a rule.

334
00:19:21.570 --> 00:19:23.760
Anthony Taylor: And that's one thing that you guys.

335
00:19:24.070 --> 00:19:31.639
Anthony Taylor: I I do want you guys to always think about when you're thinking about machine learning use cases. AI used cases is, can that be written with a rule?

336
00:19:33.400 --> 00:19:34.480
Anthony Taylor: Okay.

337
00:19:34.909 --> 00:19:44.809
Anthony Taylor: and that was, that would be a rule. Okay? So an algorithm is something that you don't come up with like a mathematical function. You let the machine do it anyway. So

338
00:19:45.130 --> 00:19:48.040
Anthony Taylor: topic modeling is basically

339
00:19:49.510 --> 00:19:53.040
Anthony Taylor: we're the computer is gonna look, not at one word.

340
00:19:53.240 --> 00:19:56.210
Anthony Taylor: but like multiple words together.

341
00:19:57.250 --> 00:19:58.640
Anthony Taylor: overlapping.

342
00:19:59.820 --> 00:20:00.870
Anthony Taylor: Okay.

343
00:20:00.900 --> 00:20:04.799
Anthony Taylor: to give a and and try to come up with a meaning. Yes.

344
00:20:05.490 --> 00:20:06.440
Baro, Sonja: So

345
00:20:06.620 --> 00:20:13.920
Baro, Sonja: does is someone telling it. So back to that lesson where we saw almost a diagramming of the sentence.

346
00:20:14.210 --> 00:20:18.929
Baro, Sonja: right? This was a now, this was an adjective. All that kind of stuff is

347
00:20:19.010 --> 00:20:23.780
Baro, Sonja: is somebody. When they're building the model defining what's important like.

348
00:20:23.840 --> 00:20:27.489
Baro, Sonja: Find your noun first, then. No, okay.

349
00:20:28.110 --> 00:20:34.220
Anthony Taylor: No, and that like I said that whole spacing thing very, very cool for analytics. I'm not 100, I mean, like I said. I don't

350
00:20:34.290 --> 00:20:37.710
Anthony Taylor: other than I've never used Spacey for parts of speech

351
00:20:37.920 --> 00:20:45.129
Anthony Taylor: I never have. But I mean I may now I really like, but but Spacey has other really cool functionality, and you know

352
00:20:45.500 --> 00:20:52.349
Anthony Taylor: but it's the the parts of speech thing is I I honest to God, think somebody with this is cool. I wanna make it less about.

353
00:20:52.800 --> 00:20:53.910
Anthony Taylor: They made a lesson.

354
00:20:56.410 --> 00:20:59.270
Anthony Taylor: so we already talked about. Well.

355
00:20:59.680 --> 00:21:03.039
Anthony Taylor: so here's 2 more topics. I'm gonna read you 2 topics

356
00:21:03.310 --> 00:21:06.490
Anthony Taylor: and want you guys to categorize that

357
00:21:06.820 --> 00:21:07.710
Anthony Taylor: a

358
00:21:07.830 --> 00:21:12.270
Anthony Taylor: Michelle Yao makes history with best actress. October.

359
00:21:12.520 --> 00:21:13.420
Anthony Taylor: There's one

360
00:21:13.990 --> 00:21:19.840
Anthony Taylor: how Usher is preparing for his super bowl performance to take it to another level.

361
00:21:20.060 --> 00:21:21.179
Anthony Taylor: That's 2.

362
00:21:23.620 --> 00:21:26.060
Anthony Taylor: What kind of categories can you come up with for that.

363
00:21:26.830 --> 00:21:28.040
Baro, Sonja: Entertainment.

364
00:21:28.730 --> 00:21:31.630
Anthony Taylor: Entertainment probably be the overall category, right?

365
00:21:32.980 --> 00:21:35.830
Anthony Taylor: And the reasoning because they're both celebrities

366
00:21:36.220 --> 00:21:37.829
Anthony Taylor: and they're both entertainers.

367
00:21:38.090 --> 00:21:40.020
Anthony Taylor: What other things could we come up with

368
00:21:43.720 --> 00:21:44.680
Anthony Taylor: movies.

369
00:21:44.890 --> 00:21:45.810
Masarirambi, Rodney: Oh, for

370
00:21:47.170 --> 00:21:53.261
Masarirambi, Rodney: we're unsure. You could even have sports as well, since it was the super super bowl.

371
00:21:53.831 --> 00:21:54.679
Anthony Taylor: Show this as soon.

372
00:21:54.680 --> 00:21:55.070
Masarirambi, Rodney: For m-.

373
00:21:55.070 --> 00:21:57.180
Anthony Taylor: It's probably gonna be sports.

374
00:21:57.990 --> 00:21:58.780
Masarirambi, Rodney: Yeah.

375
00:22:00.520 --> 00:22:04.390
Masarirambi, Rodney: for Michelle. Yo, I think you can also like

376
00:22:05.040 --> 00:22:07.649
Masarirambi, Rodney: I guess it'd be a competitive

377
00:22:09.110 --> 00:22:11.049
Masarirambi, Rodney: category as well, cause it is.

378
00:22:11.050 --> 00:22:12.220
Anthony Taylor: Sounds like sports.

379
00:22:14.500 --> 00:22:15.779
Masarirambi, Rodney: Would would it be?

380
00:22:17.550 --> 00:22:22.420
Masarirambi, Rodney: Would it be consent, sports or competition? Because competition wouldn't necessarily imply sports.

381
00:22:22.870 --> 00:22:23.950
Anthony Taylor: That's true, too.

382
00:22:24.210 --> 00:22:26.720
Anthony Taylor: I don't know. That's what I'm saying. I mean, it could be.

383
00:22:26.860 --> 00:22:29.140
Anthony Taylor: But this is again we're still talking about, you know

384
00:22:29.180 --> 00:22:30.890
Anthony Taylor: it's just another cool example.

385
00:22:34.010 --> 00:22:36.239
Anthony Taylor: so what we could do

386
00:22:36.740 --> 00:22:39.179
Anthony Taylor: really bother that. They don't have this in the slideshow.

387
00:22:45.040 --> 00:22:46.300
Anthony Taylor: Yeah, they like it.

388
00:22:46.300 --> 00:22:49.300
Masarirambi, Rodney: But they didn't like it that much to put into a slideshow.

389
00:22:49.300 --> 00:22:50.980
Anthony Taylor: Well, here, I'm gonna try to do this.

390
00:22:51.850 --> 00:22:53.860
Anthony Taylor: So what they could do.

391
00:22:54.940 --> 00:23:02.639
Anthony Taylor: I mean, so what happens is is it's going to take each of these categories that it comes up with, and then it's going to score them.

392
00:23:03.920 --> 00:23:08.069
Anthony Taylor: The probability that I belong that this belongs to this category

393
00:23:08.250 --> 00:23:13.460
Anthony Taylor: now they clearly both belong to celebrities. But do they belong to other categories? Well.

394
00:23:13.770 --> 00:23:20.440
Anthony Taylor: you know, it's just a matter of looking at it. Some movies I mean it. The only one that really makes sense is celebrities

395
00:23:20.610 --> 00:23:22.020
Anthony Taylor: outside of entertainment.

396
00:23:23.150 --> 00:23:24.000
Anthony Taylor: Okay.

397
00:23:24.550 --> 00:23:29.729
Anthony Taylor: so that is what our model is gonna do for us. It's going to

398
00:23:29.860 --> 00:23:31.070
Anthony Taylor: way.

399
00:23:32.020 --> 00:23:33.040
Anthony Taylor: Yeah, there.

400
00:23:34.450 --> 00:23:36.719
Derek Rikke: Not like a super important question, but how would.

401
00:23:36.720 --> 00:23:37.600
Anthony Taylor: No, it's okay.

402
00:23:37.600 --> 00:23:38.420
Derek Rikke: Is work.

403
00:23:38.860 --> 00:23:46.290
Derek Rikke: Cause how would it know they're both celebrities, cause I feel like celebrities are just like names, and it's like, Oh, there's like a

404
00:23:46.310 --> 00:23:49.140
Derek Rikke: proper name. There's like a name in this one. There's name in that one.

405
00:23:50.080 --> 00:23:53.860
Anthony Taylor: And and to be truthful, I love that you came up with that, and I'll tell you

406
00:23:55.390 --> 00:23:56.850
Anthony Taylor: none of these

407
00:23:56.940 --> 00:23:58.389
Anthony Taylor: would the model come up.

408
00:23:59.800 --> 00:24:02.990
Anthony Taylor: What the model would do is say.

409
00:24:04.800 --> 00:24:12.300
Anthony Taylor: actually, we didn't even do that if if we told it. There are 4 topics, and this is what we're going to do. We're going to say, remember, it's unsupervised.

410
00:24:12.440 --> 00:24:13.799
Anthony Taylor: So we're going to say

411
00:24:14.270 --> 00:24:15.910
Anthony Taylor: there's a possibility of

412
00:24:16.080 --> 00:24:17.250
Anthony Taylor: 4 topics.

413
00:24:18.060 --> 00:24:22.720
Anthony Taylor: And then it's gonna go through. Do its thing and say, Okay, well.

414
00:24:22.830 --> 00:24:24.740
Anthony Taylor: it's likely that

415
00:24:24.840 --> 00:24:27.160
Anthony Taylor: both belong to topic number one.

416
00:24:27.590 --> 00:24:29.500
Anthony Taylor: or that this belongs to topic. What

417
00:24:29.720 --> 00:24:38.209
Anthony Taylor: right? That's what this tells me is the probability that this belongs to topic one. And this is the probability that this belongs to topic one.

418
00:24:40.000 --> 00:24:42.010
Anthony Taylor: It doesn't know what topic, what is

419
00:24:42.930 --> 00:24:45.719
Anthony Taylor: alright. Now, between you guys and me.

420
00:24:45.850 --> 00:24:52.270
Anthony Taylor: celebrities doesn't even make sense because you're right. It doesn't know who Michelle Yao is, or go or usher

421
00:24:52.610 --> 00:24:53.730
Anthony Taylor: has no clue.

422
00:24:54.430 --> 00:24:58.280
Anthony Taylor: Okay, so celebrities is actually kind of a bad topic.

423
00:24:59.140 --> 00:24:59.950
Anthony Taylor: But

424
00:25:01.060 --> 00:25:05.020
Anthony Taylor: it could. It could say, they belong to the same topic for different reasons.

425
00:25:05.520 --> 00:25:09.810
Anthony Taylor: Okay, but we're gonna get into that. We'll see that in action in a few moments.

426
00:25:11.570 --> 00:25:16.789
Anthony Taylor: so topic models unable to go uncover themes on patterns of co-occurring words.

427
00:25:17.270 --> 00:25:20.069
Anthony Taylor: Okay, I'm sorry is able to uncover them.

428
00:25:20.850 --> 00:25:29.250
Anthony Taylor: Worse, the humans might not be able to identify easily or comprehensively. This makes it ideal for recommendation engine against large

429
00:25:29.440 --> 00:25:30.330
Anthony Taylor: for brat.

430
00:25:31.600 --> 00:25:34.190
Anthony Taylor: Am I saying that word right for borah

431
00:25:35.200 --> 00:25:36.990
Anthony Taylor: corpus? Multiply

432
00:25:37.130 --> 00:25:37.840
Anthony Taylor: multiple.

433
00:25:38.290 --> 00:25:39.569
Anthony Taylor: Pretty sure it's corpora

434
00:25:40.306 --> 00:25:44.600
Anthony Taylor: so we're gonna take a look at the specific one. Lda, we talked about that.

435
00:25:46.554 --> 00:25:54.339
Anthony Taylor: It's important to understand that Lda assumes the documents are a mixture of topics. If you just give it a bunch of sports topics.

436
00:25:55.890 --> 00:25:58.829
Anthony Taylor: It's gonna assume they're all mixture of sports stuff.

437
00:25:59.370 --> 00:26:03.719
Anthony Taylor: Well, you're gonna have to do that. But it's not gonna really be as helpful.

438
00:26:04.300 --> 00:26:07.009
Anthony Taylor: Okay? Because it does not understand

439
00:26:07.360 --> 00:26:08.560
Anthony Taylor: what we're doing.

440
00:26:09.080 --> 00:26:11.809
Anthony Taylor: Okay? Alright. Now, let's get back to this.

441
00:26:12.040 --> 00:26:15.909
Anthony Taylor: So we have our stuff. We

442
00:26:18.390 --> 00:26:19.999
Anthony Taylor: we did this, hey question.

443
00:26:20.440 --> 00:26:22.640
Anthony Taylor: do we need to do? Train test split here?

444
00:26:28.070 --> 00:26:29.680
Anthony Taylor: Eric, shaking his head.

445
00:26:29.890 --> 00:26:32.450
Meredith McCanse (she/her): That was actually a question I wanted to ask.

446
00:26:32.790 --> 00:26:36.349
Anthony Taylor: I love that alright. Well, Meredith has this question. Who was.

447
00:26:36.350 --> 00:26:37.070
Meredith McCanse (she/her): Answer it.

448
00:26:37.070 --> 00:26:38.940
Anthony Taylor: Do we need train test? Fliggered.

449
00:26:39.240 --> 00:26:42.299
Dipinto, Matt: It's unsupervised. So no.

450
00:26:42.900 --> 00:26:49.119
Anthony Taylor: Bingo. That is the answer unsupervised. Remember, we don't do because there's no, there's nothing to test it against. So.

451
00:26:49.430 --> 00:26:51.340
Meredith McCanse (she/her): Country desk, split, installed.

452
00:26:51.340 --> 00:26:55.880
Anthony Taylor: Hold back stuff that we can use to answer to, to test our answers, our predictions.

453
00:26:56.720 --> 00:26:57.820
Anthony Taylor: There's no

454
00:26:57.900 --> 00:27:01.869
Anthony Taylor: answer. So it doesn't help us. So no, we do not need tickets.

455
00:27:06.280 --> 00:27:07.140
Anthony Taylor: okay.

456
00:27:07.300 --> 00:27:10.475
Anthony Taylor: so we've got our model.

457
00:27:12.350 --> 00:27:14.279
Anthony Taylor: we did our fit transform.

458
00:27:14.310 --> 00:27:22.360
Anthony Taylor: So we can actually see the link. So like, how many words we have are new, this from that. But we have 3,100,

459
00:27:22.400 --> 00:27:24.159
Anthony Taylor: 49 words.

460
00:27:24.210 --> 00:27:26.619
Anthony Taylor: If we wanted to see those words.

461
00:27:27.700 --> 00:27:31.929
Anthony Taylor: we can do. And we did this the other day, too, get feature names out.

462
00:27:32.150 --> 00:27:38.359
Anthony Taylor: This gives us like the top 100 just words. They're not in order. It's just words.

463
00:27:38.970 --> 00:27:40.690
Anthony Taylor: Okay, that are in

464
00:27:41.436 --> 00:27:45.889
Anthony Taylor: the 23,377 articles

465
00:27:46.590 --> 00:27:47.410
Anthony Taylor: ken

466
00:27:47.610 --> 00:27:53.210
Anthony Taylor: pretty cool. Nothing exciting. Yet so far, we're still kind of just doing analysis here.

467
00:27:55.420 --> 00:28:01.790
Anthony Taylor: so our Dtm, not everywhere is going to be in every row. So if we want to see that we can actually

468
00:28:01.880 --> 00:28:03.120
Anthony Taylor: run this.

469
00:28:04.040 --> 00:28:06.550
Anthony Taylor: and we'll see the

470
00:28:07.670 --> 00:28:10.419
Anthony Taylor: first 500 elements from the first

471
00:28:10.440 --> 00:28:11.900
Anthony Taylor: row. So

472
00:28:11.950 --> 00:28:16.540
Anthony Taylor: there could be a lot more in this first row. We're just looking at the first 500 of

473
00:28:17.360 --> 00:28:21.179
Anthony Taylor: okay? And you should see, what do you guys see here? What does this look like to you?

474
00:28:23.320 --> 00:28:25.850
Anthony Taylor: What do you notice about these elements?

475
00:28:33.380 --> 00:28:34.620
Derek Rikke: They're almost all 0.

476
00:28:35.540 --> 00:28:38.740
Anthony Taylor: Bingo, almost. Do you see a one in there?

477
00:28:39.570 --> 00:28:40.160
Clayton Graves: One.

478
00:28:40.940 --> 00:28:42.539
Meredith McCanse (she/her): It's in the fifth rowdown.

479
00:28:42.540 --> 00:28:42.990
Derek Rikke: Yeah.

480
00:28:44.320 --> 00:28:49.549
Anthony Taylor: There it is. So this indicates in the first 500 elements of this article there is

481
00:28:49.560 --> 00:28:53.490
Anthony Taylor: one unique word, Oh, hey, Matt! What's up.

482
00:28:55.698 --> 00:29:01.180
Dipinto, Matt: Quick question, is this actually a Dtm. Because based on their definition, it was supposed to be a binary

483
00:29:01.320 --> 00:29:02.420
Dipinto, Matt: array.

484
00:29:02.490 --> 00:29:07.859
Dipinto, Matt: And this is not a binary array. This has just value, counts in it or not. Value counts, but

485
00:29:09.480 --> 00:29:11.459
Dipinto, Matt: Term frequency in it right now.

486
00:29:12.580 --> 00:29:17.250
Anthony Taylor: Hmm! It's only gonna show a one for each word.

487
00:29:18.330 --> 00:29:19.259
Dipinto, Matt: There!

488
00:29:19.407 --> 00:29:19.850
Anthony Taylor: See you more.

489
00:29:19.850 --> 00:29:21.150
Dipinto, Matt: A 3

490
00:29:21.160 --> 00:29:29.639
Dipinto, Matt: here. So if you do data frame Max, dot values, and then you run a max of the array you get from that somewhere somewhere in there has 3 iterations.

491
00:29:30.590 --> 00:29:32.449
Anthony Taylor: Let's find out what's going on.

492
00:29:32.730 --> 00:29:33.259
Anthony Taylor: That's a.

493
00:29:33.260 --> 00:29:34.149
Dipinto, Matt: And so, because.

494
00:29:34.150 --> 00:29:34.730
Anthony Taylor: And Karen and.

495
00:29:34.730 --> 00:29:36.370
Dipinto, Matt: Supervisor just counts

496
00:29:36.400 --> 00:29:37.460
Dipinto, Matt: words.

497
00:29:37.460 --> 00:29:38.050
Anthony Taylor: Yeah.

498
00:29:43.380 --> 00:29:50.390
Anthony Taylor: so did we. The question is, is, did we make this and continue mentioned that in our Dtm not everywhere is going to be in and grow.

499
00:29:50.500 --> 00:29:53.720
Anthony Taylor: If a word vocabulary column a value

500
00:29:54.430 --> 00:29:58.670
Anthony Taylor: 0 depending on the number of times that word appears in that row. So there you go

501
00:29:59.070 --> 00:30:04.250
Anthony Taylor: so, and if a vocabulary word does not appear, it's a 0. So it does say the number of times it appears in that row.

502
00:30:04.720 --> 00:30:06.140
Anthony Taylor: so it could be

503
00:30:06.360 --> 00:30:12.020
Anthony Taylor: more than one. I know you said. It's binary. But this is the Dtm that we're making.

504
00:30:12.090 --> 00:30:17.020
Anthony Taylor: Where where did you did we say Dtm. Is binary in our slide?

505
00:30:17.020 --> 00:30:21.549
Dipinto, Matt: In the slides. It says it's a one, if it appears, and it's a so

506
00:30:21.790 --> 00:30:27.750
Dipinto, Matt: we don't need to get super sticky about it. If appears in a document, the value is a one, otherwise it's a 0.

507
00:30:28.240 --> 00:30:29.630
Dipinto, Matt: That's a binary.

508
00:30:30.310 --> 00:30:33.329
Anthony Taylor: I agree. That's what that reads like, but I will.

509
00:30:33.330 --> 00:30:34.290
Dipinto, Matt: July 2.

510
00:30:34.990 --> 00:30:36.780
Anthony Taylor: I I'll be honest with you.

511
00:30:36.910 --> 00:30:39.509
Anthony Taylor: That's what I got out of it, too, so

512
00:30:40.340 --> 00:30:41.140
Anthony Taylor: cool.

513
00:30:41.290 --> 00:30:48.050
Anthony Taylor: Now we know it's actually a count of how many times the word appears in that row which goes back to Clayton's question.

514
00:30:48.960 --> 00:30:51.399
Anthony Taylor: he said, what if the word appears more than once?

515
00:30:51.780 --> 00:30:52.940
Anthony Taylor: Now we know?

516
00:30:53.800 --> 00:30:56.330
Anthony Taylor: Look at this, the mystery has been solved.

517
00:30:56.630 --> 00:30:58.940
Anthony Taylor: Da, da, da.

518
00:30:59.050 --> 00:31:00.630
Anthony Taylor: okay. So

519
00:31:01.120 --> 00:31:06.849
Anthony Taylor: dtm, there, it is the reason there's a one, because there's only one occurrence of that work.

520
00:31:07.450 --> 00:31:13.529
Anthony Taylor: Okay, alright. So we can find out what that word is. We can see all of the feature names.

521
00:31:13.660 --> 00:31:16.379
Anthony Taylor: We can say, Okay, give me only

522
00:31:16.490 --> 00:31:20.840
Anthony Taylor: the non 0 elements of the first row.

523
00:31:21.290 --> 00:31:22.370
Anthony Taylor: Okay.

524
00:31:22.510 --> 00:31:24.410
Anthony Taylor: and

525
00:31:24.500 --> 00:31:27.999
Anthony Taylor: get the indices for those and then print them out.

526
00:31:28.200 --> 00:31:29.429
Anthony Taylor: And there they are.

527
00:31:29.470 --> 00:31:31.550
Anthony Taylor: bachelor year old, young

528
00:31:32.240 --> 00:31:33.390
Anthony Taylor: one of each.

529
00:31:34.170 --> 00:31:35.830
Anthony Taylor: Here's the word index

530
00:31:36.250 --> 00:31:37.409
Anthony Taylor: for each of them.

531
00:31:38.160 --> 00:31:39.130
Anthony Taylor: Okay.

532
00:31:40.960 --> 00:31:43.340
Anthony Taylor: so we can put that in a data frame

533
00:31:44.100 --> 00:31:50.660
Anthony Taylor: same way as we've done this. There. We did this the other day. We're going to take the numbers to an array, and then the feature names out.

534
00:31:51.130 --> 00:31:54.570
Anthony Taylor: and then just grab a little bit of it, so we can see what it looks like.

535
00:31:55.120 --> 00:31:56.569
Anthony Taylor: Pretty exciting.

536
00:31:58.400 --> 00:32:01.560
Anthony Taylor: Still, no numbers more than one. And that's very upsetting.

537
00:32:02.370 --> 00:32:06.470
Anthony Taylor: Okay, so we have our cool little. Dtm, that's what we wanted.

538
00:32:06.770 --> 00:32:09.410
Anthony Taylor: With that, we're going to

539
00:32:09.650 --> 00:32:13.030
Anthony Taylor: start creating our model. So we did the preprocessing.

540
00:32:13.440 --> 00:32:15.299
Anthony Taylor: There was nothing. So

541
00:32:15.780 --> 00:32:17.450
Anthony Taylor: I want you guys to remember

542
00:32:17.990 --> 00:32:24.079
Anthony Taylor: a lot of times when we're showing you guys this stuff, we do a lot of well, this is what it looks like. Well, this is what it looks like.

543
00:32:24.320 --> 00:32:27.799
Anthony Taylor: Okay, we can see what I'm saying.

544
00:32:28.250 --> 00:32:30.730
Anthony Taylor: But when you take this apart.

545
00:32:32.290 --> 00:32:34.180
Anthony Taylor: you need to do this line.

546
00:32:37.110 --> 00:32:38.450
Anthony Taylor: this line.

547
00:32:42.240 --> 00:32:43.560
Anthony Taylor: this line.

548
00:32:55.310 --> 00:32:56.170
Anthony Taylor: That's it.

549
00:32:56.900 --> 00:33:01.130
Anthony Taylor: Okay? All the rest of this was just to show you what was happening behind the scenes.

550
00:33:01.850 --> 00:33:04.819
Anthony Taylor: So keep that in mind. When you guys see this stuff. Okay?

551
00:33:07.440 --> 00:33:08.130
Anthony Taylor: Alright.

552
00:33:08.320 --> 00:33:09.850
Anthony Taylor: So here, we're gonna do.

553
00:33:09.850 --> 00:33:10.190
Baro, Sonja: Yeah, but.

554
00:33:10.190 --> 00:33:11.939
Anthony Taylor: Seriously, yes, today.

555
00:33:11.940 --> 00:33:13.920
Baro, Sonja: Before you jump into the model. I just want.

556
00:33:13.920 --> 00:33:15.220
Anthony Taylor: Oh, sorry, Sonia!

557
00:33:15.220 --> 00:33:21.789
Baro, Sonja: No, that's okay. So can you scroll back up to where it was saying, pick out the feature names.

558
00:33:22.110 --> 00:33:24.899
Baro, Sonja: So is this basically saying

559
00:33:24.910 --> 00:33:26.070
Baro, Sonja: that

560
00:33:27.320 --> 00:33:33.810
Baro, Sonja: bachelor year old and young are the words the that are appearing.

561
00:33:35.070 --> 00:33:39.730
Baro, Sonja: or I guess I I'm not sure now, cause I can't. They can't.

562
00:33:39.730 --> 00:33:44.849
Anthony Taylor: These are the words that and they're they occur one time each in this first row.

563
00:33:45.750 --> 00:33:48.240
Anthony Taylor: and this is their index. So when.

564
00:33:48.240 --> 00:33:49.020
Baro, Sonja: Where they're at.

565
00:33:49.020 --> 00:33:50.049
Anthony Taylor: Like 500.

566
00:33:50.380 --> 00:33:51.550
Baro, Sonja: Yeah, so.

567
00:33:51.550 --> 00:33:52.859
Anthony Taylor: 500. But yeah.

568
00:33:53.050 --> 00:33:59.070
Baro, Sonja: The fact that there's only one of them is making it important or no.

569
00:33:59.580 --> 00:34:00.529
Anthony Taylor: We don't know yet.

570
00:34:00.960 --> 00:34:03.729
Anthony Taylor: I mean. And and it's not even something that we're gonna know.

571
00:34:04.320 --> 00:34:08.439
Anthony Taylor: Okay, this is just pre processing. So we don't. We haven't even.

572
00:34:08.690 --> 00:34:11.090
Anthony Taylor: It's not something we're gonna we're gonna know.

573
00:34:11.440 --> 00:34:14.070
Anthony Taylor: and you'll see as we go in, you'll see. But.

574
00:34:14.070 --> 00:34:18.400
Baro, Sonja: Something to show that we could see the what's happening in the background.

575
00:34:19.030 --> 00:34:20.979
Anthony Taylor: So there's right. Those are just.

576
00:34:21.170 --> 00:34:32.226
Anthony Taylor: I mean, you could certainly do that to understand. And I I recommend you do that to understand. But I mean there's the word. Once it got rid of the stop words. It had young year old, and.

577
00:34:32.510 --> 00:34:34.080
Baro, Sonja: Bachelor. Yeah.

578
00:34:34.280 --> 00:34:38.540
Anthony Taylor: Which I would have thought Mary would have been important that one. But with it I'm just weird.

579
00:34:39.030 --> 00:34:40.459
Baro, Sonja: Okay. Thank you.

580
00:34:40.679 --> 00:34:42.239
Anthony Taylor: I'm a romantic.

581
00:34:43.049 --> 00:34:44.149
Anthony Taylor: I would think

582
00:34:44.369 --> 00:34:47.829
Anthony Taylor: bachelor year old. Young would not be a good combination.

583
00:34:48.199 --> 00:34:49.214
Baro, Sonja: You'll.

584
00:34:51.449 --> 00:34:52.439
Anthony Taylor: So

585
00:34:52.942 --> 00:34:57.039
Anthony Taylor: so here we go. We we create our model. Now, the important thing here.

586
00:34:57.229 --> 00:34:58.059
Anthony Taylor: It's that.

587
00:34:58.819 --> 00:35:00.579
Anthony Taylor: So what we're saying

588
00:35:00.889 --> 00:35:04.949
Anthony Taylor: just like when we did unsupervised originally weeks ago.

589
00:35:06.529 --> 00:35:08.159
Anthony Taylor: we're going to guess

590
00:35:08.369 --> 00:35:10.129
Anthony Taylor: there are 7 topics.

591
00:35:11.889 --> 00:35:13.129
Anthony Taylor: It's just a guess.

592
00:35:14.689 --> 00:35:15.589
Anthony Taylor: Alright.

593
00:35:16.249 --> 00:35:17.679
Anthony Taylor: till we're going to fit our model

594
00:35:21.629 --> 00:35:22.959
Anthony Taylor: while that's running.

595
00:35:24.499 --> 00:35:30.899
Anthony Taylor: we're going to get the values of each topic word distribution. So all this is going to do. Well, let's just.

596
00:35:32.840 --> 00:35:34.750
Masarirambi, Rodney: Question. You said.

597
00:35:34.750 --> 00:35:35.149
Anthony Taylor: Go for it.

598
00:35:35.150 --> 00:35:39.450
Masarirambi, Rodney: You said just to you said just to guess, and then by your tone

599
00:35:40.480 --> 00:35:45.129
Masarirambi, Rodney: made it seem like no was exactly 7. But we just hope, like just a spirit of guess.

600
00:35:45.900 --> 00:35:50.250
Anthony Taylor: It. It's a straight up Guest, I mean, you might once we do this, and you'll see in a few minutes.

601
00:35:50.688 --> 00:35:56.919
Anthony Taylor: You might change it based on the output. You might go. Yeah, maybe it's 50, maybe it's 10.

602
00:35:56.920 --> 00:35:57.530
Masarirambi, Rodney: In it.

603
00:35:57.530 --> 00:35:59.230
Anthony Taylor: Okay. But it is. Yes.

604
00:35:59.680 --> 00:36:09.259
Anthony Taylor: alright. So here we're gonna look at it. And basically 1, 2, 3, 4, 5, 6. There's one more in there. 7.

605
00:36:10.320 --> 00:36:11.400
Anthony Taylor: Okay.

606
00:36:11.480 --> 00:36:15.280
Anthony Taylor: so what this is doing is telling us the probability

607
00:36:15.400 --> 00:36:18.699
Anthony Taylor: that of to which topic this belongs to.

608
00:36:20.020 --> 00:36:25.329
Anthony Taylor: Okay. And you can't really see it right now. But we're gonna get to that. So like, you can see here, this one's at 15

609
00:36:25.680 --> 00:36:35.449
Anthony Taylor: and 7 and 10. So unless the one under there is higher than 15. This is probably going to be topic one or 2 depending on how you number it.

610
00:36:36.100 --> 00:36:37.070
Anthony Taylor: Okay.

611
00:36:37.840 --> 00:36:40.349
Anthony Taylor: alright. So once we have that

612
00:36:41.790 --> 00:36:45.189
Anthony Taylor: we can get the length of each one, and this makes sense. There should be.

613
00:36:45.220 --> 00:36:51.250
Anthony Taylor: The the amount should be the same as the number of words in your vocabulary.

614
00:36:51.520 --> 00:36:58.699
Anthony Taylor: We're going to get the array for the first topic. I apologize. This one up here is actually goes up to 3,149.

615
00:36:58.830 --> 00:37:00.429
Anthony Taylor: This is doing it by work.

616
00:37:00.620 --> 00:37:03.319
Anthony Taylor: Here, we're doing a single row.

617
00:37:03.880 --> 00:37:06.310
Anthony Taylor: Okay, so this is just that first

618
00:37:07.850 --> 00:37:08.530
Anthony Taylor: route.

619
00:37:08.870 --> 00:37:09.930
Anthony Taylor: Okay.

620
00:37:10.770 --> 00:37:19.820
Anthony Taylor: then we're going to sort it. And then we're gonna talk about this just second. So don't worry about it. We're gonna sort it. And this is a new method for us called Arc sort.

621
00:37:20.500 --> 00:37:21.769
Anthony Taylor: Is it going to show us

622
00:37:22.140 --> 00:37:25.010
Anthony Taylor: it's not gonna show me? Darn, it's okay. We got it down there

623
00:37:25.120 --> 00:37:27.339
Anthony Taylor: and notice this cool little negative

624
00:37:27.590 --> 00:37:28.630
Anthony Taylor: K,

625
00:37:28.720 --> 00:37:32.070
Anthony Taylor: basically, we could take an array and sort it.

626
00:37:32.330 --> 00:37:38.949
Anthony Taylor: If you don't put the negative, it'll be an ascending order. If you put the negative, it'll be in descending order. Pretty simple, huh?

627
00:37:39.300 --> 00:37:42.870
Anthony Taylor: And then we're gonna take a look and see what we get.

628
00:37:43.610 --> 00:37:48.949
Anthony Taylor: And there we go, so sorted first topic for value and sorted first print about.

629
00:37:49.410 --> 00:37:51.639
Anthony Taylor: So basically we have

630
00:37:51.910 --> 00:37:53.709
Anthony Taylor: is just the values.

631
00:37:54.540 --> 00:37:59.080
Anthony Taylor: Alright. They still don't mean anything to us. It's just gob and goof at this point.

632
00:37:59.650 --> 00:38:01.400
Anthony Taylor: But we can see something is happening.

633
00:38:02.320 --> 00:38:06.210
Anthony Taylor: Okay. So we're gonna take you to side. Here we go on in the side.

634
00:38:06.400 --> 00:38:16.509
Anthony Taylor: Argort returns the index position from least to greatest. So what they were doing here is, they said, for value, which was an index

635
00:38:17.490 --> 00:38:21.650
Anthony Taylor: in the sorted indexes. Print the value.

636
00:38:22.090 --> 00:38:28.969
Anthony Taylor: Okay? So it was printing out the index value of each one and thus giving us count. So in this case.

637
00:38:28.990 --> 00:38:33.199
Anthony Taylor: if you have an array, and and remember, forget that stuff up above for

638
00:38:33.290 --> 00:38:34.500
Anthony Taylor: 10 s.

639
00:38:34.760 --> 00:38:36.050
Anthony Taylor: This is all new.

640
00:38:36.470 --> 00:38:39.480
Anthony Taylor: You have an array. It's got the 10, a 201.

641
00:38:40.610 --> 00:38:41.999
Anthony Taylor: If I say.

642
00:38:42.990 --> 00:38:46.699
Anthony Taylor: print the indices of the array. 1021 from least

643
00:38:46.890 --> 00:38:48.270
Anthony Taylor: to greatest.

644
00:38:50.540 --> 00:38:51.520
Anthony Taylor: Okay.

645
00:38:51.820 --> 00:38:55.660
Anthony Taylor: it's going to print based on the value.

646
00:38:55.870 --> 00:38:59.979
Anthony Taylor: But it's gonna give me the index of each one, and then vice versa.

647
00:39:00.300 --> 00:39:01.609
Anthony Taylor: giving us

648
00:39:01.710 --> 00:39:07.560
Anthony Taylor: so in this case, from least to greatest, is 2 0, one

649
00:39:07.860 --> 00:39:10.180
Anthony Taylor: from greatest to lee, or from

650
00:39:10.650 --> 00:39:13.779
Anthony Taylor: greatest, 2 least. We have one

651
00:39:13.940 --> 00:39:15.640
Anthony Taylor: 0 2

652
00:39:17.060 --> 00:39:17.960
Anthony Taylor: got it

653
00:39:19.570 --> 00:39:23.959
Anthony Taylor: pretty cool. Notice only difference between us ending and descending

654
00:39:24.630 --> 00:39:26.660
Anthony Taylor: that cool little minus sun.

655
00:39:28.790 --> 00:39:34.889
Anthony Taylor: So if you have an array, and you need to quickly sort it. This is a very, very fast way to do.

656
00:39:35.520 --> 00:39:36.760
Anthony Taylor: Yes, Christy.

657
00:39:38.450 --> 00:39:39.810
Kanouff, Christine: Okay, I'm a

658
00:39:40.210 --> 00:39:45.639
Kanouff, Christine: bit confused. Are are we doing this just on the titles?

659
00:39:46.000 --> 00:39:48.460
Kanouff, Christine: Or is this doing it on the

660
00:39:49.210 --> 00:39:51.290
Kanouff, Christine: text of the article?

661
00:39:54.480 --> 00:39:56.490
Anthony Taylor: way up here.

662
00:39:56.640 --> 00:40:00.220
Anthony Taylor: It is just the our right now. It's just the headline.

663
00:40:02.200 --> 00:40:03.050
Anthony Taylor: Yes.

664
00:40:07.010 --> 00:40:07.750
Anthony Taylor: okay.

665
00:40:07.960 --> 00:40:08.370
Kanouff, Christine: Thanks.

666
00:40:08.370 --> 00:40:11.310
Anthony Taylor: Alright. So no, no problem. That's a great question.

667
00:40:11.410 --> 00:40:15.150
Anthony Taylor: So sort the array of the first topic. So first topic.

668
00:40:15.170 --> 00:40:17.750
Anthony Taylor: hard sort, we're just going to sort it.

669
00:40:17.850 --> 00:40:18.910
Anthony Taylor: Boom.

670
00:40:18.980 --> 00:40:20.510
Anthony Taylor: hey? We get this cooler wreck.

671
00:40:20.790 --> 00:40:28.059
Anthony Taylor: Alright. So print the value of the word that is least representative of this topic. So we've got first topic.

672
00:40:28.730 --> 00:40:30.480
Anthony Taylor: So we're gonna say.

673
00:40:30.940 --> 00:40:33.399
Anthony Taylor: give me. And remember, it's sorted.

674
00:40:34.120 --> 00:40:35.330
Anthony Taylor: Okay. So

675
00:40:36.940 --> 00:40:38.310
Anthony Taylor: realized

676
00:40:39.160 --> 00:40:39.950
Anthony Taylor: that

677
00:40:40.590 --> 00:40:42.469
Anthony Taylor: this is what we're talking about. Right?

678
00:40:44.180 --> 00:40:45.180
Anthony Taylor: Okay?

679
00:40:45.550 --> 00:40:47.459
Anthony Taylor: So this is all sorted out.

680
00:40:47.720 --> 00:40:49.560
Anthony Taylor: And we're going to say, Okay.

681
00:40:49.630 --> 00:40:51.480
Anthony Taylor: give me the first.

682
00:40:51.560 --> 00:40:53.100
Anthony Taylor: whatever this value is.

683
00:40:53.540 --> 00:40:57.169
Anthony Taylor: and and then the last. Whatever this value is because it's sorted.

684
00:40:57.730 --> 00:40:59.189
Anthony Taylor: So we can run this

685
00:40:59.940 --> 00:41:03.380
Anthony Taylor: whoops already written it on this, and we can see

686
00:41:03.860 --> 00:41:07.539
Anthony Taylor: lowest value point 1 4 to high, which matches

687
00:41:08.230 --> 00:41:09.180
Anthony Taylor: this.

688
00:41:09.790 --> 00:41:11.010
Anthony Taylor: Everyone agree.

689
00:41:12.350 --> 00:41:17.960
Anthony Taylor: Okay. So that was like an aside. Just wanted to show you arc sort in the middle of an activity, because.

690
00:41:19.920 --> 00:41:23.149
Clayton Graves: Can you? Can you explain to me where the numbers

691
00:41:23.660 --> 00:41:27.384
Clayton Graves: 1,716 and 1,688.

692
00:41:28.090 --> 00:41:30.729
Anthony Taylor: So right here we sorted the array

693
00:41:31.770 --> 00:41:32.680
Anthony Taylor: right

694
00:41:33.040 --> 00:41:39.229
Anthony Taylor: and it output, and it showed us the the the lowest index and the highest.

695
00:41:39.230 --> 00:41:40.299
Clayton Graves: Got it. Okay.

696
00:41:40.300 --> 00:41:41.379
Anthony Taylor: And that's what we're seeing.

697
00:41:41.490 --> 00:41:47.210
Anthony Taylor: Okay. So now we're going to get the industry for the top 10 words for the first topic.

698
00:41:47.530 --> 00:41:51.329
Anthony Taylor: Okay, so top 10 words for topic 0.

699
00:41:51.770 --> 00:41:52.839
Anthony Taylor: When we get

700
00:41:52.920 --> 00:41:54.200
Anthony Taylor: these indexes

701
00:41:54.770 --> 00:41:58.180
Anthony Taylor: for these indexes, we can use feature names out

702
00:41:58.550 --> 00:42:02.579
Anthony Taylor: with the index and get the actual words, there they are.

703
00:42:04.590 --> 00:42:05.620
Anthony Taylor: Okay.

704
00:42:05.690 --> 00:42:09.310
Anthony Taylor: we're making progress. We could do the same for the bottom words.

705
00:42:10.930 --> 00:42:15.430
Anthony Taylor: All we did was change our archport from a positive to our negative to a positive.

706
00:42:18.170 --> 00:42:19.080
Anthony Taylor: All right.

707
00:42:19.600 --> 00:42:20.370
Anthony Taylor: Now

708
00:42:22.110 --> 00:42:27.800
Anthony Taylor: we're gonna print the top 20 words for each topic. Now, what are the top? What are the topics?

709
00:42:28.110 --> 00:42:29.399
Anthony Taylor: We don't know.

710
00:42:30.210 --> 00:42:31.410
Anthony Taylor: but now

711
00:42:31.420 --> 00:42:34.769
Anthony Taylor: we have the words, we can try to figure it out.

712
00:42:35.340 --> 00:42:36.280
Anthony Taylor: A.

713
00:42:36.430 --> 00:42:37.430
Anthony Taylor: So

714
00:42:37.700 --> 00:42:42.640
Anthony Taylor: what you would do at this point is you would read these words.

715
00:42:44.210 --> 00:42:45.989
Anthony Taylor: and you would come up with a topic.

716
00:42:50.160 --> 00:42:53.929
Anthony Taylor: There is no computer program that can do this. Well, an ln.

717
00:42:56.210 --> 00:42:59.850
Anthony Taylor: yeah. Derek, I saw your chat, mister.

718
00:43:00.980 --> 00:43:02.230
Anthony Taylor: but but.

719
00:43:04.000 --> 00:43:04.740
Clayton Graves: Learn.

720
00:43:07.500 --> 00:43:08.980
Anthony Taylor: You guys can see there's a lot.

721
00:43:09.910 --> 00:43:11.650
Anthony Taylor: See if I can get rid of my.

722
00:43:18.490 --> 00:43:23.030
Baro, Sonja: So you're saying, a human now goes through and looks at these.

723
00:43:23.030 --> 00:43:25.759
Anthony Taylor: Just these 7, because there's only 7 topics.

724
00:43:25.850 --> 00:43:27.219
Anthony Taylor: So yeah, Meredith.

725
00:43:28.080 --> 00:43:33.000
Meredith McCanse (she/her): Is this sort of the unsupervised learning portion of it like? Is it classifying.

726
00:43:33.000 --> 00:43:44.960
Anthony Taylor: All unsupervised, all of what we've done so far. What it's basically saying, is it? Think of this, if you think back to clustering, it's basically taken those words and clustered them

727
00:43:45.480 --> 00:43:51.459
Anthony Taylor: into these clusters. And now it's asked you to define each of these topics.

728
00:43:51.840 --> 00:43:55.660
Meredith McCanse (she/her): Got it. That's I meant to say, cluster. Okay, got it.

729
00:43:56.410 --> 00:44:00.579
Anthony Taylor: Okay. So once we've done that so that we've fortunately

730
00:44:00.970 --> 00:44:02.960
Anthony Taylor: rather than make you guys figure it out.

731
00:44:03.040 --> 00:44:06.080
Anthony Taylor: we have come up with these 7. Are these right? Or

732
00:44:06.310 --> 00:44:08.249
Anthony Taylor: but these are the 7 that we came up with.

733
00:44:09.110 --> 00:44:10.060
Anthony Taylor: Okay.

734
00:44:10.400 --> 00:44:12.659
Anthony Taylor: so now that we have this.

735
00:44:13.090 --> 00:44:16.549
Anthony Taylor: we can come in here and transform the Dtm.

736
00:44:16.750 --> 00:44:21.870
Anthony Taylor: To get an array with the number of documents and number of topics looks like this.

737
00:44:22.480 --> 00:44:27.460
Anthony Taylor: So now we have the 23,377 documents that we had up above.

738
00:44:27.780 --> 00:44:29.420
Anthony Taylor: and 7 top

739
00:44:30.540 --> 00:44:31.929
Anthony Taylor: the 7 we define.

740
00:44:34.020 --> 00:44:37.330
Anthony Taylor: we can get the first one and see

741
00:44:37.670 --> 00:44:41.620
Anthony Taylor: 1, 2, 3, 4, 5, 6, 7.

742
00:44:43.290 --> 00:44:44.160
Anthony Taylor: Okay.

743
00:44:44.320 --> 00:44:45.770
Anthony Taylor: which one of these?

744
00:44:46.800 --> 00:44:48.220
Anthony Taylor: Which topic

745
00:44:48.230 --> 00:44:49.849
Anthony Taylor: does this one fallen?

746
00:44:51.080 --> 00:44:52.649
Anthony Taylor: I can see it

747
00:44:52.730 --> 00:44:54.489
Anthony Taylor: looks like it's this one, right?

748
00:44:55.150 --> 00:45:01.160
Anthony Taylor: But we can do this a little nicer, we can say, Hey, let's sort this out. Let's run it.

749
00:45:01.250 --> 00:45:05.639
Anthony Taylor: And we can see so rank what topic to probability was

750
00:45:06.630 --> 00:45:08.570
Anthony Taylor: effectively, 49%.

751
00:45:10.010 --> 00:45:11.930
Anthony Taylor: Okay. So we're saying.

752
00:45:12.250 --> 00:45:13.350
Anthony Taylor: sports.

753
00:45:16.520 --> 00:45:18.560
Anthony Taylor: Anybody, remember what topic one was.

754
00:45:20.200 --> 00:45:20.830
Clayton Graves: Rattle.

755
00:45:22.150 --> 00:45:22.900
Anthony Taylor: No.

756
00:45:24.160 --> 00:45:30.109
Anthony Taylor: it was. Is it okay for a young 30? Whatever young girl to marry, whatever.

757
00:45:30.920 --> 00:45:31.730
Baro, Sonja: Entertainment.

758
00:45:32.400 --> 00:45:34.440
Anthony Taylor: Yeah, definitely wouldn't drought.

759
00:45:34.950 --> 00:45:36.670
Anthony Taylor: I didn't say these were perfect.

760
00:45:38.950 --> 00:45:43.560
Anthony Taylor: interestingly, though. No, when what does it say for 6? It's like.

761
00:45:43.970 --> 00:45:44.840
Anthony Taylor: no way.

762
00:45:45.080 --> 00:45:47.500
Anthony Taylor: but I can't know that there's no way you can know that

763
00:45:47.560 --> 00:45:50.810
Anthony Taylor: right? It doesn't know. It's just it's put it in that topic.

764
00:45:51.130 --> 00:45:54.650
Anthony Taylor: Which does that mean that it's wrong, or that we are wrong.

765
00:45:58.790 --> 00:46:04.249
Anthony Taylor: but we'd have to like, run our whole model and look at everything that falls into topic, too.

766
00:46:04.290 --> 00:46:05.710
Anthony Taylor: and see

767
00:46:06.300 --> 00:46:10.270
Anthony Taylor: if that's I mean it. Maybe we just misclassified

768
00:46:10.380 --> 00:46:11.540
Anthony Taylor: topic 2,

769
00:46:12.250 --> 00:46:18.059
Anthony Taylor: maybe it topic 2 shouldn't be sports. Maybe it should be lifestyle or entertainment or

770
00:46:18.420 --> 00:46:20.080
Anthony Taylor: stupid TV shows.

771
00:46:20.630 --> 00:46:35.070
Baro, Sonja: So, Anthony, is. Is this an example of where? I don't know if you've noticed, but sometimes like it'll when you go on a Netflix, or what? Pick your favorite streaming, and you classifies a movie

772
00:46:35.310 --> 00:46:40.880
Baro, Sonja: into a category that seems completely wrong.

773
00:46:40.910 --> 00:46:43.829
Baro, Sonja: like imitation game into common.

774
00:46:43.830 --> 00:46:45.719
Anthony Taylor: Could be, I doubt.

775
00:46:46.130 --> 00:46:47.140
Anthony Taylor: I mean.

776
00:46:47.270 --> 00:46:49.080
Anthony Taylor: so well.

777
00:46:49.830 --> 00:46:51.990
Anthony Taylor: I'm not gonna say it's impossible.

778
00:46:52.070 --> 00:46:56.520
Anthony Taylor: What I would say is that most movies come with a description.

779
00:46:56.830 --> 00:47:01.130
Anthony Taylor: So it's pretty unlikely that you would have to run something like this on that

780
00:47:01.320 --> 00:47:05.089
Anthony Taylor: right? This is more. I mean, this actually makes sense for like

781
00:47:05.280 --> 00:47:08.920
Anthony Taylor: a huge corpus of of articles. Or

782
00:47:09.150 --> 00:47:10.920
Anthony Taylor: you know, I mean, you could

783
00:47:11.000 --> 00:47:14.400
Anthony Taylor: technically even do this like the inauguration speeches.

784
00:47:14.490 --> 00:47:20.210
Anthony Taylor: Right? You could say what topics were each inauguration speech covering over, you know, 52 present.

785
00:47:20.490 --> 00:47:26.309
Anthony Taylor: right? And and maybe get. But again, a human has to come up with topics.

786
00:47:26.530 --> 00:47:28.809
Anthony Taylor: All this is going to do is give you

787
00:47:29.010 --> 00:47:32.859
Anthony Taylor: a a list of words to kind of base that topic

788
00:47:32.890 --> 00:47:34.180
Anthony Taylor: choice from

789
00:47:34.990 --> 00:47:39.950
Anthony Taylor: alright. It's still cool, and it's still very, very helpful.

790
00:47:41.590 --> 00:47:42.620
Anthony Taylor: Just yeah.

791
00:47:42.730 --> 00:47:45.511
Anthony Taylor: Okay. So we got that. What do we got here?

792
00:47:45.930 --> 00:47:49.219
Anthony Taylor: get the topic with the highest probability. I know. That's 2.

793
00:47:50.530 --> 00:47:53.719
Anthony Taylor: Alright. So we're gonna read in our original ones.

794
00:47:53.880 --> 00:47:57.369
Anthony Taylor: We're gonna grab the first 20.

795
00:47:58.813 --> 00:48:02.800
Anthony Taylor: Combine the original data with the topic label. Okay.

796
00:48:02.900 --> 00:48:04.489
Anthony Taylor: so let's see how it did.

797
00:48:06.640 --> 00:48:09.140
Anthony Taylor: So it said, sports

798
00:48:11.650 --> 00:48:12.860
Anthony Taylor: sports.

799
00:48:13.740 --> 00:48:18.679
Anthony Taylor: Taylor Swift dances when no one can see her in new, delicate video. That's entertainment.

800
00:48:19.440 --> 00:48:20.890
Anthony Taylor: I would say. Cheers.

801
00:48:20.890 --> 00:48:23.300
Clayton Graves: With category.

802
00:48:23.300 --> 00:48:24.279
Anthony Taylor: I don't.

803
00:48:24.280 --> 00:48:27.809
Clayton Graves: Number. It's categorized as sports, but I think that should be lifestyle.

804
00:48:28.410 --> 00:48:32.950
Anthony Taylor: I agree? Oh, no! What was for politics? Oh, that's hilarious!

805
00:48:33.040 --> 00:48:35.739
Anthony Taylor: How to say cheers in 20 language.

806
00:48:36.090 --> 00:48:37.410
Anthony Taylor: Politics!

807
00:48:38.160 --> 00:48:42.520
Anthony Taylor: Welcome to hell, real police wearing a camp. That's 7. That was sports, I think.

808
00:48:44.460 --> 00:48:45.849
Anthony Taylor: Nope, technology.

809
00:48:47.900 --> 00:48:48.670
Anthony Taylor: And

810
00:48:49.757 --> 00:48:56.999
Anthony Taylor: conservative pundit points out where real blame for gops descent into madness lies entertainment.

811
00:49:00.000 --> 00:49:04.249
Anthony Taylor: We asked the American public to settle 5. Internet's dumbest debates. What's 5

812
00:49:05.700 --> 00:49:07.540
Anthony Taylor: business? Yeah.

813
00:49:08.180 --> 00:49:10.120
Anthony Taylor: Somebody's getting the business

814
00:49:10.400 --> 00:49:16.110
Anthony Taylor: team moms, Oj's caitlin, Lowell heads to treatment over suicidal thoughts.

815
00:49:16.750 --> 00:49:17.970
Anthony Taylor: sports.

816
00:49:19.270 --> 00:49:22.920
Anthony Taylor: I think we've definitely miss caught this this categorize

817
00:49:22.970 --> 00:49:24.110
Anthony Taylor: topic 2.

818
00:49:24.310 --> 00:49:26.160
Anthony Taylor: Okay. In fact.

819
00:49:26.410 --> 00:49:30.970
Anthony Taylor: I would argue, based on everything that it picked for topic 2.

820
00:49:31.850 --> 00:49:32.950
Anthony Taylor: This is

821
00:49:35.120 --> 00:49:36.350
Anthony Taylor: entertainment.

822
00:49:36.560 --> 00:49:37.870
Anthony Taylor: lifestyle.

823
00:49:38.990 --> 00:49:40.120
Clayton Graves: Their lifestyle.

824
00:49:40.860 --> 00:49:41.640
Anthony Taylor: Yeah.

825
00:49:42.120 --> 00:49:45.799
Anthony Taylor: clearly, it's not sports. It didn't get a single one of them right?

826
00:49:46.970 --> 00:49:50.680
Anthony Taylor: I mean, this is probably the only one in there that had anything to do with sports.

827
00:49:54.190 --> 00:49:55.200
Anthony Taylor: Okay.

828
00:49:55.610 --> 00:49:58.580
Anthony Taylor: well, here, let's look at another, another 10 of them.

829
00:49:59.240 --> 00:50:04.489
Anthony Taylor: So these are 33 best iconic foods. Oh, wait! What was 3. Was that food?

830
00:50:06.730 --> 00:50:08.310
Anthony Taylor: Food? Huh?

831
00:50:09.440 --> 00:50:13.369
Anthony Taylor: I mean the fact that it has the word food in it.

832
00:50:16.380 --> 00:50:17.910
Anthony Taylor: marketing plan.

833
00:50:18.560 --> 00:50:22.150
Anthony Taylor: summer fancy food show. There's the word food again.

834
00:50:23.580 --> 00:50:24.960
Anthony Taylor: No twos at all.

835
00:50:26.750 --> 00:50:31.470
Anthony Taylor: Food again. Wow! It's really good at getting food when the word food is in it.

836
00:50:32.640 --> 00:50:34.299
Clayton Graves: Yeah, but it missed the cheeses.

837
00:50:35.550 --> 00:50:36.929
Anthony Taylor: It sure did. Didn't.

838
00:50:37.700 --> 00:50:39.260
Baro, Sonja: And the first night.

839
00:50:39.580 --> 00:50:41.670
Baro, Sonja: knowing where you are, first bite.

840
00:50:43.500 --> 00:50:44.990
Anthony Taylor: Okay. So

841
00:50:45.890 --> 00:50:54.530
Anthony Taylor: I don't want you to get discouraged by this, because it did do what we asked it to do. We said, Take all of these this huge

842
00:50:54.980 --> 00:50:56.919
Anthony Taylor: amount of words

843
00:50:57.300 --> 00:51:00.190
Anthony Taylor: and categorize them or not, categorize them.

844
00:51:00.200 --> 00:51:02.570
Anthony Taylor: bust them up into multiple

845
00:51:02.630 --> 00:51:08.509
Anthony Taylor: segments, and then we name the segments clearly. We named them wrong, or it did a really bad job.

846
00:51:08.990 --> 00:51:14.100
Anthony Taylor: Alright. But I don't see any of them right? So I'm gonna guess

847
00:51:14.200 --> 00:51:17.040
Anthony Taylor: that we just miss topicked them.

848
00:51:17.490 --> 00:51:18.550
Anthony Taylor: Okay.

849
00:51:18.720 --> 00:51:20.659
Clayton Graves: We're we're looking at this.

850
00:51:21.530 --> 00:51:26.350
Clayton Graves: What? How would you determine if you didn't have enough topics or too many topics?

851
00:51:27.710 --> 00:51:29.079
Anthony Taylor: If they're just wrong.

852
00:51:30.220 --> 00:51:33.669
Anthony Taylor: you would literally look at what what you're seeing.

853
00:51:33.900 --> 00:51:40.639
Anthony Taylor: And I mean, like, this one's clearly wrong. So what I would probably do next. If this were me, I'd probably throw this in a table

854
00:51:40.770 --> 00:51:48.640
Anthony Taylor: and then start filtering. Hey? Let's look at all of the twos, and let's see if there's any common theme there, maybe all of the twos. Maybe it's

855
00:51:48.890 --> 00:51:50.120
Anthony Taylor: properly

856
00:51:50.290 --> 00:51:52.469
Anthony Taylor: busting them up into a topic.

857
00:51:52.550 --> 00:51:54.280
Anthony Taylor: We just mislabeled the top

858
00:51:54.760 --> 00:51:59.960
Anthony Taylor: right or how would you know if you have too many like?

859
00:52:00.680 --> 00:52:06.599
Anthony Taylor: Let let's go back to the food one. So let's say, you know, it's like nailing. It's like

860
00:52:06.690 --> 00:52:11.039
Anthony Taylor: it gets like half the food. One's right, and then the other half, you know.

861
00:52:11.070 --> 00:52:16.870
Anthony Taylor: are in a whole nother topic. But we can clearly see their food. Well, maybe we need to make one less topic.

862
00:52:16.880 --> 00:52:19.200
Anthony Taylor: So all of those food ones come together

863
00:52:19.390 --> 00:52:20.070
Anthony Taylor: mean

864
00:52:20.330 --> 00:52:25.520
Anthony Taylor: right? But we don't know that again. You'd have to run your model and see if it brought those words together.

865
00:52:25.800 --> 00:52:27.140
Anthony Taylor: Right? Yeah, Derek.

866
00:52:28.580 --> 00:52:29.800
Derek Rikke: Could you do

867
00:52:29.970 --> 00:52:33.970
Derek Rikke: some kind of like elbow curve, looking at the probabilities

868
00:52:35.230 --> 00:52:36.189
Derek Rikke: because, like the probability.

869
00:52:36.190 --> 00:52:37.080
Anthony Taylor: Not so much.

870
00:52:37.080 --> 00:52:38.409
Derek Rikke: 49%,

871
00:52:38.680 --> 00:52:39.889
Derek Rikke: which seems right.

872
00:52:42.620 --> 00:52:44.459
Anthony Taylor: Yeah. Well, hmm.

873
00:52:45.420 --> 00:52:53.410
Anthony Taylor: I I don't know for sure if you get like, I said, I personally use this one. I'm not aware of an elbow cart for this, because Elbert elbow curb

874
00:52:53.800 --> 00:52:57.550
Anthony Taylor: alright, I wanna hear what Jennifer has to say about this. Let's see. Go, Jen.

875
00:52:57.800 --> 00:52:58.813
Jennifer Dahlgren: Another question.

876
00:52:59.440 --> 00:53:03.070
Anthony Taylor: Darn it, let's hope it is the elbow curve. Well, then, let me finish the elbow curve coming.

877
00:53:03.240 --> 00:53:08.169
Anthony Taylor: I don't know that it would work cause the elbow curve is looking for is trying different

878
00:53:08.380 --> 00:53:14.439
Anthony Taylor: clustering, and it's basing it. I mean, the one thing I don't see in this is a score

879
00:53:16.470 --> 00:53:19.050
Anthony Taylor: right. You don't see an accuracy score here.

880
00:53:19.730 --> 00:53:22.590
Derek Rikke: Could you use the probability as this kind of score, though.

881
00:53:22.590 --> 00:53:24.380
Anthony Taylor: I mean you you you

882
00:53:24.430 --> 00:53:25.630
Anthony Taylor: could

883
00:53:26.160 --> 00:53:28.429
Anthony Taylor: I mean you could say well.

884
00:53:29.640 --> 00:53:34.939
Anthony Taylor: I would think that there is pro. You know what. Here's what I would say, and this is just off the top of my head.

885
00:53:35.610 --> 00:53:39.730
Anthony Taylor: because we have all of these arrays with 7 probability scores in it.

886
00:53:39.840 --> 00:53:41.250
Anthony Taylor: You could

887
00:53:42.320 --> 00:53:46.740
Anthony Taylor: probably come up with either an algorithm or just some math

888
00:53:46.830 --> 00:53:48.189
Anthony Taylor: to go. You know what?

889
00:53:48.330 --> 00:53:49.350
Anthony Taylor: We have

890
00:53:50.300 --> 00:53:51.360
Anthony Taylor: 6

891
00:53:51.450 --> 00:53:52.740
Anthony Taylor: clear

892
00:53:53.840 --> 00:53:59.789
Anthony Taylor: groups out of all of these. So like you could say, Look, we've got, you know, probability our topic to has.

893
00:54:00.020 --> 00:54:03.680
Anthony Taylor: you know, 500 probabilities of 50 or better

894
00:54:03.960 --> 00:54:09.909
Anthony Taylor: right and and and do something like that. And then you could say, Well, look, there's really only 4 topics here.

895
00:54:10.290 --> 00:54:13.279
Anthony Taylor: you know these other ones. The probabilities are really low.

896
00:54:14.260 --> 00:54:21.190
Anthony Taylor: so perhaps we should do less topics. I'm sure there's a way to do it, and I'm sure if you use this a lot.

897
00:54:21.390 --> 00:54:24.819
Anthony Taylor: you would come up with what? Okay, Jen, go for it.

898
00:54:25.550 --> 00:54:32.190
Jennifer Dahlgren: No, I was. I was just curious when you would go back to like the top 20 words for each topic.

899
00:54:32.230 --> 00:54:46.070
Jennifer Dahlgren: and maybe you would change and include on the topic to include, like as a stopword, for instance, cause it's not adding anything to the model, and it's probably acting as a deterrent.

900
00:54:46.200 --> 00:54:47.170
Jennifer Dahlgren: So

901
00:54:47.290 --> 00:54:51.210
Jennifer Dahlgren: which could you? Could you start to do that kind of stuff to it to make it better.

902
00:54:51.810 --> 00:54:52.980
Anthony Taylor: I I

903
00:54:53.680 --> 00:55:03.740
Anthony Taylor: you could absolutely do it with stop. I don't know if we can manually manipulate these outside of that, but when you look at. See? It's kind of funny when we look at Topic 2,

904
00:55:04.050 --> 00:55:05.260
Anthony Taylor: the words

905
00:55:05.600 --> 00:55:07.389
Anthony Taylor: I would have said, sport, too.

906
00:55:08.031 --> 00:55:11.880
Anthony Taylor: There's Nfl. There's player, there's football, there's great

907
00:55:12.450 --> 00:55:15.860
Anthony Taylor: right? Soccer players

908
00:55:16.540 --> 00:55:17.690
Anthony Taylor: police

909
00:55:19.050 --> 00:55:20.760
Anthony Taylor: the word sports

910
00:55:21.300 --> 00:55:21.780
Anthony Taylor: right?

911
00:55:21.780 --> 00:55:27.193
Meredith McCanse (she/her): But then look at the words for topic 7 that got assigned to technology.

912
00:55:28.280 --> 00:55:29.120
Meredith McCanse (she/her): It's.

913
00:55:29.120 --> 00:55:30.290
Anthony Taylor: Day. Apple.

914
00:55:33.380 --> 00:55:35.670
Anthony Taylor: Yeah, I don't see much else. Iphone

915
00:55:35.980 --> 00:55:36.860
Anthony Taylor: watch.

916
00:55:39.260 --> 00:55:40.350
Anthony Taylor: Amazon.

917
00:55:41.140 --> 00:55:42.740
Anthony Taylor: Yeah, that

918
00:55:43.800 --> 00:55:45.130
Anthony Taylor: I don't know what that would be.

919
00:55:45.970 --> 00:55:54.690
Anthony Taylor: I could see this falling see? And maybe and you know what Derek, maybe, or or anybody really, when you look at these words, if if there's like.

920
00:55:54.780 --> 00:55:57.599
Anthony Taylor: if you look at this, and all of these are sports.

921
00:55:57.890 --> 00:56:04.980
Anthony Taylor: and this and all of these are, and this and all of these are sports. Then you could pretty much easily say, I got too many times

922
00:56:06.040 --> 00:56:07.010
Anthony Taylor: right.

923
00:56:07.928 --> 00:56:10.969
Anthony Taylor: Or there's like no relationship.

924
00:56:12.000 --> 00:56:13.440
Anthony Taylor: Maybe you don't have enough.

925
00:56:13.750 --> 00:56:15.370
Anthony Taylor: or you know, you see.

926
00:56:16.670 --> 00:56:18.300
Anthony Taylor: like this one, I mean.

927
00:56:18.440 --> 00:56:21.639
Anthony Taylor: 4 wasn't even politics, was it? It was 6.

928
00:56:22.180 --> 00:56:23.340
Anthony Taylor: What was for

929
00:56:24.130 --> 00:56:26.400
Anthony Taylor: politics? 6 was entertain.

930
00:56:27.630 --> 00:56:28.999
Anthony Taylor: That's kind of funny.

931
00:56:29.200 --> 00:56:30.040
Anthony Taylor: Oh.

932
00:56:30.240 --> 00:56:32.740
Anthony Taylor: and I mean in this. So 4 makes sense.

933
00:56:33.680 --> 00:56:36.359
Anthony Taylor: right? But I mean, look at 6.

934
00:56:43.630 --> 00:56:47.859
Anthony Taylor: I don't know. Awful lot of pilots political words in there.

935
00:56:49.070 --> 00:56:50.850
Anthony Taylor: or political names.

936
00:56:52.080 --> 00:56:54.509
Anthony Taylor: So I guess ultimately, guys

937
00:56:55.200 --> 00:56:57.240
Anthony Taylor: what Lda comes down to is

938
00:56:57.680 --> 00:57:01.100
Anthony Taylor: how you utilize these, how you name these topics.

939
00:57:01.410 --> 00:57:07.609
Anthony Taylor: and if these word sets make sense, I I agree with Jen. Stop words, for things like like

940
00:57:07.660 --> 00:57:10.149
Anthony Taylor: that'd be an easy one to get rid of

941
00:57:10.300 --> 00:57:19.390
Anthony Taylor: even stuff like like descriptive words like, like, you know, our adjective type words right? Better, best. Good. What? What's that really doing?

942
00:57:22.650 --> 00:57:23.440
Anthony Taylor: Yeah.

943
00:57:26.060 --> 00:57:27.419
Anthony Taylor: was that I heard it.

944
00:57:27.420 --> 00:57:34.030
Meredith McCanse (she/her): The word says or state. Yeah, like in topic number 4, the second word.

945
00:57:34.600 --> 00:57:36.719
Anthony Taylor: Oh, say, yeah. Oh, yeah, what's that? Do?

946
00:57:37.640 --> 00:57:39.510
Anthony Taylor: Right? And then what?

947
00:57:40.210 --> 00:57:41.260
Anthony Taylor: Okay?

948
00:57:41.340 --> 00:57:51.259
Anthony Taylor: There's there's not a lot in. So anyway, definitely, room to tune. And the the idea here guys understand that we can create a model.

949
00:57:51.350 --> 00:57:54.230
Anthony Taylor: an Nlp model that will take

950
00:57:54.770 --> 00:57:57.250
Anthony Taylor: words, sentences

951
00:57:57.260 --> 00:58:00.140
Anthony Taylor: and try to sort them into groups

952
00:58:00.320 --> 00:58:01.989
Anthony Taylor: that we can then later.

953
00:58:02.520 --> 00:58:04.749
Anthony Taylor: That's the point. That's it.

954
00:58:11.480 --> 00:58:14.689
Anthony Taylor: I'm trying to decide. If I want to make you guys do this exercise.

955
00:58:17.320 --> 00:58:18.780
Anthony Taylor: it's it's

956
00:58:19.550 --> 00:58:20.640
Anthony Taylor: a lot.

957
00:58:21.490 --> 00:58:23.640
Anthony Taylor: You do have 20 min do it.

958
00:58:26.020 --> 00:58:29.540
Anthony Taylor: but I'm leaning towards

959
00:58:31.120 --> 00:58:32.879
Anthony Taylor: just reviewing it.

960
00:58:33.320 --> 00:58:37.310
Anthony Taylor: cause it's so similar to the other one and then moving on. Next thing. What do you guys want to do?

961
00:58:37.550 --> 00:58:41.200
Anthony Taylor: I'll take a boat. Does anybody wanna actually go do this in breakout?

962
00:58:41.340 --> 00:58:41.890
Anthony Taylor: It.

963
00:58:41.890 --> 00:58:52.610
Dipinto, Matt: Does seem like it's going to be a lot more interesting than the headline characterization, because they're actual articles. So there's more words in them to actually be able to like.

964
00:58:52.610 --> 00:58:55.160
Anthony Taylor: The style. Yeah.

965
00:59:04.660 --> 00:59:07.670
Anthony Taylor: basically, what's happening for those that are curious.

966
00:59:08.050 --> 00:59:10.080
Anthony Taylor: Our exercises leader

967
00:59:11.090 --> 00:59:15.929
Anthony Taylor: require us to create a model that takes almost an hour to train.

968
00:59:18.650 --> 00:59:22.469
Anthony Taylor: so so they were very nice, and they gave us the model saved.

969
00:59:23.110 --> 00:59:28.039
Anthony Taylor: But you have to open them with the same version of Tensorflow that they were saved in.

970
00:59:28.690 --> 00:59:33.390
Anthony Taylor: and they didn't tell me what version of tensorflow that they saved them in.

971
00:59:33.550 --> 00:59:34.939
Anthony Taylor: So I have to keep

972
00:59:35.260 --> 00:59:37.639
Anthony Taylor: decrementing. My, so my

973
00:59:39.220 --> 00:59:40.600
Anthony Taylor: tensorflow

974
00:59:44.970 --> 00:59:49.900
Anthony Taylor: and then trying to run it and see if it fixes it.

975
00:59:55.600 --> 00:59:57.350
Anthony Taylor: So we shall see.

976
01:00:00.470 --> 01:00:01.330
Anthony Taylor: Hold on.

977
01:00:01.930 --> 01:00:03.130
Anthony Taylor: kind of stop that.

978
01:00:06.560 --> 01:00:07.230
Anthony Taylor: Okay.

979
01:00:09.000 --> 01:00:13.020
Anthony Taylor: so hopefully, we get to see that entire exercise, but.

980
01:00:13.020 --> 01:00:15.190
Dipinto, Matt: It was trained in 2, 14.

981
01:00:16.590 --> 01:00:17.760
Anthony Taylor: It was not the.

982
01:00:18.220 --> 01:00:24.999
Dipinto, Matt: It says it was right in the model itself. If you just open it as a text file, it's got some plain text start so it might just be broken, broken.

983
01:00:25.970 --> 01:00:30.090
Anthony Taylor: It could just be broken, cause I've tried 2, 14. That's the first one I tried.

984
01:00:31.230 --> 01:00:32.060
Anthony Taylor: So

985
01:00:42.890 --> 01:00:44.649
Anthony Taylor: notepad was a bad choice.

986
01:00:57.770 --> 01:01:02.040
Anthony Taylor: Okay, that's cure us, not tensorflow. However.

987
01:01:02.130 --> 01:01:03.630
Anthony Taylor: it's a good guess that

988
01:01:05.070 --> 01:01:06.630
Anthony Taylor: wonder

989
01:01:08.450 --> 01:01:15.190
Anthony Taylor: I might try decrementing curios. I did notice that it was curios 2.1 4, but I didn't think to change curios. Just tensorflow

990
01:01:16.660 --> 01:01:20.480
Anthony Taylor: might try that, or as you want to try it, James, I don't know what number you're on.

991
01:01:22.310 --> 01:01:26.430
James Torres: So I was just trying to. I was just trying to make it current. But it

992
01:01:26.890 --> 01:01:28.760
James Torres: doesn't seem to be working.

993
01:01:29.400 --> 01:01:31.739
Anthony Taylor: It'll run takes like an hour.

994
01:01:32.750 --> 01:01:36.160
Anthony Taylor: So at least the one that that I was working on earlier.

995
01:01:36.530 --> 01:01:40.129
Anthony Taylor: Alright, let's get back to it.

996
01:01:40.970 --> 01:01:42.909
Anthony Taylor: The we need

997
01:01:45.200 --> 01:01:46.070
Anthony Taylor: that one.

998
01:01:47.540 --> 01:01:49.330
Anthony Taylor: Okay.

999
01:01:49.500 --> 01:01:50.420
Anthony Taylor: so

1000
01:01:50.890 --> 01:01:57.900
Anthony Taylor: now we got another topic modeling model. This one's called the non-negative matrix factorization.

1001
01:02:00.200 --> 01:02:01.830
Anthony Taylor: Okay, I know.

1002
01:02:03.490 --> 01:02:04.430
Anthony Taylor: so

1003
01:02:04.860 --> 01:02:08.789
Anthony Taylor: with this, the biggest difference in this one is the last one

1004
01:02:09.291 --> 01:02:18.779
Anthony Taylor: was not using. Tf id. This one actually uses the tm, pf, id so term frequency across the board.

1005
01:02:19.040 --> 01:02:20.870
Anthony Taylor: Okay, so

1006
01:02:21.140 --> 01:02:22.510
Anthony Taylor: let me get the.

1007
01:02:27.720 --> 01:02:31.839
Anthony Taylor: I know it breaks it into smaller matrixes.

1008
01:02:31.930 --> 01:02:34.189
Anthony Taylor: Well, this first one does. Oh.

1009
01:02:34.330 --> 01:02:39.040
Anthony Taylor: too far. The first one does everything into that. Dtm.

1010
01:02:39.510 --> 01:02:43.959
Anthony Taylor: this guy is going to do it a little bit different. Here we go.

1011
01:02:44.380 --> 01:02:46.750
Anthony Taylor: So it's using the whole Tf idf

1012
01:02:49.530 --> 01:02:54.420
Anthony Taylor: to do its thing creates the 2 smaller matrixes.

1013
01:02:56.150 --> 01:03:06.039
Anthony Taylor: Yeah. So we start off with documents and terms and vectors. Then it's going to. When we apply this, it's going to create a

1014
01:03:07.485 --> 01:03:10.010
Anthony Taylor: words, topics and and documents.

1015
01:03:11.340 --> 01:03:12.130
Anthony Taylor: Topics.

1016
01:03:12.630 --> 01:03:13.730
Anthony Taylor: Vectors.

1017
01:03:14.220 --> 01:03:15.170
Anthony Taylor: Okay?

1018
01:03:15.320 --> 01:03:19.489
Anthony Taylor: So it just creates 2 smaller matrices

1019
01:03:19.630 --> 01:03:21.909
Anthony Taylor: to do its magic.

1020
01:03:22.290 --> 01:03:26.799
Anthony Taylor: Okay, the biggest difference between this one and the previous one.

1021
01:03:26.970 --> 01:03:32.810
Anthony Taylor: It's using. Tf, id. So in this case the output, you'll see a tuple.

1022
01:03:32.820 --> 01:03:42.940
Anthony Taylor: which is the the the row for each document. The second number represents the index of the word. And then the last number is the actual TF. Idf score.

1023
01:03:44.340 --> 01:03:45.300
Anthony Taylor: Okay.

1024
01:03:45.710 --> 01:03:47.369
Anthony Taylor: that's you're gonna see that

1025
01:03:48.260 --> 01:03:49.069
Anthony Taylor: really, really

1026
01:03:49.200 --> 01:03:49.860
Anthony Taylor: quick.

1027
01:03:51.010 --> 01:03:53.300
Anthony Taylor: Alright. So let's go through

1028
01:03:53.820 --> 01:03:55.199
Anthony Taylor: and knock this out.

1029
01:04:02.990 --> 01:04:05.309
Anthony Taylor: so here

1030
01:04:05.660 --> 01:04:10.130
Anthony Taylor: we're reading in the articles. This looks like the one we had earlier. Yes, it is.

1031
01:04:11.200 --> 01:04:17.709
Anthony Taylor: We're going to preprocess our text same way as we did in the other one. And that's the good news. A lot of this is the thing.

1032
01:04:17.850 --> 01:04:22.790
Anthony Taylor: Biggest difference. Right here, gonna use the Tf id vectorizer.

1033
01:04:24.090 --> 01:04:28.940
Anthony Taylor: Okay? And then we're gonna do a fit transform check out the shape.

1034
01:04:29.100 --> 01:04:32.340
Anthony Taylor: All this is telling us same thing as we did we got last time.

1035
01:04:32.550 --> 01:04:34.640
Anthony Taylor: except the difference is.

1036
01:04:34.690 --> 01:04:36.949
Anthony Taylor: is this time

1037
01:04:37.070 --> 01:04:40.840
Anthony Taylor: we're getting the Tf. Id. For each word

1038
01:04:41.840 --> 01:04:47.560
Anthony Taylor: alright. So once we have that we can do feature names out. These are going to look very, very similar

1039
01:04:48.450 --> 01:04:51.260
Anthony Taylor: to what we had earlier, except again.

1040
01:04:51.270 --> 01:04:54.210
Anthony Taylor: instead of house we have. Tf, id.

1041
01:04:55.760 --> 01:04:56.690
Anthony Taylor: hey?

1042
01:04:57.270 --> 01:04:59.699
Anthony Taylor: So to apply the Nmf model.

1043
01:04:59.880 --> 01:05:05.329
Anthony Taylor: everything's basically the same except for we're going to use Nmf instead of

1044
01:05:05.660 --> 01:05:07.549
Anthony Taylor: this is this is a little bad.

1045
01:05:07.850 --> 01:05:09.170
Anthony Taylor: And then.

1046
01:05:09.700 --> 01:05:10.710
Anthony Taylor: okay.

1047
01:05:11.110 --> 01:05:16.169
Anthony Taylor: same here we're gonna enumerate it. Take a look. Yep, everything looks good. There.

1048
01:05:16.270 --> 01:05:19.129
Anthony Taylor: let's look at the first one

1049
01:05:19.540 --> 01:05:21.460
Anthony Taylor: again. This is huge.

1050
01:05:21.990 --> 01:05:23.390
Anthony Taylor: Do a sort

1051
01:05:24.040 --> 01:05:28.929
Anthony Taylor: got an idea there. And now we can get the actual words.

1052
01:05:29.190 --> 01:05:33.820
Anthony Taylor: best world America, food, America's hotels, ordered worlds, restaurants, bars.

1053
01:05:36.810 --> 01:05:39.329
Anthony Taylor: Kathy! And his top 10 words for the first topic.

1054
01:05:39.650 --> 01:05:40.430
Clayton Graves: Travel.

1055
01:05:40.430 --> 01:05:41.290
Anthony Taylor: Alright.

1056
01:05:41.570 --> 01:05:43.239
Anthony Taylor: That looks like travel to me

1057
01:05:45.020 --> 01:05:46.160
Anthony Taylor: could be food

1058
01:05:46.870 --> 01:05:47.720
Anthony Taylor: and

1059
01:05:48.200 --> 01:05:51.230
Anthony Taylor: wait top 10 words from the indices.

1060
01:05:51.910 --> 01:05:52.640
Anthony Taylor: Okay.

1061
01:05:52.800 --> 01:05:56.780
Anthony Taylor: so top 30 words for each topic.

1062
01:05:58.020 --> 01:06:04.739
Anthony Taylor: Here we go again. So now we're gonna look at top playthings. Hotel Friday. Cheese, puffin clothes, foods, waze black.

1063
01:06:05.310 --> 01:06:07.200
Anthony Taylor: I don't know. Death match.

1064
01:06:10.020 --> 01:06:11.259
Anthony Taylor: That's a weird one.

1065
01:06:14.650 --> 01:06:18.290
Anthony Taylor: Breakfast chocolate fail, taste, coffee, Italian. Now.

1066
01:06:18.850 --> 01:06:20.250
Anthony Taylor: I'd say, that's for me.

1067
01:06:22.140 --> 01:06:31.730
Anthony Taylor: I was right to food and drink. So entertainment, technology, food and drink politics business. So again, guys, we've only changed like 2 things from what we just did. An hour ago.

1068
01:06:32.780 --> 01:06:33.680
Anthony Taylor: Alright

1069
01:06:34.468 --> 01:06:37.140
Anthony Taylor: here we're gonna transform.

1070
01:06:37.660 --> 01:06:43.460
Anthony Taylor: Get the shape. So again, you see, it's by topic and words, we have our sorted indices.

1071
01:06:44.650 --> 01:06:46.890
Anthony Taylor: Okay? Exciting.

1072
01:06:49.750 --> 01:06:53.209
Anthony Taylor: probability 22.

1073
01:06:53.820 --> 01:06:56.690
Anthony Taylor: It looks like it's gonna fall under. Well, they're sorted by that.

1074
01:06:56.710 --> 01:06:58.729
Anthony Taylor: So, topic 7. For that one.

1075
01:06:59.340 --> 01:07:02.509
Anthony Taylor: Here we can reload the articles

1076
01:07:02.960 --> 01:07:06.509
Anthony Taylor: and take a peek with just topic 7. What was 7

1077
01:07:07.810 --> 01:07:10.390
Anthony Taylor: travel still doesn't make sense.

1078
01:07:11.110 --> 01:07:13.559
Anthony Taylor: Now, this one kind of makes sense.

1079
01:07:13.740 --> 01:07:15.279
Anthony Taylor: That's also travel.

1080
01:07:16.600 --> 01:07:19.539
Anthony Taylor: No, I would think business based on what's up there.

1081
01:07:21.300 --> 01:07:24.540
Anthony Taylor: Taylor Swift dances is technology.

1082
01:07:25.120 --> 01:07:27.159
Anthony Taylor: Never mind. Okay?

1083
01:07:27.716 --> 01:07:29.750
Anthony Taylor: And then at the end.

1084
01:07:30.190 --> 01:07:31.750
Anthony Taylor: we get these cool ones here.

1085
01:07:34.320 --> 01:07:41.289
Anthony Taylor: That's so weird. So the these are the 33, 33 of the best, most iconic American foods

1086
01:07:41.350 --> 01:07:42.760
Anthony Taylor: fell under

1087
01:07:43.900 --> 01:07:45.100
Anthony Taylor: entertainment.

1088
01:07:48.090 --> 01:07:49.330
Anthony Taylor: Where do you guys want

1089
01:07:50.650 --> 01:07:52.880
Anthony Taylor: perfection? No.

1090
01:07:53.330 --> 01:07:54.530
Baro, Sonja: So is, that

1091
01:07:54.630 --> 01:08:01.209
Baro, Sonja: is that a difference? Because the thing we, one of the things we changed was the models model that we were using.

1092
01:08:02.010 --> 01:08:07.399
Anthony Taylor: Right, we definitely use a different model. And that's and it. And it measures everything slightly different. Yes.

1093
01:08:07.400 --> 01:08:12.496
Clayton Graves: Even even with a different model. These these really suck. So

1094
01:08:13.140 --> 01:08:13.980
Clayton Graves: what.

1095
01:08:14.420 --> 01:08:15.260
Baro, Sonja: I said right.

1096
01:08:15.260 --> 01:08:15.960
Anthony Taylor: So right.

1097
01:08:15.960 --> 01:08:17.540
Baro, Sonja: But so what do you do?

1098
01:08:17.540 --> 01:08:23.429
Clayton Graves: So I'm wondering if we mess with the number of topics and tweak the number of topics we might get

1099
01:08:23.540 --> 01:08:25.600
Clayton Graves: better results.

1100
01:08:27.710 --> 01:08:31.080
Anthony Taylor: I I still say the answer is, maybe, or

1101
01:08:31.560 --> 01:08:36.689
Anthony Taylor: you know, I think that Jen's point about changing some of the stop words is probably a big helper.

1102
01:08:39.380 --> 01:08:43.349
Anthony Taylor: th! There's a number of things that we could do to to tweak this.

1103
01:08:43.439 --> 01:08:48.190
Anthony Taylor: The the primary goal of today was to show you. This is possible.

1104
01:08:49.859 --> 01:08:56.470
Anthony Taylor: Okay, whether I don't believe you're gonna run into this again unless you choose

1105
01:08:56.600 --> 01:08:58.610
Anthony Taylor: to run into it again.

1106
01:09:01.279 --> 01:09:06.010
Anthony Taylor: yeah, they say, question, how do these results compare with Lda?

1107
01:09:06.710 --> 01:09:10.909
Anthony Taylor: Answer? Mms does a decent job, but doesn't

1108
01:09:10.950 --> 01:09:13.310
Anthony Taylor: quite hit the mark on many of them.

1109
01:09:14.100 --> 01:09:15.019
Anthony Taylor: I would say that.

1110
01:09:15.020 --> 01:09:18.680
Baro, Sonja: Yeah. The previous one, at least, was getting food

1111
01:09:19.140 --> 01:09:19.830
Baro, Sonja: right?

1112
01:09:19.830 --> 01:09:20.600
Anthony Taylor: Yeah.

1113
01:09:20.600 --> 01:09:23.240
Baro, Sonja: And there was food. They got that. Yeah.

1114
01:09:24.000 --> 01:09:27.879
Clayton Graves: Now, obviously, we're not going to go over additional

1115
01:09:28.040 --> 01:09:29.740
Clayton Graves: models. I don't think.

1116
01:09:29.740 --> 01:09:30.929
Anthony Taylor: Not tuning yet.

1117
01:09:30.939 --> 01:09:34.169
Clayton Graves: But are there additional models that might do better here.

1118
01:09:36.180 --> 01:09:42.749
Anthony Taylor: Okay. Again, as I said earlier, I made that disclaimer. This is not something that I've had to do.

1119
01:09:44.580 --> 01:09:46.530
Anthony Taylor: The short answer is.

1120
01:09:47.200 --> 01:09:49.400
Anthony Taylor: I would say, most likely. Yes.

1121
01:09:49.550 --> 01:09:55.099
Anthony Taylor: there are other models that do this. I mean, we could Google it. Find out in a few seconds. Let's do that.

1122
01:09:55.510 --> 01:09:57.179
Anthony Taylor: Let's do that.

1123
01:09:58.666 --> 01:10:00.760
Anthony Taylor: Models that

1124
01:10:01.510 --> 01:10:05.570
Anthony Taylor: wait models for topic modeling.

1125
01:10:05.590 --> 01:10:08.240
Anthony Taylor: My guess is, if I'm being honest.

1126
01:10:10.450 --> 01:10:13.689
Anthony Taylor: the knowing how a lot of this stuff is done.

1127
01:10:14.340 --> 01:10:16.359
Anthony Taylor: it's possible that they just

1128
01:10:16.780 --> 01:10:20.589
Anthony Taylor: they just didn't bother with like tuning it. It was. They're just trying to show you

1129
01:10:20.950 --> 01:10:22.749
Anthony Taylor: what can come of it.

1130
01:10:23.380 --> 01:10:23.960
Clayton Graves: Like.

1131
01:10:23.960 --> 01:10:24.790
Anthony Taylor: A

1132
01:10:26.160 --> 01:10:27.160
Anthony Taylor: sorry.

1133
01:10:27.160 --> 01:10:28.559
Clayton Graves: Kind of like the homework.

1134
01:10:29.830 --> 01:10:31.270
Anthony Taylor: Well, sometimes.

1135
01:10:31.830 --> 01:10:33.530
Anthony Taylor: sometime.

1136
01:10:34.300 --> 01:10:39.290
Anthony Taylor: Conceptually spurious words can appear, not because they're related. In other words.

1137
01:10:39.540 --> 01:10:42.349
Anthony Taylor: I can see if there's any mention of different models.

1138
01:10:42.780 --> 01:10:43.869
Clayton Graves: I'm going to go out, chat.

1139
01:10:43.870 --> 01:10:46.899
Anthony Taylor: This looks like a good explanation on how it works.

1140
01:10:47.310 --> 01:10:50.159
Clayton Graves: Now I gotta go ask Chat Gp what spurious means.

1141
01:10:51.930 --> 01:10:56.409
Anthony Taylor: Hey? Look, there's a data cap article on this with examples

1142
01:10:59.410 --> 01:11:01.130
Anthony Taylor: that damn data can't.

1143
01:11:03.550 --> 01:11:06.949
Anthony Taylor: So there's okay. Well, there's one right there that we haven't looked at LSE.

1144
01:11:07.920 --> 01:11:09.719
Anthony Taylor: We looked at Da.

1145
01:11:15.030 --> 01:11:17.660
Anthony Taylor: Here's the preprocessing steps.

1146
01:11:22.310 --> 01:11:25.949
Anthony Taylor: Yeah. So the short answer is, yes.

1147
01:11:26.930 --> 01:11:32.659
Anthony Taylor: you know, have we are. You're clearly not going to go through them all. The idea, like I said, the the

1148
01:11:32.840 --> 01:11:45.750
Anthony Taylor: 100% of the idea of this was simply to show you that this is a possibility to introduce you to that possibility and give you an opportunity to see it at work. Is it perfect? No, no model is perfect.

1149
01:11:45.800 --> 01:11:47.160
Anthony Taylor: Could it be better?

1150
01:11:47.300 --> 01:11:50.650
Anthony Taylor: 100%, yes. Could you make it better?

1151
01:11:50.880 --> 01:11:52.870
Anthony Taylor: Also a hundred percent? Yes.

1152
01:11:52.990 --> 01:11:58.579
Anthony Taylor: just with the things we talked about playing around with topics playing around with stop words.

1153
01:12:00.650 --> 01:12:07.449
Anthony Taylor: There's no doubt in my mind that you could get this better. Perfect. Yeah, I don't know that there is a perfect. At this point

1154
01:12:07.510 --> 01:12:10.010
Anthony Taylor: we're not at the point of perfect.

1155
01:12:10.150 --> 01:12:13.270
Anthony Taylor: We're at the point of you know what?

1156
01:12:14.130 --> 01:12:15.890
Anthony Taylor: Hold on. I'm gonna show you guys.

1157
01:12:15.890 --> 01:12:21.159
Clayton Graves: As we, as we demonstrated at the beginning of the class, humans can't get it perfect either.

1158
01:12:21.670 --> 01:12:22.300
Anthony Taylor: Exactly.

1159
01:12:22.300 --> 01:12:22.860
Baro, Sonja: Up, past.

1160
01:12:22.860 --> 01:12:26.449
Anthony Taylor: I want to show you guys. So this is gonna be.

1161
01:12:27.000 --> 01:12:35.250
Anthony Taylor: this is the lecture for Wednesday. I'm not going to show it all to you, but I want to show you where we are on the timeline. So back in the fifties

1162
01:12:35.360 --> 01:12:36.970
Anthony Taylor: started all this stuff.

1163
01:12:41.060 --> 01:12:45.199
Anthony Taylor: we're getting close to the early 2,000 s, now.

1164
01:12:47.060 --> 01:12:49.019
Anthony Taylor: okay, we're gonna cover

1165
01:12:49.090 --> 01:12:51.400
Anthony Taylor: this, even though that's the broken one.

1166
01:12:51.540 --> 01:12:53.399
Anthony Taylor: We're going to cover this today.

1167
01:12:54.030 --> 01:12:56.759
Anthony Taylor: So in the grand timeline of

1168
01:12:56.870 --> 01:13:01.309
Anthony Taylor: universe of AI and Nl, we're only in 2,007.

1169
01:13:03.360 --> 01:13:08.939
Anthony Taylor: Starting on Thursday. We're gonna jump forward to almost 2,020.

1170
01:13:10.230 --> 01:13:16.330
Anthony Taylor: Now, considering how fast all of this stuff grows. This is a tremendous leap

1171
01:13:16.360 --> 01:13:19.010
Anthony Taylor: from, and we could get it mostly right

1172
01:13:19.540 --> 01:13:22.250
Anthony Taylor: to. We're nailing this stuff now.

1173
01:13:23.850 --> 01:13:26.769
Anthony Taylor: Okay, so do keep that in mind

1174
01:13:27.570 --> 01:13:28.580
Anthony Taylor: cool.

1175
01:13:28.840 --> 01:13:32.349
Anthony Taylor: I can't believe how lucky I was that we just happened to be there.

1176
01:13:34.540 --> 01:13:35.500
Anthony Taylor: Love that.

1177
01:13:36.080 --> 01:13:38.830
Anthony Taylor: Does that make you feel any better anybody, anybody?

1178
01:13:40.380 --> 01:13:41.340
Anthony Taylor: Bye.

1179
01:13:41.650 --> 01:13:45.440
Anthony Taylor: alright. So this next one isn't everyone due?

1180
01:13:46.640 --> 01:13:47.830
Anthony Taylor: Okay?

1181
01:13:50.170 --> 01:13:51.680
Anthony Taylor: So

1182
01:13:52.660 --> 01:13:55.799
Anthony Taylor: fortunately it's not real long.

1183
01:14:02.690 --> 01:14:05.110
Anthony Taylor: stand by. I wanna make sure I got the right one. Okay.

1184
01:14:05.260 --> 01:14:06.110
Anthony Taylor: so

1185
01:14:06.340 --> 01:14:07.730
Anthony Taylor: let's get started.

1186
01:14:07.740 --> 01:14:09.379
Anthony Taylor: Let's run this guy.

1187
01:14:14.720 --> 01:14:16.970
Anthony Taylor: hey? You know what? Before I start this.

1188
01:14:20.000 --> 01:14:21.759
Anthony Taylor: I'm gonna try one more thing.

1189
01:14:23.660 --> 01:14:26.180
Anthony Taylor: I don't know if it'll let me do this, but

1190
01:14:30.180 --> 01:14:33.969
Anthony Taylor: I just can't get my mind off of this guys. I really want this to work for you.

1191
01:14:36.890 --> 01:14:37.750
Anthony Taylor: Alright.

1192
01:14:38.850 --> 01:14:39.730
Anthony Taylor: Okay?

1193
01:14:40.616 --> 01:14:44.429
Anthony Taylor: So we have this, we're gonna read in our news articles.

1194
01:14:45.330 --> 01:14:50.480
Anthony Taylor: So we're gonna do news articles underscore. Df, equals. Pd, dot read

1195
01:14:51.280 --> 01:14:53.220
Anthony Taylor: underscores

1196
01:14:53.740 --> 01:14:55.160
Anthony Taylor: Csv

1197
01:14:56.170 --> 01:14:57.020
Anthony Taylor: and do

1198
01:15:05.690 --> 01:15:09.220
Anthony Taylor: okay? And then take a peek at the first few road

1199
01:15:11.400 --> 01:15:12.140
Anthony Taylor: poop.

1200
01:15:12.300 --> 01:15:13.940
Anthony Taylor: Yay.

1201
01:15:16.340 --> 01:15:21.120
Anthony Taylor: we could check for no values. Now we're gonna do that with our info.

1202
01:15:25.400 --> 01:15:28.549
Anthony Taylor: We can see we have no nose. That was pretty easy.

1203
01:15:31.920 --> 01:15:33.570
Anthony Taylor: I am not.

1204
01:15:33.880 --> 01:15:35.440
Anthony Taylor: And to type all of that.

1205
01:15:36.320 --> 01:15:39.040
Anthony Taylor: So I will slack this out to you guys.

1206
01:15:50.830 --> 01:15:51.850
Anthony Taylor: there you go.

1207
01:15:57.360 --> 01:16:01.710
Anthony Taylor: So this is just gonna do the cleanup that we've been doing everywhere else.

1208
01:16:02.600 --> 01:16:04.030
Anthony Taylor: nicely done.

1209
01:16:04.820 --> 01:16:08.770
Anthony Taylor: Alright. So now we're gonna do our Tf, id vectorizer.

1210
01:16:09.220 --> 01:16:11.010
Anthony Taylor: So we're going to do

1211
01:16:11.210 --> 01:16:13.100
Anthony Taylor: TF,

1212
01:16:14.480 --> 01:16:17.639
Anthony Taylor: I'll get it right. I promise. Ivf, there we go.

1213
01:16:17.650 --> 01:16:19.429
Anthony Taylor: That actually, that's not all.

1214
01:16:20.160 --> 01:16:24.029
Anthony Taylor: Stand by. Create a variable for that. So TF. Idf

1215
01:16:24.130 --> 01:16:25.230
Anthony Taylor: equals.

1216
01:16:26.770 --> 01:16:30.710
Anthony Taylor: Tf, id vectorizer, we're gonna do a Max. Df.

1217
01:16:34.480 --> 01:16:35.950
Anthony Taylor: gur, okay.

1218
01:16:36.170 --> 01:16:38.050
Anthony Taylor: 0 point 9 5

1219
01:16:39.460 --> 01:16:41.230
Anthony Taylor: and a min.

1220
01:16:41.360 --> 01:16:42.400
Anthony Taylor: PF.

1221
01:16:43.380 --> 01:16:44.440
Anthony Taylor: 5,

1222
01:16:45.680 --> 01:16:49.659
Anthony Taylor: and stop words will be English

1223
01:16:52.800 --> 01:16:55.480
Anthony Taylor: A,

1224
01:16:58.830 --> 01:17:01.899
Anthony Taylor: and just dump that out. So we can make sure we did it

1225
01:17:03.970 --> 01:17:05.000
Anthony Taylor: looking good.

1226
01:17:06.680 --> 01:17:09.460
Anthony Taylor: Okay. So now we're gonna do our

1227
01:17:09.630 --> 01:17:11.550
Anthony Taylor: fit transform.

1228
01:17:11.760 --> 01:17:14.889
Anthony Taylor: So we're gonna do Dtm equals

1229
01:17:15.190 --> 01:17:19.450
Anthony Taylor: TFID f.it

1230
01:17:20.110 --> 01:17:25.729
Anthony Taylor: underscore transform and then pass in just our news articles.

1231
01:17:27.930 --> 01:17:29.669
Anthony Taylor: which are new, summary.

1232
01:17:30.110 --> 01:17:31.440
Anthony Taylor: very nice.

1233
01:17:31.720 --> 01:17:34.839
Anthony Taylor: And then let's print out shape and see what we have.

1234
01:17:41.530 --> 01:17:46.269
Anthony Taylor: So 2,000 third, 25 rows, 5,172. Unique words!

1235
01:17:47.410 --> 01:17:48.760
Anthony Taylor: Pretty exciting!

1236
01:17:50.600 --> 01:17:55.370
Anthony Taylor: so now we have that. Let's go ahead and start putting in our in an in F model.

1237
01:17:56.050 --> 01:17:58.120
Anthony Taylor: So we have an MF. Model.

1238
01:17:58.310 --> 01:17:59.370
Anthony Taylor: It was

1239
01:18:00.830 --> 01:18:02.250
Anthony Taylor: in

1240
01:18:02.580 --> 01:18:04.050
Anthony Taylor: MF.

1241
01:18:04.810 --> 01:18:08.249
Anthony Taylor: And then we're going to pass in the number of components.

1242
01:18:08.800 --> 01:18:10.780
Anthony Taylor: We'll start with 5,

1243
01:18:11.060 --> 01:18:14.420
Anthony Taylor: and then we're gonna do a random state. So we all see the same thing.

1244
01:18:14.600 --> 01:18:16.039
Anthony Taylor: 42.

1245
01:18:17.890 --> 01:18:19.940
Anthony Taylor: Okay, and then fit it

1246
01:18:23.960 --> 01:18:25.370
Anthony Taylor: with our Dtm.

1247
01:18:26.510 --> 01:18:27.360
Anthony Taylor: nay.

1248
01:18:27.980 --> 01:18:30.879
Anthony Taylor: let's do a quick link and see what we got.

1249
01:18:31.200 --> 01:18:36.259
Anthony Taylor: This is pretty much like, said, this is all the same stuff as we did earlier. We're just trying to

1250
01:18:38.900 --> 01:18:40.910
Anthony Taylor: give you guys the same

1251
01:18:41.220 --> 01:18:44.139
Anthony Taylor: again. Do we need all these steps new?

1252
01:18:44.780 --> 01:18:45.920
Anthony Taylor: We do not.

1253
01:18:46.200 --> 01:18:47.090
Anthony Taylor: But

1254
01:18:48.620 --> 01:18:55.490
Anthony Taylor: alright, I'm gonna go ahead and type this out as a little long. But this gives everybody some time to to go through this like one at a time.

1255
01:18:55.710 --> 01:18:57.039
Anthony Taylor: So we're going to do

1256
01:18:57.730 --> 01:18:59.130
Anthony Taylor: 2 variables

1257
01:18:59.390 --> 01:19:03.520
Anthony Taylor: because we're enumerating. We know about that done that.

1258
01:19:03.570 --> 01:19:06.750
Anthony Taylor: we're gonna grab the components from our

1259
01:19:06.880 --> 01:19:07.860
Anthony Taylor: model.

1260
01:19:08.860 --> 01:19:13.660
Anthony Taylor: Okay? So that'll give us all of the components coming out of our model.

1261
01:19:14.250 --> 01:19:15.930
Anthony Taylor: I gotta print

1262
01:19:16.942 --> 01:19:19.149
Anthony Taylor: the top 15 words

1263
01:19:23.100 --> 01:19:24.949
Anthony Taylor: for topic.

1264
01:19:25.030 --> 01:19:29.560
Anthony Taylor: And then, of course, we don't actually have a topic. So we're just gonna give it the number.

1265
01:19:29.780 --> 01:19:31.290
Anthony Taylor: And this will be

1266
01:19:32.100 --> 01:19:33.350
Anthony Taylor: index.

1267
01:19:34.240 --> 01:19:38.759
Anthony Taylor: plus what cause we're gonna do. 1, 2, 3, 4, 5 instead of 0. Blah, blah, blah.

1268
01:19:39.330 --> 01:19:40.310
Anthony Taylor: okay?

1269
01:19:40.930 --> 01:19:42.340
Anthony Taylor: And then

1270
01:19:42.530 --> 01:19:47.279
Anthony Taylor: we're gonna do print TFID f

1271
01:19:47.440 --> 01:19:50.029
Anthony Taylor: dot, you're gonna get the feature names.

1272
01:19:51.210 --> 01:19:55.080
Anthony Taylor: We're gonna get the first one. Well, we're gonna loop through them.

1273
01:19:55.180 --> 01:19:57.220
Anthony Taylor: So whichever loop we're in.

1274
01:19:57.860 --> 01:20:00.690
Anthony Taylor: Oh, we're doing a list comprehension. I missed my first break.

1275
01:20:02.100 --> 01:20:05.949
Anthony Taylor: You know what? I'm gonna start that line. Don't don't change your typing guys.

1276
01:20:07.040 --> 01:20:10.900
Anthony Taylor: Hold on. I wanna, I'm really liking teaching this comprehension this way.

1277
01:20:11.110 --> 01:20:14.760
Anthony Taylor: Hopefully, others agree. Cause I really like doing it this way. Now.

1278
01:20:14.980 --> 01:20:18.309
Anthony Taylor: So we have our list comprehension. We're gonna do

1279
01:20:18.900 --> 01:20:20.030
Anthony Taylor: 4.

1280
01:20:20.320 --> 01:20:22.340
Anthony Taylor: I is

1281
01:20:22.930 --> 01:20:26.280
Anthony Taylor: arc sort. Remember, that's our arrays order.

1282
01:20:26.540 --> 01:20:27.670
Anthony Taylor: Okay?

1283
01:20:27.770 --> 01:20:29.980
Anthony Taylor: And we're gonna grab.

1284
01:20:30.280 --> 01:20:32.430
Anthony Taylor: So we're doing descending

1285
01:20:33.670 --> 01:20:35.310
Anthony Taylor: 15.

1286
01:20:36.270 --> 01:20:38.839
Anthony Taylor: So this is, gonna give us our 15 words.

1287
01:20:39.220 --> 01:20:40.350
Anthony Taylor: Okay.

1288
01:20:41.600 --> 01:20:45.199
Anthony Taylor: once we have that, what are we gonna do with I?

1289
01:20:45.320 --> 01:20:46.880
Anthony Taylor: We're going to

1290
01:20:48.650 --> 01:20:49.820
Anthony Taylor: get

1291
01:20:51.900 --> 01:20:52.720
Anthony Taylor: care.

1292
01:20:55.260 --> 01:20:57.770
Anthony Taylor: I really like my auto fill sorry

1293
01:20:57.900 --> 01:20:59.240
Anthony Taylor: feature names out.

1294
01:20:59.280 --> 01:21:02.030
Anthony Taylor: open close bracket. I,

1295
01:21:02.320 --> 01:21:09.249
Anthony Taylor: okay, so this is, gonna go through the array, basically get the index. And this is, gonna give us the feature name

1296
01:21:09.340 --> 01:21:11.150
Anthony Taylor: for that index.

1297
01:21:11.180 --> 01:21:12.899
Anthony Taylor: Now, do I have a problem here?

1298
01:21:13.090 --> 01:21:16.350
Anthony Taylor: Oh, yeah, sorry. This needs to be topic

1299
01:21:17.190 --> 01:21:18.550
Anthony Taylor: dot arcs sort.

1300
01:21:19.480 --> 01:21:21.390
Anthony Taylor: Yeah. So we're using this value.

1301
01:21:23.490 --> 01:21:24.460
Anthony Taylor: Okay.

1302
01:21:25.780 --> 01:21:28.189
Anthony Taylor: Then print a new line just to keep it neat.

1303
01:21:29.610 --> 01:21:31.719
Anthony Taylor: New line is just like that.

1304
01:21:33.090 --> 01:21:35.329
Anthony Taylor: Everybody understand that now, more or less.

1305
01:21:36.550 --> 01:21:37.840
Anthony Taylor: let's run it.

1306
01:21:38.130 --> 01:21:43.230
Anthony Taylor: So there's our word. So government rise December company prices market.

1307
01:21:43.820 --> 01:21:44.730
Anthony Taylor: I don't know.

1308
01:21:45.290 --> 01:21:47.129
Anthony Taylor: Economics. What do you guys think

1309
01:21:48.750 --> 01:21:50.349
Anthony Taylor: I would say business.

1310
01:21:53.450 --> 01:21:55.049
Baro, Sonja: Oh, someone didn't work.

1311
01:21:56.360 --> 01:22:00.350
Clayton Graves: So the first one's business, the second one is entertainment.

1312
01:22:01.240 --> 01:22:03.859
Clayton Graves: third, one is politics.

1313
01:22:04.750 --> 01:22:06.639
Clayton Graves: fourth, one is sports.

1314
01:22:07.900 --> 01:22:09.569
Clayton Graves: fifth, one is technology.

1315
01:22:11.510 --> 01:22:13.020
Anthony Taylor: Anybody disagree with that

1316
01:22:14.560 --> 01:22:16.990
Anthony Taylor: you have while I'm typing it to disagree.

1317
01:22:17.690 --> 01:22:20.310
Meredith McCanse (she/her): I have pretty different words in the first one.

1318
01:22:21.160 --> 01:22:23.499
Anthony Taylor: Okay, you don't like business.

1319
01:22:24.030 --> 01:22:24.600
Anthony Taylor: Oh, yeah.

1320
01:22:24.600 --> 01:22:25.170
Meredith McCanse (she/her): However.

1321
01:22:25.170 --> 01:22:26.790
Anthony Taylor: Did you use your random state.

1322
01:22:27.340 --> 01:22:29.630
Meredith McCanse (she/her): Yeah, random state 42

1323
01:22:33.430 --> 01:22:34.860
Meredith McCanse (she/her): I have words like.

1324
01:22:34.920 --> 01:22:39.089
Meredith McCanse (she/her): well, like year growth sales bank oil.

1325
01:22:39.590 --> 01:22:41.950
Meredith McCanse (she/her): I mean, I guess it's similar.

1326
01:22:43.170 --> 01:22:48.109
Meredith McCanse (she/her): But like my top word isn't even a word. It's just the letter B, the letters BM.

1327
01:22:49.760 --> 01:22:50.450
Anthony Taylor: Okay.

1328
01:22:51.050 --> 01:22:51.737
Dipinto, Matt: Looks like you have.

1329
01:22:51.910 --> 01:22:53.320
Anthony Taylor: Like a good. Oh, no, it's right there.

1330
01:22:53.320 --> 01:22:54.950
Dipinto, Matt: The same list backwards.

1331
01:22:54.950 --> 01:22:56.790
Anthony Taylor: Is different. Yeah, did you.

1332
01:22:56.790 --> 01:22:57.280
Meredith McCanse (she/her): Oh!

1333
01:22:57.770 --> 01:23:01.000
Dipinto, Matt: numpy.org sort of negative topic.

1334
01:23:03.265 --> 01:23:03.680
Meredith McCanse (she/her): Death.

1335
01:23:05.770 --> 01:23:06.470
Anthony Taylor: Okay.

1336
01:23:06.610 --> 01:23:11.200
Anthony Taylor: anyway. So it it, the good news is, you got all the words.

1337
01:23:11.610 --> 01:23:13.080
Anthony Taylor: So we're okay there.

1338
01:23:13.440 --> 01:23:16.009
Anthony Taylor: sports and tech.

1339
01:23:16.780 --> 01:23:18.500
Anthony Taylor: Okay, I like it.

1340
01:23:21.456 --> 01:23:25.540
Anthony Taylor: So let's get our results

1341
01:23:27.750 --> 01:23:31.569
Anthony Taylor: and pop them into here. And then

1342
01:23:32.070 --> 01:23:35.470
Anthony Taylor: F model dot transform.

1343
01:23:35.500 --> 01:23:36.700
Anthony Taylor: Dtm.

1344
01:23:40.120 --> 01:23:44.459
Anthony Taylor: and we're gonna get the shape of these. I'm not sure why they keep doing the shape thing. I mean.

1345
01:23:44.780 --> 01:23:46.300
Anthony Taylor: We already know the shape.

1346
01:23:48.100 --> 01:23:52.419
Anthony Taylor: and we can see we have our 5 topics and all of our row. All of our articles

1347
01:23:52.800 --> 01:23:54.410
Anthony Taylor: read it in again.

1348
01:23:55.530 --> 01:23:59.049
Anthony Taylor: These are the labels I just did up above

1349
01:23:59.780 --> 01:24:01.750
Anthony Taylor: business entertainment.

1350
01:24:03.130 --> 01:24:08.989
Anthony Taylor: So this is basically what we did in the in the instructor example, we're gonna create this cool little dictionary

1351
01:24:09.130 --> 01:24:11.500
Anthony Taylor: and then use it to map

1352
01:24:15.513 --> 01:24:16.800
Anthony Taylor: our labels

1353
01:24:21.760 --> 01:24:23.230
Anthony Taylor: to our

1354
01:24:24.060 --> 01:24:24.970
Anthony Taylor: duff.

1355
01:24:38.060 --> 01:24:39.100
Anthony Taylor: Okay?

1356
01:24:40.580 --> 01:24:42.190
Anthony Taylor: Did some lead speed.

1357
01:24:43.500 --> 01:24:45.989
Anthony Taylor: Now, that wasn't lead speed, not even close.

1358
01:24:46.600 --> 01:24:47.720
Anthony Taylor: Okay.

1359
01:24:47.820 --> 01:24:51.910
Anthony Taylor: So to get our top 10, all we got to do

1360
01:24:52.460 --> 01:24:55.949
Anthony Taylor: is news articles DF. Underscore 2.

1361
01:24:57.270 --> 01:24:59.310
Anthony Taylor: And then we can do head. And

1362
01:25:00.230 --> 01:25:01.399
Anthony Taylor: and there we go.

1363
01:25:01.980 --> 01:25:07.489
Anthony Taylor: So how do we do? According to financial times, chief operator, kicking the tires for the video. Yeah, that's good.

1364
01:25:08.090 --> 01:25:12.150
Anthony Taylor: Sasha's predicting profits to rise. 50% is okay.

1365
01:25:13.060 --> 01:25:15.530
Anthony Taylor: If could cost 80.

1366
01:25:15.840 --> 01:25:17.300
Anthony Taylor: That's pounds. Yeah.

1367
01:25:17.320 --> 01:25:21.740
Anthony Taylor: to run Uk referendum on the Europe ministries revealed, Mr. Leslie could not be.

1368
01:25:23.210 --> 01:25:24.720
Anthony Taylor: I'd say, that's poly.

1369
01:25:27.170 --> 01:25:29.150
Anthony Taylor: Alright. This looks pretty good to me.

1370
01:25:37.940 --> 01:25:39.099
Anthony Taylor: What do you guys think?

1371
01:25:47.730 --> 01:25:49.010
Anthony Taylor: I think that looks good?

1372
01:25:50.050 --> 01:25:54.470
Anthony Taylor: Maybe it's just that first group of of stuff just stinks.

1373
01:25:54.470 --> 01:25:57.549
Clayton Graves: Yeah, maybe maybe the brits just got it better. I don't. Don't.

1374
01:26:00.510 --> 01:26:02.100
Anthony Taylor: I think it's more likely

1375
01:26:02.520 --> 01:26:07.039
Anthony Taylor: that first data set just isn't a good candidate for this.

1376
01:26:07.340 --> 01:26:09.670
Clayton Graves: I like my answer you very much.

1377
01:26:09.920 --> 01:26:13.520
Anthony Taylor: Well, you can. You have a right to like your answer better?

1378
01:26:14.130 --> 01:26:15.129
Anthony Taylor: I don't care.

1379
01:26:15.630 --> 01:26:17.480
Anthony Taylor: I like your answer, too.

1380
01:26:21.690 --> 01:26:22.979
Anthony Taylor: And then there's the pop.

1381
01:26:24.820 --> 01:26:27.500
Anthony Taylor: Yeah, I think these actually came out pretty good.

1382
01:26:28.320 --> 01:26:29.899
Anthony Taylor: I'm pretty pleased with that.

1383
01:26:30.270 --> 01:26:32.550
Anthony Taylor: Any questions about any of that.

1384
01:26:37.340 --> 01:26:38.810
Anthony Taylor: Okay? Then.

1385
01:26:42.290 --> 01:26:42.950
Anthony Taylor: huh?

1386
01:26:42.950 --> 01:26:44.189
Baro, Sonja: Yeah. Way, better?

1387
01:26:45.050 --> 01:26:48.259
Anthony Taylor: Is way better right? I mean, I would say, that's

1388
01:26:48.400 --> 01:26:49.840
Anthony Taylor: completely

1389
01:26:49.890 --> 01:26:50.990
Anthony Taylor: usable.

1390
01:26:55.970 --> 01:26:57.520
Anthony Taylor: Alright game.

1391
01:27:06.950 --> 01:27:09.460
Anthony Taylor: So let's talk about

1392
01:27:11.580 --> 01:27:12.969
Anthony Taylor: are in it.

1393
01:27:13.320 --> 01:27:14.279
Anthony Taylor: and can

1394
01:27:14.980 --> 01:27:19.480
Anthony Taylor: so R and ends or neural networks. The the thing that makes R and ends special

1395
01:27:20.160 --> 01:27:21.559
Anthony Taylor: is they have a member.

1396
01:27:23.760 --> 01:27:24.690
Anthony Taylor: Okay.

1397
01:27:24.940 --> 01:27:27.200
Anthony Taylor: they have a memory. So

1398
01:27:29.240 --> 01:27:34.720
Anthony Taylor: if when you're using. Rn is like, so this is an example of some text generation with an Rn.

1399
01:27:34.960 --> 01:27:35.975
Anthony Taylor: okay,

1400
01:27:37.040 --> 01:27:41.300
Anthony Taylor: it could actually remember the past. So we can give it.

1401
01:27:41.320 --> 01:27:42.380
Anthony Taylor: I,

1402
01:27:42.710 --> 01:27:47.180
Anthony Taylor: and it knows that oh, well, after I sometimes it's an app.

1403
01:27:47.750 --> 01:27:50.270
Anthony Taylor: and after M, sometimes it's your.

1404
01:27:51.340 --> 01:27:53.959
Anthony Taylor: and so if we gave it, I and your

1405
01:27:54.030 --> 01:27:58.479
Anthony Taylor: then it's going to go. Oh, well, I remember I am. Your is often followed by

1406
01:27:58.680 --> 01:27:59.550
Anthony Taylor: foul

1407
01:28:00.100 --> 01:28:02.130
Anthony Taylor: okay, now, that's a cool

1408
01:28:02.340 --> 01:28:06.019
Anthony Taylor: yeah, okay, that's a neat example. I'm gonna give you a better example in a second.

1409
01:28:06.280 --> 01:28:10.740
Anthony Taylor: What are we current neural networks used for? Well, pretty much anything

1410
01:28:11.030 --> 01:28:18.910
Anthony Taylor: where it is important to gather information as opposed to just reading it. Now, what does that mean?

1411
01:28:20.940 --> 01:28:22.760
Anthony Taylor: well, let me ask you this question.

1412
01:28:22.910 --> 01:28:26.649
Anthony Taylor: So Cnn's what was the primary purpose for Cnn's.

1413
01:28:32.350 --> 01:28:33.809
Derek Rikke: Evaluate images.

1414
01:28:34.370 --> 01:28:41.809
Anthony Taylor: Yeah, images. So could it tell us which way a car is going? Or could it just identify? There's a car.

1415
01:28:45.770 --> 01:28:50.720
Clayton Graves: Yeah, it's just gonna be able to identify the car. At best, it's not gonna be able to tell anything else.

1416
01:28:51.360 --> 01:28:55.170
Anthony Taylor: Right, and the reason for that is is, it can't see

1417
01:28:55.180 --> 01:28:56.840
Anthony Taylor: the picture before that

1418
01:28:58.070 --> 01:29:08.790
Anthony Taylor: right. If we could see if we could evaluate the picture before it, and the second picture, and say, Oh, well, that car moved from here to here, we might be able to say which direction.

1419
01:29:08.930 --> 01:29:15.330
Anthony Taylor: But the neural network, the A and N. And the Cnn. They don't have the ability to remember

1420
01:29:15.650 --> 01:29:17.010
Anthony Taylor: what the last

1421
01:29:17.780 --> 01:29:25.329
Anthony Taylor: picture was. There's no clue. They just that's just not what they do. They're very good at detecting patterns that are static.

1422
01:29:25.880 --> 01:29:27.050
Anthony Taylor: Okay, now.

1423
01:29:27.140 --> 01:29:31.009
Anthony Taylor: don't get confused with oh, well, that means they can't do video. No, that's not true.

1424
01:29:31.130 --> 01:29:34.220
Anthony Taylor: Okay, video is actually done one frame at a time.

1425
01:29:35.380 --> 01:29:38.290
Anthony Taylor: Okay, but that's not what we're talking about.

1426
01:29:38.400 --> 01:29:40.130
Anthony Taylor: So for Nlp.

1427
01:29:40.200 --> 01:29:46.100
Anthony Taylor: the ability for the model. To remember a sequence

1428
01:29:48.070 --> 01:29:49.090
Anthony Taylor: is

1429
01:29:49.110 --> 01:29:50.890
Anthony Taylor: incredibly powerful.

1430
01:29:51.110 --> 01:29:56.729
Anthony Taylor: And really it was the first time that text generation kind of became a thing.

1431
01:29:57.220 --> 01:29:58.330
Anthony Taylor: Okay? So

1432
01:29:58.430 --> 01:30:03.379
Anthony Taylor: before all of the Llms before Openai released its stuff.

1433
01:30:03.640 --> 01:30:05.170
Anthony Taylor: You guys have

1434
01:30:06.700 --> 01:30:10.179
Anthony Taylor: text complete on your phones. Right?

1435
01:30:11.450 --> 01:30:23.179
Anthony Taylor: Okay? Well, that was basically done with. Rn, it looked at the it it you you had as you start to type, it goes. Oh, well, usually, when people put those words together.

1436
01:30:23.210 --> 01:30:25.299
Anthony Taylor: there's trying to say this.

1437
01:30:25.350 --> 01:30:28.309
Anthony Taylor: and it gives you the next word or 2 words, for

1438
01:30:28.530 --> 01:30:30.599
Anthony Taylor: however many words it was trained up.

1439
01:30:31.482 --> 01:30:34.650
Anthony Taylor: So that's how that works. DNA sequencing.

1440
01:30:35.130 --> 01:30:38.519
Anthony Taylor: I mean, it's remarkably complex.

1441
01:30:38.920 --> 01:30:42.410
Anthony Taylor: So they have the ability to remember. The last item

1442
01:30:42.420 --> 01:30:54.499
Anthony Taylor: is important. But the most important thing here is that we have the sequencing, and that's why, it's doing it. Time series, dated. Now, here's one I know. He's Natalie alike. Music, composition.

1443
01:30:55.590 --> 01:31:03.159
Anthony Taylor: Okay, music composition. Think about this. But what we've learned within lp, so far we could really only see

1444
01:31:03.430 --> 01:31:04.730
Anthony Taylor: a pattern.

1445
01:31:05.130 --> 01:31:08.769
Anthony Taylor: but we didn't see how one pattern led to another pattern.

1446
01:31:09.180 --> 01:31:15.010
Anthony Taylor: because it wasn't in sequence. A song is nothing more than a sequence.

1447
01:31:16.810 --> 01:31:26.490
Anthony Taylor: Okay? So as we build up the song, we're creating this sequence of notes or choruses, or whatever. Now I go all the terminology.

1448
01:31:26.920 --> 01:31:28.470
Anthony Taylor: But it's still a sequence.

1449
01:31:29.912 --> 01:31:36.999
Anthony Taylor: Arnins can actually remember that. And with that they actually have the capability to write

1450
01:31:37.130 --> 01:31:37.980
Anthony Taylor: music

1451
01:31:39.250 --> 01:31:40.350
Anthony Taylor: pretty cool. Huh?

1452
01:31:45.080 --> 01:31:48.349
Anthony Taylor: so if we record. So here's some more information on that.

1453
01:31:50.090 --> 01:32:00.670
Anthony Taylor: if we record a cards movement right, the A and N can say, Hey, this car has no idea where it went, but the sequence of images. The R. And N. Would be able to figure out

1454
01:32:00.860 --> 01:32:03.079
Anthony Taylor: which direction that car is going.

1455
01:32:03.370 --> 01:32:06.050
Anthony Taylor: Okay. It would be horrifically

1456
01:32:06.220 --> 01:32:07.270
Anthony Taylor: I

1457
01:32:08.000 --> 01:32:10.250
Anthony Taylor: cost, but it can do it.

1458
01:32:10.250 --> 01:32:11.180
Clayton Graves: Wouldn't be able to.

1459
01:32:11.180 --> 01:32:11.650
Anthony Taylor: Where to get.

1460
01:32:11.650 --> 01:32:14.439
Clayton Graves: Set up east, west, right to be able to do left to right.

1461
01:32:14.440 --> 01:32:18.100
Anthony Taylor: No, yeah, it would be the direction on the picture itself.

1462
01:32:18.300 --> 01:32:19.770
Anthony Taylor: like, it's going right?

1463
01:32:20.070 --> 01:32:23.390
Anthony Taylor: Yeah, it could say that, or up or whatever.

1464
01:32:23.770 --> 01:32:26.250
Anthony Taylor: So what are things it's used for? Well.

1465
01:32:26.650 --> 01:32:28.289
Anthony Taylor: our assistance.

1466
01:32:28.770 --> 01:32:30.020
Anthony Taylor: all of them.

1467
01:32:30.420 --> 01:32:39.160
Anthony Taylor: Okay, r and N is great for that. Because again, it's taking this information and going. Hey? What did he mean by that? What am I going to do with that?

1468
01:32:39.890 --> 01:32:53.800
Anthony Taylor: Alright? And then it triggers, you know, like, for all of our our home devices. You say the magic word. It opens its ears. You say something, it basically takes this apart, tokenizes it.

1469
01:32:53.970 --> 01:32:56.939
Anthony Taylor: and then applies it to a trigger.

1470
01:32:57.230 --> 01:33:00.670
Anthony Taylor: and that trigger points to a program that then runs.

1471
01:33:01.220 --> 01:33:05.819
Anthony Taylor: That's pretty easy. I'll I'll tell you something you ever want to do something fun.

1472
01:33:06.250 --> 01:33:10.220
Anthony Taylor: Aws! Lets you create Alexa apps for free.

1473
01:33:10.760 --> 01:33:12.399
Anthony Taylor: And it's really not hard.

1474
01:33:13.030 --> 01:33:17.309
Anthony Taylor: And it's a lot of fun to do, and you can load them up on your own personal.

1475
01:33:17.490 --> 01:33:23.839
Anthony Taylor: You could put them up there on the public, too, if they're good. But if you want, you can just have it up on your own stuff for fun. It's kind of neat

1476
01:33:24.781 --> 01:33:30.689
Anthony Taylor: DNA sequencing, I mean, there's not a whole lot to say about that other than it's literally a sequel.

1477
01:33:31.020 --> 01:33:36.440
Anthony Taylor: hey? We're trying to figure out the order, what goes where and why it does.

1478
01:33:36.560 --> 01:33:37.590
Anthony Taylor: etc.

1479
01:33:37.920 --> 01:33:39.780
Anthony Taylor: Time series data

1480
01:33:39.900 --> 01:33:41.569
Anthony Taylor: again makes sense.

1481
01:33:41.730 --> 01:33:45.039
Anthony Taylor: Okay, we're going over time. We need to see what it was before

1482
01:33:45.490 --> 01:33:49.470
Anthony Taylor: the further back. We can remember the better job we're going to do.

1483
01:33:49.850 --> 01:33:51.519
Anthony Taylor: predicting what's coming.

1484
01:33:52.130 --> 01:33:55.829
Anthony Taylor: If you're only predicting, based on. Let me give you to you this way.

1485
01:33:56.140 --> 01:34:01.540
Anthony Taylor: If you're trying to do stock predictions. Everybody loves stock predictions in here right? Everybody likes to talk about that.

1486
01:34:01.610 --> 01:34:05.279
Anthony Taylor: So if you're trying to do stock predictions, but you're only looking at the last

1487
01:34:05.390 --> 01:34:06.350
Anthony Taylor: value

1488
01:34:07.960 --> 01:34:12.600
Anthony Taylor: right? It's probably even though you might be able to detect the pattern.

1489
01:34:12.690 --> 01:34:15.440
Anthony Taylor: It's still the last value

1490
01:34:15.610 --> 01:34:17.119
Anthony Taylor: is all you're really looking.

1491
01:34:18.100 --> 01:34:22.039
Anthony Taylor: and and you're trying to determine where the pattern's going to go from there.

1492
01:34:22.200 --> 01:34:27.819
Anthony Taylor: Well, with R and N, you can actually look at the previous. However many you're allowed to keep

1493
01:34:29.150 --> 01:34:31.480
Anthony Taylor: to come up with the next value.

1494
01:34:31.620 --> 01:34:34.390
Anthony Taylor: So think of it like text generation thing.

1495
01:34:34.920 --> 01:34:37.510
Anthony Taylor: Alright. I am a

1496
01:34:39.830 --> 01:34:42.810
Anthony Taylor: whatever it is. Okay. Here's all your suggestions.

1497
01:34:42.970 --> 01:34:51.690
Anthony Taylor: So I took 3 words, and I have. I've limited the amount of suggestions to every word in the English language through words that fit after Ima.

1498
01:34:52.540 --> 01:35:00.179
Anthony Taylor: Well, same thing happens with like the stocks and all that kind of stuff. If it's like, it's 58, 56, 57,

1499
01:35:00.310 --> 01:35:03.500
Anthony Taylor: right? Well, what's the normal next?

1500
01:35:04.770 --> 01:35:06.259
Anthony Taylor: Based on our training?

1501
01:35:06.420 --> 01:35:07.190
Anthony Taylor: Okay?

1502
01:35:07.943 --> 01:35:12.900
Anthony Taylor: And music composition? So we can actually make music with these models.

1503
01:35:13.960 --> 01:35:19.239
Anthony Taylor: So we kind of already talked about this neural networks have the ability to identify

1504
01:35:20.440 --> 01:35:27.339
Anthony Taylor: pretty much anything. Okay, but not necessarily a sequence. I mean they can work with sequences.

1505
01:35:27.630 --> 01:35:31.040
Anthony Taylor: but they're still identifying them. At that moment

1506
01:35:32.190 --> 01:35:35.410
Anthony Taylor: they're looking for a pattern and making a prediction.

1507
01:35:36.840 --> 01:35:37.889
Anthony Taylor: I can.

1508
01:35:37.960 --> 01:35:40.259
Anthony Taylor: So they're really good at stuff like.

1509
01:35:40.380 --> 01:35:41.320
Anthony Taylor: here's a car

1510
01:35:43.210 --> 01:35:45.409
Anthony Taylor: while it are. It is

1511
01:35:45.770 --> 01:35:50.089
Anthony Taylor: we can actually pass in a sequence of data.

1512
01:35:50.530 --> 01:35:56.309
Anthony Taylor: and it understands. It can say, Oh, well, the car was here then it was here, and then it was here.

1513
01:35:58.920 --> 01:36:02.259
Anthony Taylor: Okay, so it moved across the picture. If you will

1514
01:36:02.410 --> 01:36:10.270
Anthony Taylor: again, you're right, not east left south. Whatnot none of that. But it can tell that the car is moving in what direction across the image it's moved.

1515
01:36:10.690 --> 01:36:13.990
Anthony Taylor: I don't know why they liked that. But it's a good one. But okay.

1516
01:36:14.100 --> 01:36:17.199
Anthony Taylor: so an A and N just goes straight through.

1517
01:36:17.780 --> 01:36:19.249
Anthony Taylor: Here's the inputs

1518
01:36:19.770 --> 01:36:21.180
Anthony Taylor: look for a pattern

1519
01:36:21.790 --> 01:36:24.050
Anthony Taylor: probability of an out of the out

1520
01:36:24.470 --> 01:36:25.250
Anthony Taylor: done

1521
01:36:25.690 --> 01:36:27.370
Anthony Taylor: while on Rn, it

1522
01:36:27.540 --> 01:36:31.070
Anthony Taylor: actually feeds back to itself

1523
01:36:31.810 --> 01:36:34.220
Anthony Taylor: information that it has gathered.

1524
01:36:34.670 --> 01:36:43.510
Anthony Taylor: Okay, so the first one comes in. It sees the first image, and it goes okay. Well, pretty sure. That's car. Feed it back in.

1525
01:36:44.020 --> 01:36:45.970
Anthony Taylor: Oh, there's another image.

1526
01:36:46.100 --> 01:36:49.609
Anthony Taylor: It's the same car, but it's in a different location, feed it back in.

1527
01:36:49.610 --> 01:36:54.099
Clayton Graves: Is this similar to? We were talking about the model that

1528
01:36:54.220 --> 01:36:58.919
Clayton Graves: the hidden model could could talk back to the output model. And

1529
01:36:59.130 --> 01:37:00.619
Clayton Graves: yeah, talk to each other, man.

1530
01:37:00.620 --> 01:37:02.189
Anthony Taylor: Codes are talking to each other.

1531
01:37:02.660 --> 01:37:04.140
Clayton Graves: But this is the same version.

1532
01:37:05.060 --> 01:37:09.089
Anthony Taylor: This is, this is an r in it. So, yeah, this is where you see this actually at

1533
01:37:09.500 --> 01:37:11.200
Anthony Taylor: right now.

1534
01:37:12.410 --> 01:37:14.169
Anthony Taylor: how does it work? Well.

1535
01:37:14.730 --> 01:37:19.719
Anthony Taylor: So when you read the sentence, your brain is able to decode and understand it, because the neurons

1536
01:37:19.740 --> 01:37:23.100
Anthony Taylor: they have memory, like artists, don't have sentiment.

1537
01:37:23.460 --> 01:37:25.570
Anthony Taylor: But here's this is, this is a better.

1538
01:37:25.930 --> 01:37:33.960
Anthony Taylor: Okay. So it reads this in the individual words, sequentially. So we feed it. One word at a time. And we say, okay.

1539
01:37:34.650 --> 01:37:43.229
Anthony Taylor: here's first word. First word is I that a member? Second words one. Okay, they're both in memory. 2, all right. All 3 of those. Now, a memory

1540
01:37:43.670 --> 01:37:45.029
Anthony Taylor: at this point.

1541
01:37:45.150 --> 01:37:50.010
Anthony Taylor: If you were to type, I want to, it might come up and say and suggest invest

1542
01:37:51.340 --> 01:37:55.420
Anthony Taylor: alright. But we threw that in memory because we're training our model.

1543
01:37:55.630 --> 01:37:57.590
Anthony Taylor: Okay? 4.

1544
01:37:57.970 --> 01:38:04.439
Anthony Taylor: Still training your model. Now, what I want you guys to notice is, look at what's happening with an R and N, there is a flaw.

1545
01:38:05.040 --> 01:38:06.090
Anthony Taylor: Okay?

1546
01:38:06.470 --> 01:38:08.779
Anthony Taylor: And the the flaw is

1547
01:38:08.970 --> 01:38:11.959
Anthony Taylor: can't really hold that much memory.

1548
01:38:13.340 --> 01:38:17.059
Anthony Taylor: See what's happening to the yellow as we move further along.

1549
01:38:19.570 --> 01:38:21.220
Anthony Taylor: So eventually that just

1550
01:38:21.290 --> 01:38:22.709
Anthony Taylor: is pushed off the map.

1551
01:38:24.500 --> 01:38:27.440
Anthony Taylor: Okay? And then it's no longer part of this

1552
01:38:27.910 --> 01:38:28.880
Anthony Taylor: discussion.

1553
01:38:29.350 --> 01:38:29.980
Anthony Taylor: So.

1554
01:38:29.980 --> 01:38:33.279
Clayton Graves: Like the beginning of class versus the end of class. For me.

1555
01:38:34.040 --> 01:38:38.550
Anthony Taylor: Exactly everything we taught you on day one you have now forgot.

1556
01:38:39.110 --> 01:38:43.610
Anthony Taylor: Okay, I have a theory on this, because I I have bad.

1557
01:38:43.920 --> 01:38:44.890
Anthony Taylor: really bad, but

1558
01:38:45.160 --> 01:38:46.290
Anthony Taylor: and that

1559
01:38:46.340 --> 01:38:49.759
Anthony Taylor: I tell people that my brain is like a glass of water.

1560
01:38:50.240 --> 01:38:53.689
Anthony Taylor: right? It's except for it's overflowing.

1561
01:38:53.760 --> 01:38:58.030
Anthony Taylor: because I'm constantly learning stuff. All the unimportant stuff falls out the other side

1562
01:38:58.700 --> 01:39:02.200
Anthony Taylor: right? That works, except for when I forget something important that sucks.

1563
01:39:02.200 --> 01:39:05.250
Clayton Graves: So. So let me let me ask you this, if we're talking about.

1564
01:39:05.250 --> 01:39:05.840
Anthony Taylor: Huh!

1565
01:39:06.720 --> 01:39:09.590
Clayton Graves: We're talking about a specific amount of memory.

1566
01:39:09.930 --> 01:39:15.989
Clayton Graves: Could you then increase the amount of memory allocated to the, to the to the model.

1567
01:39:16.810 --> 01:39:19.039
Clayton Graves: so that you could remember more steps.

1568
01:39:20.910 --> 01:39:29.209
Anthony Taylor: In theory. Yes, but no matter what, there is a a definite limit, it's it's literally considered like the biggest flaw with an r in it.

1569
01:39:29.310 --> 01:39:32.270
Anthony Taylor: Okay? And when they first came out this was amazing.

1570
01:39:32.330 --> 01:39:36.350
Anthony Taylor: This was one of the coolest like, I said, this was

1571
01:39:36.460 --> 01:39:38.100
Anthony Taylor: the invention

1572
01:39:38.110 --> 01:39:39.130
Anthony Taylor: of

1573
01:39:39.360 --> 01:39:42.200
Anthony Taylor: text complete, which we all

1574
01:39:42.710 --> 01:39:44.700
Anthony Taylor: I mean a door. Now.

1575
01:39:44.990 --> 01:39:46.549
Anthony Taylor: right? We all love it.

1576
01:39:46.630 --> 01:39:48.950
Anthony Taylor: Everybody loves it. It's the greatest thing ever

1577
01:39:50.460 --> 01:39:54.310
Anthony Taylor: But as you guys are, gonna see in just a second we did solve this problem.

1578
01:39:54.770 --> 01:39:56.589
Anthony Taylor: but not within our event.

1579
01:39:57.521 --> 01:40:01.500
Anthony Taylor: But our nans were like, I said, the 2,007

1580
01:40:02.450 --> 01:40:06.950
Anthony Taylor: step was our ninth, and it worked, and it was really quite good.

1581
01:40:09.260 --> 01:40:17.130
Anthony Taylor: so yeah, so they have the sequential memory. The final output was created from the rest of the sequence. So let's say, all we wanted

1582
01:40:17.190 --> 01:40:18.420
Anthony Taylor: was to.

1583
01:40:18.590 --> 01:40:21.770
Anthony Taylor: basically, we wanted to get to this

1584
01:40:21.970 --> 01:40:25.800
Anthony Taylor: right? We wanted to predict this. So we were get. We gave it. This

1585
01:40:26.050 --> 01:40:28.009
Anthony Taylor: I want to invest for.

1586
01:40:28.470 --> 01:40:32.720
Anthony Taylor: and due to its training, it was able to suggest retirement.

1587
01:40:33.330 --> 01:40:37.680
Anthony Taylor: And maybe that was right. Maybe it was wrong. But how many times you guys get mad?

1588
01:40:38.300 --> 01:40:43.729
Anthony Taylor: I mean, I don't know if anybody gets mad when they're do get a text complete, and it's not what they meant to say.

1589
01:40:44.230 --> 01:40:49.540
Anthony Taylor: The only time you get annoyed with it is when you accidentally push complete, and then it's like, Oh, man!

1590
01:40:49.830 --> 01:40:51.420
Anthony Taylor: Then you got a backspace.

1591
01:40:51.880 --> 01:40:54.759
Clayton Graves: I don't know about. I don't know about test complete, but

1592
01:40:54.790 --> 01:40:57.479
Clayton Graves: I know auto correct is a pretty big deal.

1593
01:40:57.810 --> 01:40:58.400
Clayton Graves: and.

1594
01:40:58.400 --> 01:40:59.320
Anthony Taylor: Exactly.

1595
01:41:01.260 --> 01:41:02.349
Masarirambi, Rodney: That's when the one Duncan.

1596
01:41:02.350 --> 01:41:03.170
Anthony Taylor: Same thing?

1597
01:41:04.270 --> 01:41:04.930
Anthony Taylor: What.

1598
01:41:04.930 --> 01:41:08.550
Masarirambi, Rodney: Just when you just when you don't duck and expect it. That's the only time.

1599
01:41:08.880 --> 01:41:09.810
Anthony Taylor: Exact.

1600
01:41:10.790 --> 01:41:11.430
Mason, Natalie: Secondary.

1601
01:41:11.430 --> 01:41:12.200
Anthony Taylor: And this

1602
01:41:12.730 --> 01:41:15.789
Anthony Taylor: especially with voice chat. I'm I'm a big

1603
01:41:16.000 --> 01:41:18.230
Anthony Taylor: like voice type work. I just.

1604
01:41:18.590 --> 01:41:20.770
Anthony Taylor: I'm like, I'll just I voice type like

1605
01:41:21.210 --> 01:41:23.779
Anthony Taylor: and and I and I just tell people get used to

1606
01:41:24.030 --> 01:41:27.330
Anthony Taylor: it's gonna be wrong about a third of the time. Just

1607
01:41:27.390 --> 01:41:33.949
Anthony Taylor: try to figure out what I meant to say, anyway. Okay.

1608
01:41:33.980 --> 01:41:35.390
Anthony Taylor: so they're forgetting.

1609
01:41:35.410 --> 01:41:39.840
Anthony Taylor: Vanishing gradient is a problem with short-term memory.

1610
01:41:41.480 --> 01:41:43.740
Anthony Taylor: So what do we do? Well.

1611
01:41:44.120 --> 01:41:48.090
Anthony Taylor: then, came along the Lstm long, short-term memory.

1612
01:41:48.850 --> 01:41:52.099
Anthony Taylor: Yeah, these things were named by professions.

1613
01:41:52.470 --> 01:41:53.620
Anthony Taylor: Okay.

1614
01:41:53.640 --> 01:41:58.400
Anthony Taylor: so Lstm was the improvement of R and N,

1615
01:41:58.500 --> 01:42:01.739
Anthony Taylor: and it actually did a very, very good job.

1616
01:42:02.060 --> 01:42:12.699
Anthony Taylor: basically it exactly as it says, this one has working memory. This one has working memory, but it also has the ability to hold more

1617
01:42:15.210 --> 01:42:21.510
Anthony Taylor: so solution for longer time windows. They're they're they're similar. But they basically have gates.

1618
01:42:22.420 --> 01:42:24.790
Anthony Taylor: Okay, for lack of a better term.

1619
01:42:24.790 --> 01:42:27.369
Clayton Graves: Basically like RAM versus hardram.

1620
01:42:28.170 --> 01:42:28.720
Clayton Graves: right.

1621
01:42:28.720 --> 01:42:32.059
Anthony Taylor: Sort of I mean, this is all in memory. But

1622
01:42:32.080 --> 01:42:34.520
Anthony Taylor: so actually, they want me to show you this.

1623
01:42:34.650 --> 01:42:36.750
Anthony Taylor: So here's this cool little

1624
01:42:36.950 --> 01:42:38.730
Anthony Taylor: hugging face sight.

1625
01:42:39.130 --> 01:42:40.450
Anthony Taylor: I'll throw it into

1626
01:42:40.470 --> 01:42:44.720
Anthony Taylor: a phone in the Zoom chat. Oh, never mind, for people who aren't here

1627
01:42:44.960 --> 01:42:48.609
Anthony Taylor: always forget that. Somebody said that I'm never going to forget that again.

1628
01:42:49.480 --> 01:42:52.800
Anthony Taylor: You got to put it in slack. So other people can get to

1629
01:42:52.990 --> 01:42:55.270
Anthony Taylor: that didn't come to class.

1630
01:42:55.390 --> 01:43:02.170
Anthony Taylor: Okay, so all you gotta do here, guys, you delete that this is basically just a transformer. Wait a minute. Is that today

1631
01:43:02.430 --> 01:43:03.490
Anthony Taylor: it is today.

1632
01:43:03.907 --> 01:43:09.199
Anthony Taylor: And you could do I want, and at any time you can hit Tab.

1633
01:43:10.530 --> 01:43:11.530
Anthony Taylor: and

1634
01:43:12.870 --> 01:43:14.660
Anthony Taylor: it will. There you go.

1635
01:43:16.030 --> 01:43:18.679
Anthony Taylor: I want to be an app

1636
01:43:21.230 --> 01:43:23.570
Anthony Taylor: expert tab

1637
01:43:25.580 --> 01:43:27.900
Anthony Taylor: and a app

1638
01:43:29.590 --> 01:43:30.530
Anthony Taylor: doctor.

1639
01:43:32.720 --> 01:43:40.160
Anthony Taylor: Alright. So all of this is just a trained model that was trained on some some corpus or some text.

1640
01:43:40.530 --> 01:43:44.569
Anthony Taylor: And when every time you hit tab, it basically just sends

1641
01:43:44.670 --> 01:43:47.759
Anthony Taylor: the words that you've typed in so far

1642
01:43:48.110 --> 01:43:51.430
Anthony Taylor: and says, Well, what do you think is next? And then it gives us the options.

1643
01:43:51.490 --> 01:43:53.710
Anthony Taylor: That's basically what we're building

1644
01:43:54.180 --> 01:43:58.079
Anthony Taylor: or what we're talking about, how far we're going to get to building it.

1645
01:43:58.470 --> 01:44:00.030
Anthony Taylor: But what we're talking about.

1646
01:44:00.440 --> 01:44:01.280
Anthony Taylor: Okay.

1647
01:44:02.080 --> 01:44:05.320
Anthony Taylor: you guys can play with that if you want, it's it's it's kind of boring.

1648
01:44:19.460 --> 01:44:22.899
Anthony Taylor: I only had. It's weird that they had us. Yet. So

1649
01:44:23.780 --> 01:44:27.340
Anthony Taylor: automatic text generators typically use neural networks to predict

1650
01:44:27.990 --> 01:44:34.429
Anthony Taylor: predictions are only possible after models have been trained. These things take a long time to train.

1651
01:44:35.070 --> 01:44:36.150
Anthony Taylor: Okay?

1652
01:44:39.170 --> 01:44:39.940
Anthony Taylor: oh.

1653
01:44:40.070 --> 01:44:41.069
Anthony Taylor: here we are.

1654
01:44:42.260 --> 01:44:44.529
Anthony Taylor: If you want to learn more about R and ends

1655
01:44:45.080 --> 01:44:47.769
Anthony Taylor: there is. We have a cheat sheet.

1656
01:44:48.240 --> 01:44:51.559
Anthony Taylor: I will make sure it gets uploaded to your git lab.

1657
01:44:53.310 --> 01:44:54.370
Anthony Taylor: Okay.

1658
01:44:55.800 --> 01:44:57.869
Anthony Taylor: so guys. I'm just gonna tell you

1659
01:44:58.070 --> 01:45:01.380
Anthony Taylor: there's a very good chance. We're gonna get out early

1660
01:45:04.460 --> 01:45:06.550
Anthony Taylor: because I don't think

1661
01:45:06.720 --> 01:45:08.209
Anthony Taylor: we can run this.

1662
01:45:08.720 --> 01:45:10.660
Anthony Taylor: but we'll run it as far as we can.

1663
01:45:12.540 --> 01:45:14.260
Anthony Taylor: Let's just see if this works.

1664
01:45:27.390 --> 01:45:28.979
Clayton Graves: I had to do some coming.

1665
01:45:29.260 --> 01:45:30.340
Clayton Graves: I had to do something very.

1666
01:45:30.340 --> 01:45:33.769
Anthony Taylor: Yeah, you do have to do the download. Oh, sorry. I'm sorry. Go ahead.

1667
01:45:37.030 --> 01:45:38.090
Anthony Taylor: Go ahead, Clayton.

1668
01:45:38.140 --> 01:45:39.379
Anthony Taylor: You're muted, Buddy.

1669
01:45:42.200 --> 01:45:48.429
Clayton Graves: So yeah, you had to do the the python or no, you have the python dash and space you download

1670
01:45:48.580 --> 01:45:49.210
Clayton Graves: with the.

1671
01:45:49.210 --> 01:45:50.830
Anthony Taylor: Yeah, it's like.

1672
01:45:50.830 --> 01:45:53.859
Clayton Graves: Thank you, Michael. And that worked.

1673
01:45:53.880 --> 01:45:56.589
Clayton Graves: But the the actual

1674
01:45:56.970 --> 01:45:57.640
Clayton Graves: oh

1675
01:45:58.060 --> 01:46:00.500
Clayton Graves: training of the model, or whatever is

1676
01:46:00.630 --> 01:46:01.720
Clayton Graves: huge.

1677
01:46:02.670 --> 01:46:06.160
Anthony Taylor: Over an hour if anybody finished it. Did you start it already?

1678
01:46:06.760 --> 01:46:08.140
Anthony Taylor: Yeah, is it running?

1679
01:46:08.480 --> 01:46:10.090
Anthony Taylor: Okay? Don't stop it.

1680
01:46:11.600 --> 01:46:16.540
Anthony Taylor: If it gets done in the next, like 5, 10 min we could just everybody could just share his model

1681
01:46:17.094 --> 01:46:22.989
Anthony Taylor: and and in hindsight I wish I would have just went ahead and trained it earlier today. Because I I

1682
01:46:23.240 --> 01:46:26.049
Anthony Taylor: I'll explain in a second. Alright. So, everybody

1683
01:46:26.210 --> 01:46:30.410
Anthony Taylor: before you start this exercise. You do need to do this just as mentioned.

1684
01:46:30.760 --> 01:46:33.969
Anthony Taylor: You need to download this. I'll tell you. There's a

1685
01:46:34.760 --> 01:46:37.410
Anthony Taylor: there's also a pip install you're going to need.

1686
01:46:38.805 --> 01:46:42.340
Anthony Taylor: Curios pre-processing. I'll get it for you.

1687
01:46:42.640 --> 01:46:44.450
Anthony Taylor: since I have this open.

1688
01:46:45.860 --> 01:46:49.350
Clayton Graves: I'm not likely to finish in time. I'm only at 1 77.

1689
01:46:49.940 --> 01:46:54.669
Anthony Taylor: Oh, yeah, no, I I just don't think we're gonna get to see it today, which it's

1690
01:46:55.820 --> 01:47:00.282
Anthony Taylor: I mean, if you, if anybody wants to try it. They're welcome to try it.

1691
01:47:01.480 --> 01:47:03.240
Anthony Taylor: There's a

1692
01:47:03.519 --> 01:47:10.249
Anthony Taylor: but we'll go through all the steps anyway. You just won't be able to finish it. That's up. It's only like the last 2 steps.

1693
01:47:11.190 --> 01:47:14.379
Anthony Taylor: But anyway, it's curios pre-processing.

1694
01:47:15.980 --> 01:47:17.529
Anthony Taylor: Alright. Where'd it go?

1695
01:47:19.230 --> 01:47:20.950
Anthony Taylor: This one? There you go.

1696
01:47:21.660 --> 01:47:26.409
Anthony Taylor: So everybody needs to run that python in spacey download and

1697
01:47:28.180 --> 01:47:30.080
Anthony Taylor: Pippin's dot. QS. Process.

1698
01:47:31.310 --> 01:47:32.950
Anthony Taylor: Okay, okay.

1699
01:47:35.300 --> 01:47:36.400
Anthony Taylor: Alright.

1700
01:47:39.110 --> 01:47:39.583
Baro, Sonja: Where's this?

1701
01:47:39.820 --> 01:47:40.139
Anthony Taylor: In, the.

1702
01:47:40.470 --> 01:47:40.800
Baro, Sonja: One.

1703
01:47:41.600 --> 01:47:43.729
Anthony Taylor: It's they're both in slack under. Live.

1704
01:47:43.960 --> 01:47:44.546
Baro, Sonja: Thank you.

1705
01:47:45.970 --> 01:47:46.700
Baro, Sonja: Yeah.

1706
01:47:48.490 --> 01:47:49.420
Anthony Taylor: Okay.

1707
01:47:51.300 --> 01:47:52.850
Anthony Taylor: though.

1708
01:47:55.910 --> 01:48:01.029
Anthony Taylor: we're going to import Spacey, we are going to use the large English model for this.

1709
01:48:01.478 --> 01:48:05.600
Anthony Taylor: We're gonna get rid of a couple of them all of the other things that Spacey gives us.

1710
01:48:05.890 --> 01:48:06.940
Anthony Taylor: Okay.

1711
01:48:07.880 --> 01:48:09.360
Anthony Taylor: we're gonna load that up.

1712
01:48:10.820 --> 01:48:16.720
Anthony Taylor: we're gonna create some functions which is always a good idea. But this one's a little different. Does anybody remember

1713
01:48:17.060 --> 01:48:19.040
Anthony Taylor: what that's actually going to do?

1714
01:48:29.630 --> 01:48:32.860
Anthony Taylor: You could just read comments on it. But I'll tell you.

1715
01:48:33.468 --> 01:48:36.280
Anthony Taylor: It's basically gonna open the file

1716
01:48:36.610 --> 01:48:41.960
Anthony Taylor: and then loop through and read each line of text into this variable.

1717
01:48:42.680 --> 01:48:44.650
Anthony Taylor: And then it's gonna return

1718
01:48:45.340 --> 01:48:47.789
Anthony Taylor: all of the text in a single variable.

1719
01:48:48.500 --> 01:48:53.120
Anthony Taylor: which is good for what we're trying to do right? Remember, we kind of basically, we're doing that anyway.

1720
01:48:53.530 --> 01:48:54.490
Anthony Taylor: So

1721
01:48:54.810 --> 01:48:58.700
Anthony Taylor: you know what? Let me clear the output so we could see this a little better.

1722
01:49:02.097 --> 01:49:07.909
Anthony Taylor: Yeah. Okay, then we're gonna do the punctuation thing we've been doing this all day.

1723
01:49:09.740 --> 01:49:15.670
Anthony Taylor: this is a slightly different way. They're doing a a list comprehension on this.

1724
01:49:15.730 --> 01:49:20.310
Anthony Taylor: They're lowercasing it, and they're getting rid of all of the stuff.

1725
01:49:22.360 --> 01:49:24.090
Anthony Taylor: Alright, that's a lot of stuff

1726
01:49:27.170 --> 01:49:33.539
Anthony Taylor: we're going to read in 4 chapters of movie, Dick, and we're going to remove the punctuation.

1727
01:49:35.800 --> 01:49:40.809
Anthony Taylor: See how long it is 100 or 11,338. Pretty exciting.

1728
01:49:41.829 --> 01:49:45.980
Anthony Taylor: We can look over the tokens. These are pretty much just the words.

1729
01:49:47.250 --> 01:49:51.060
Anthony Taylor: okay, call me Ish. Call me chair.

1730
01:49:52.180 --> 01:49:57.190
Anthony Taylor: I really liked it when somebody said that. How waiting for your book! I love that that's so fun.

1731
01:49:57.683 --> 01:50:03.069
Anthony Taylor: There are a couple of tokens that look like this for one reason or another. Let's see how many

1732
01:50:03.280 --> 01:50:04.200
Anthony Taylor: 6

1733
01:50:04.300 --> 01:50:05.480
Anthony Taylor: that's exciting.

1734
01:50:06.090 --> 01:50:08.430
Anthony Taylor: Okay, so, Max, we're gonna okay.

1735
01:50:09.100 --> 01:50:11.609
Anthony Taylor: So keeping in mind

1736
01:50:11.980 --> 01:50:13.010
Anthony Taylor: that

1737
01:50:15.620 --> 01:50:22.509
Anthony Taylor: everything I just showed you was based on completing a sentence, basically or completing a phrase.

1738
01:50:22.750 --> 01:50:26.880
Anthony Taylor: So one of the first things we do with Lts, then, is, we have to say.

1739
01:50:27.330 --> 01:50:30.830
Anthony Taylor: how many tokens do we want to use to train?

1740
01:50:31.650 --> 01:50:35.090
Anthony Taylor: So do we use 4 words, 10 words or

1741
01:50:35.850 --> 01:50:39.020
Anthony Taylor: 25 words plus one target?

1742
01:50:41.100 --> 01:50:46.900
Anthony Taylor: Okay, so that's what we're gonna use in this one. We're gonna tell it, hey? I want you to do 25 words at a time.

1743
01:50:47.820 --> 01:50:48.600
Anthony Taylor: Now.

1744
01:50:49.600 --> 01:50:51.610
Anthony Taylor: well, yeah, let me finish going through this.

1745
01:50:51.700 --> 01:50:53.170
Anthony Taylor: Okay? So

1746
01:50:54.100 --> 01:50:56.620
Anthony Taylor: what's interesting about this?

1747
01:50:59.580 --> 01:51:03.449
Anthony Taylor: I wanna, I have a very good explanation of all of this stuff.

1748
01:51:03.710 --> 01:51:09.709
Anthony Taylor: Oh, okay, so this is, gonna tell us 26 tokens we're gonna come in here and say, look

1749
01:51:09.870 --> 01:51:13.040
Anthony Taylor: or range the train length 26

1750
01:51:13.090 --> 01:51:18.479
Anthony Taylor: to the length of the total tokens. I want you to

1751
01:51:18.820 --> 01:51:22.500
Anthony Taylor: iterate through, get words from 0 to 26,

1752
01:51:22.670 --> 01:51:28.819
Anthony Taylor: and then the second iteration from one to 27, etc. So what does that mean? Remember the convolutional network?

1753
01:51:28.920 --> 01:51:31.309
Anthony Taylor: When I told you about the the frame

1754
01:51:31.460 --> 01:51:36.689
Anthony Taylor: and it would go, it would look at like the corner of the picture and then move over one pixel.

1755
01:51:37.110 --> 01:51:44.700
Anthony Taylor: Okay, that's what's gonna happen here. But by words. So it's gonna take the phrase, take 26 words.

1756
01:51:45.350 --> 01:51:48.030
Anthony Taylor: and then the next loop. It's going to go

1757
01:51:48.480 --> 01:51:50.740
Anthony Taylor: oop. Move over one word.

1758
01:51:51.080 --> 01:51:52.780
Anthony Taylor: 26 more words.

1759
01:51:53.570 --> 01:51:54.260
Anthony Taylor: Boo!

1760
01:51:54.920 --> 01:51:58.919
Anthony Taylor: 26 more words, and so on, and so on.

1761
01:51:59.590 --> 01:52:01.580
Anthony Taylor: until it gets every work.

1762
01:52:02.580 --> 01:52:03.550
Anthony Taylor: Okay?

1763
01:52:05.790 --> 01:52:09.360
Anthony Taylor: so yeah, so we run this, and this is going to break it up into that.

1764
01:52:09.840 --> 01:52:18.059
Anthony Taylor: And then when you look, you can see. So here's the first 26 words call me Ishmael blah blah blah blah. It ends with on

1765
01:52:18.400 --> 01:52:19.350
Anthony Taylor: okay.

1766
01:52:20.090 --> 01:52:25.539
Anthony Taylor: the next 26 words. Me see all it did was move over one.

1767
01:52:26.740 --> 01:52:29.000
Anthony Taylor: and it ends with, sure.

1768
01:52:29.770 --> 01:52:32.150
Anthony Taylor: Ishmael ends with.

1769
01:52:34.240 --> 01:52:35.199
Anthony Taylor: got it.

1770
01:52:36.910 --> 01:52:39.190
Anthony Taylor: Everyone clear on that. That's important.

1771
01:52:40.400 --> 01:52:41.230
Anthony Taylor: Okay.

1772
01:52:42.580 --> 01:52:44.920
Anthony Taylor: and now we're just gonna join

1773
01:52:45.210 --> 01:52:46.740
Anthony Taylor: these together.

1774
01:52:47.480 --> 01:52:50.090
Anthony Taylor: You see. Now, it's just this one big, long phrase.

1775
01:52:51.770 --> 01:52:54.029
Anthony Taylor: why does that matter? That's just how the model works

1776
01:52:54.380 --> 01:52:55.400
Anthony Taylor: don't sweat that.

1777
01:52:55.680 --> 01:52:56.980
Anthony Taylor: So the link.

1778
01:52:57.100 --> 01:53:01.269
Anthony Taylor: So this link should be, remember, the link before

1779
01:53:02.740 --> 01:53:06.389
Anthony Taylor: was 11,338.

1780
01:53:09.040 --> 01:53:11.389
Anthony Taylor: It should be exactly

1781
01:53:11.630 --> 01:53:14.110
Anthony Taylor: 26 characters less.

1782
01:53:16.060 --> 01:53:21.369
Anthony Taylor: Okay? Why? Because that was the length of of the lines we wanted. Okay.

1783
01:53:21.430 --> 01:53:27.080
Anthony Taylor: so here, we're going to do the preprocessing. If you remember to pick install, you should not have a problem with that one.

1784
01:53:27.639 --> 01:53:29.639
Anthony Taylor: We're gonna do a tokenizer.

1785
01:53:30.130 --> 01:53:31.190
Anthony Taylor: Okay.

1786
01:53:31.260 --> 01:53:34.630
Anthony Taylor: this is just going to map each word with an index.

1787
01:53:34.870 --> 01:53:36.320
Anthony Taylor: So we could take a look

1788
01:53:37.970 --> 01:53:40.089
Anthony Taylor: pretty pretty straightforward. Yeah.

1789
01:53:41.060 --> 01:53:44.479
Anthony Taylor: V, one, a 2 and 3 of 4.

1790
01:53:45.950 --> 01:53:48.070
Anthony Taylor: Natalie, are you still on the east coast?

1791
01:53:50.090 --> 01:53:50.890
Anthony Taylor: Okay.

1792
01:53:51.120 --> 01:53:53.103
Mason, Natalie: Yeah, I'm gonna be on.

1793
01:53:53.910 --> 01:53:57.199
Mason, Natalie: Can you go back up? Yeah, I'm tired now.

1794
01:53:58.205 --> 01:53:59.539
Mason, Natalie: I'm just. I'm

1795
01:53:59.600 --> 01:54:04.399
Mason, Natalie: I'm frustrated because I can't get my stuff to work. I did the pip installs.

1796
01:54:04.500 --> 01:54:07.850
Mason, Natalie: I did everything, and it's just not. I'm still on the second.

1797
01:54:07.850 --> 01:54:08.670
Anthony Taylor: On this one.

1798
01:54:08.670 --> 01:54:09.340
Mason, Natalie: No.

1799
01:54:11.120 --> 01:54:12.440
Anthony Taylor: Where? Where are you stuck at?

1800
01:54:12.440 --> 01:54:15.439
Mason, Natalie: I'm pretty much on the first cell I've been over here trying to get this.

1801
01:54:15.640 --> 01:54:16.410
Anthony Taylor: This one?

1802
01:54:17.870 --> 01:54:19.120
Anthony Taylor: Did you do that one.

1803
01:54:19.710 --> 01:54:21.050
Mason, Natalie: It's not awesome

1804
01:54:25.230 --> 01:54:27.730
Mason, Natalie: it mine, says Web.

1805
01:54:28.270 --> 01:54:30.803
Mason, Natalie: SM. Not LG.

1806
01:54:31.570 --> 01:54:32.920
Anthony Taylor: The the one in slack.

1807
01:54:33.570 --> 01:54:34.270
Mason, Natalie: Okay.

1808
01:54:35.130 --> 01:54:41.470
Anthony Taylor: Yeah, there's 2 of them there. There's like the python, Msp, download large and pip in stock Kiras process.

1809
01:54:42.620 --> 01:54:45.770
Anthony Taylor: Try that, and then tell me. If it's still stuck, it's that should fix you.

1810
01:54:46.180 --> 01:54:47.010
Mason, Natalie: Okay.

1811
01:54:47.720 --> 01:54:48.820
Anthony Taylor: Not a problem

1812
01:54:49.160 --> 01:54:49.799
Anthony Taylor: by you. Okay.

1813
01:54:50.076 --> 01:54:51.179
Masarirambi, Rodney: Whole east coast, thing.

1814
01:54:51.750 --> 01:54:52.790
Mason, Natalie: I'm gonna be on.

1815
01:54:52.790 --> 01:54:53.340
Anthony Taylor: In this case.

1816
01:54:53.340 --> 01:54:55.609
Mason, Natalie: I have to go to Florida on Friday.

1817
01:54:56.150 --> 01:54:57.960
Masarirambi, Rodney: I leave Florida on Friday.

1818
01:54:59.520 --> 01:55:01.569
Masarirambi, Rodney: I'm on Martha Island right now.

1819
01:55:02.190 --> 01:55:04.599
Anthony Taylor: For your graduation. I will be employed

1820
01:55:07.280 --> 01:55:08.190
Anthony Taylor: anyway.

1821
01:55:08.330 --> 01:55:09.145
Anthony Taylor: Okay,

1822
01:55:10.670 --> 01:55:15.289
Anthony Taylor: alright. So here we can print them out. You can see each word.

1823
01:55:15.700 --> 01:55:20.200
Anthony Taylor: How often it is in the first 4 chapters of what we did. Very cool.

1824
01:55:20.550 --> 01:55:21.410
Anthony Taylor: Ken.

1825
01:55:24.470 --> 01:55:29.330
Anthony Taylor: What is the size? So how many words are in our vocabulary, 2,718

1826
01:55:29.730 --> 01:55:30.869
Anthony Taylor: pretty cool.

1827
01:55:31.750 --> 01:55:41.580
Anthony Taylor: We can encode. So we're going to encode each word and let's print some out. We can see now they're basically encoded to their index. So that's kind of cool.

1828
01:55:41.780 --> 01:55:42.700
Anthony Taylor: Okay.

1829
01:55:45.070 --> 01:55:53.869
Anthony Taylor: Now, we're going to get the words associated with the indices for the first sequence. So call me Ismail some years ago. So this should be, yeah.

1830
01:55:53.880 --> 01:55:56.160
Anthony Taylor: The first 26 words

1831
01:55:56.770 --> 01:55:59.320
Anthony Taylor: got it, and you can kind of see that here.

1832
01:56:01.650 --> 01:56:02.580
Anthony Taylor: And yet.

1833
01:56:03.960 --> 01:56:10.499
Anthony Taylor: Alright. So that's basically how it's getting what it's. So if you want to see a specific word, you can just

1834
01:56:11.140 --> 01:56:14.320
Anthony Taylor: ask for the specific index. You see the specific work.

1835
01:56:15.510 --> 01:56:20.160
Anthony Taylor: So we can also check and see how many times this word is in there

1836
01:56:20.400 --> 01:56:21.360
Anthony Taylor: by

1837
01:56:21.850 --> 01:56:29.519
Anthony Taylor: basically. So this is a set comprehension. So we can say for word and index in index dot items

1838
01:56:30.450 --> 01:56:33.720
Anthony Taylor: show me the word. And then for sequence in

1839
01:56:33.810 --> 01:56:36.780
Anthony Taylor: we can say index. 2 words dot get

1840
01:56:37.280 --> 01:56:38.130
Anthony Taylor: the

1841
01:56:38.480 --> 01:56:45.839
Anthony Taylor: index and space, and then for index and sequence. And then we're going to do plus equals, to get all 9 out of 56.

1842
01:56:45.940 --> 01:56:49.440
Anthony Taylor: And the final value is what 7

1843
01:56:49.510 --> 01:56:53.380
Anthony Taylor: so call appears in there 27 facts.

1844
01:56:55.210 --> 01:56:58.400
Anthony Taylor: This is a cool one. By the way, notice, this is very generic.

1845
01:56:58.740 --> 01:57:00.389
Anthony Taylor: You could use this anywhere.

1846
01:57:01.700 --> 01:57:02.630
Anthony Taylor: Alright.

1847
01:57:04.100 --> 01:57:04.980
Anthony Taylor: alright.

1848
01:57:05.260 --> 01:57:06.699
Anthony Taylor: numpy array.

1849
01:57:06.840 --> 01:57:09.359
Anthony Taylor: We're just going to take our sequences.

1850
01:57:09.380 --> 01:57:11.420
Anthony Taylor: Put them into an array now.

1851
01:57:12.060 --> 01:57:17.660
Anthony Taylor: Okay. So now all of our sequences that we made up here that look like this. We have now

1852
01:57:18.300 --> 01:57:21.750
Anthony Taylor: created an array of arrays with all of those sequences.

1853
01:57:22.130 --> 01:57:24.180
Anthony Taylor: This is what the model is looking for

1854
01:57:26.010 --> 01:57:27.499
Anthony Taylor: we can do a link

1855
01:57:28.450 --> 01:57:33.800
Anthony Taylor: we can print out like first one. We've seen this before. The same one is up above.

1856
01:57:35.930 --> 01:57:40.729
Anthony Taylor: Alright. So we're gonna one hot encode, the target variable. What's the target? Variable.

1857
01:57:48.906 --> 01:57:49.480
Vasquez, Gabriel: Last word.

1858
01:57:49.480 --> 01:57:50.439
Clayton Graves: Target word.

1859
01:57:50.720 --> 01:57:51.569
Clayton Graves: the target of like.

1860
01:57:51.570 --> 01:57:59.309
Anthony Taylor: Last word. I think Gabe said it right. But yes, also, it's the last word in the sequence of 26.

1861
01:57:59.880 --> 01:58:08.360
Anthony Taylor: Okay? So we're going to come here. Then we're going to say, Okay, give me everything but the last word.

1862
01:58:08.600 --> 01:58:10.720
Anthony Taylor: and that will be our X

1863
01:58:10.800 --> 01:58:11.950
Anthony Taylor: values.

1864
01:58:12.700 --> 01:58:16.420
Anthony Taylor: And then here we're gonna give me the last word.

1865
01:58:16.990 --> 01:58:21.709
Anthony Taylor: There's the last word indexes. Remember, these are the indexes for the last word.

1866
01:58:22.360 --> 01:58:24.990
Anthony Taylor: Okay, and then x and y

1867
01:58:26.110 --> 01:58:27.559
Anthony Taylor: alright. So now we have

1868
01:58:27.730 --> 01:58:31.140
Anthony Taylor: all of our 25 words.

1869
01:58:32.110 --> 01:58:36.180
Anthony Taylor: and they and the 20 sixth word is right here.

1870
01:58:37.260 --> 01:58:40.629
Anthony Taylor: So remember what we're trying to build is text completion.

1871
01:58:41.400 --> 01:58:43.490
Anthony Taylor: Now, it's really

1872
01:58:43.830 --> 01:58:51.389
Anthony Taylor: they're they're trying to call it text generation. But it's really completion. Most Llms, by the way, are really completion.

1873
01:58:52.220 --> 01:59:00.189
Anthony Taylor: Okay. When when properly prompted, you should always leave the prompt with like an like an open

1874
01:59:00.420 --> 01:59:01.280
Anthony Taylor: like.

1875
01:59:01.470 --> 01:59:03.060
Anthony Taylor: and like

1876
01:59:03.830 --> 01:59:06.369
Anthony Taylor: alright. To do this I would

1877
01:59:06.530 --> 01:59:09.619
Anthony Taylor: blank, and then it understands better. But

1878
01:59:09.830 --> 01:59:12.039
Anthony Taylor: these days. They're they're pretty good either way.

1879
01:59:12.280 --> 01:59:16.939
Anthony Taylor: Okay? So now we can look at the shape we see, we have 11,312, which is correct

1880
01:59:17.040 --> 01:59:18.000
Anthony Taylor: and

1881
01:59:18.360 --> 01:59:21.550
Anthony Taylor: 25 values. And we have

1882
01:59:22.320 --> 01:59:25.760
Anthony Taylor: alright. Oh, okay, yeah. So and then, so we have 25

1883
01:59:26.060 --> 01:59:27.310
Anthony Taylor: words

1884
01:59:27.580 --> 01:59:30.249
Anthony Taylor: in our model, our Y shape.

1885
01:59:30.520 --> 01:59:32.500
Anthony Taylor: It's just the same number. Yes.

1886
01:59:32.990 --> 01:59:33.480
Clayton Graves: Finished.

1887
01:59:35.710 --> 01:59:40.130
Anthony Taylor: Oh, try to run the last couple of steps, see if you can save it and reopen.

1888
01:59:41.190 --> 01:59:43.200
Anthony Taylor: I'm going to be super pumped if you can.

1889
01:59:43.770 --> 01:59:47.350
Anthony Taylor: Okay. Which one are you doing? The instructor, one, or the student

1890
01:59:47.650 --> 01:59:49.300
Anthony Taylor: instructor? One right.

1891
01:59:49.300 --> 01:59:49.890
Clayton Graves: Yeah.

1892
01:59:50.080 --> 01:59:51.330
Anthony Taylor: Nice.

1893
01:59:51.690 --> 02:00:00.700
Anthony Taylor: Okay, so what do we do here? So here, we're basically doing 2 categorical with our values, which look, that gives us a lot

1894
02:00:01.150 --> 02:00:03.870
Anthony Taylor: of columns. But that's okay, doesn't matter.

1895
02:00:03.970 --> 02:00:06.340
Anthony Taylor: Fact, we can take a look. This is what it looks like.

1896
02:00:06.570 --> 02:00:07.689
Anthony Taylor: We have this

1897
02:00:07.830 --> 02:00:09.630
Anthony Taylor: really big array.

1898
02:00:09.950 --> 02:00:11.670
Anthony Taylor: And yeah.

1899
02:00:12.060 --> 02:00:15.450
Clayton Graves: I've got the Caris file, and I've got the tokenizer.

1900
02:00:16.140 --> 02:00:19.959
Anthony Taylor: Oh, my God, try to! And what version of tensorflow are you using?

1901
02:00:20.950 --> 02:00:22.240
Anthony Taylor: 1? 5? Right.

1902
02:00:22.880 --> 02:00:24.119
Clayton Graves: I believe so. Yes.

1903
02:00:24.830 --> 02:00:29.780
Anthony Taylor: Do you mind? Load no, load those up to slack, and let's see if we can make those work, cause I'm about to be there.

1904
02:00:30.663 --> 02:00:40.260
Anthony Taylor: Okay, so we're gonna load our sequential model. Now, that's important. Guys. Remember, we stopped using sequential model when we went to C and it.

1905
02:00:40.910 --> 02:00:46.339
Anthony Taylor: But for R and N, it's actually back to sequential. We're just adding this little loopy loop back into it.

1906
02:00:47.030 --> 02:00:48.050
Anthony Taylor: Okay?

1907
02:00:48.110 --> 02:00:53.709
Anthony Taylor: And then we're going to grab dense layer an Lstm. Layer and an embedding layer.

1908
02:00:54.150 --> 02:00:55.450
Anthony Taylor: Alright.

1909
02:00:55.980 --> 02:00:56.954
Anthony Taylor: Get to there.

1910
02:00:58.450 --> 02:01:02.560
Anthony Taylor: I know there's something special I want to say about the embedding layer, so I don't want to miss it.

1911
02:01:07.210 --> 02:01:08.060
Anthony Taylor: here we go.

1912
02:01:10.100 --> 02:01:11.000
Anthony Taylor: Okay.

1913
02:01:12.264 --> 02:01:14.750
Anthony Taylor: so we're going to import those.

1914
02:01:15.900 --> 02:01:17.440
Anthony Taylor: Hi, so

1915
02:01:17.620 --> 02:01:20.449
Anthony Taylor: this function looks really scary.

1916
02:01:20.920 --> 02:01:22.300
Anthony Taylor: Okay, it's not

1917
02:01:22.580 --> 02:01:29.509
Anthony Taylor: all right. We have an embedding layer. This maps the word indexes to the vectors, to the dense. Remember the dense layer.

1918
02:01:29.810 --> 02:01:33.559
Anthony Taylor: Okay, then we have an Lstm layer with 2 of them

1919
02:01:33.900 --> 02:01:37.090
Anthony Taylor: another dense layer and then an output layer.

1920
02:01:37.450 --> 02:01:39.790
Anthony Taylor: The only thing that's really different

1921
02:01:40.110 --> 02:01:41.709
Anthony Taylor: is these 2 guys.

1922
02:01:42.700 --> 02:01:49.940
Anthony Taylor: I realize we haven't done an embedding layer either, but this one just simply embeds the indexes. That's it.

1923
02:01:50.640 --> 02:01:57.440
Anthony Taylor: all right. So we have a sequential model. We, our first one, will be embedding the vocabulary side.

1924
02:01:57.690 --> 02:01:59.359
Anthony Taylor: which we did up above.

1925
02:02:00.466 --> 02:02:01.720
Anthony Taylor: How many

1926
02:02:02.430 --> 02:02:08.629
Anthony Taylor: basically tokens? Are we passing in 25, right? Remember 26 words minus one.

1927
02:02:09.220 --> 02:02:11.100
Anthony Taylor: And then the input link.

1928
02:02:11.310 --> 02:02:16.149
Anthony Taylor: So all of that we calculated above, these are just values. We can try.

1929
02:02:16.890 --> 02:02:19.989
Anthony Taylor: Okay, this is these are just hyper parameters.

1930
02:02:20.360 --> 02:02:21.810
Clayton Graves: It seemed alone.

1931
02:02:22.820 --> 02:02:25.269
Anthony Taylor: Oh, I love that! I hope it works.

1932
02:02:25.270 --> 02:02:25.679
Clayton Graves: What do you.

1933
02:02:25.680 --> 02:02:26.779
Anthony Taylor: Okay? And

1934
02:02:27.342 --> 02:02:32.629
Anthony Taylor: just load it. Load the the 2 files, just upload them to slack for us.

1935
02:02:33.350 --> 02:02:35.399
Anthony Taylor: We might all use your files.

1936
02:02:36.435 --> 02:02:43.279
Anthony Taylor: Which is perfect timing, because we have like 5. So and then when it's all done, it'll give us our final

1937
02:02:43.420 --> 02:02:44.330
Anthony Taylor: model.

1938
02:02:45.020 --> 02:02:45.980
Anthony Taylor: So

1939
02:02:46.240 --> 02:02:48.689
Anthony Taylor: don't get ahead of me right here. Gang.

1940
02:02:50.090 --> 02:02:53.789
Anthony Taylor: don't push play until I tell you to.

1941
02:02:54.030 --> 02:02:54.930
Anthony Taylor: So

1942
02:02:55.230 --> 02:02:59.149
Anthony Taylor: this is our model summary. We created our model with our cool function

1943
02:02:59.340 --> 02:03:00.529
Anthony Taylor: looks great.

1944
02:03:00.540 --> 02:03:02.660
Anthony Taylor: If you press this button

1945
02:03:04.150 --> 02:03:06.910
Anthony Taylor: it'll take at least 60 min to complete.

1946
02:03:07.190 --> 02:03:08.500
Anthony Taylor: Don't press that button.

1947
02:03:09.630 --> 02:03:10.460
Anthony Taylor: Okay.

1948
02:03:11.200 --> 02:03:16.239
Anthony Taylor: And then, when you were done, you would dump it out like Clayton did for us.

1949
02:03:17.680 --> 02:03:18.550
Anthony Taylor: But

1950
02:03:18.630 --> 02:03:21.729
Anthony Taylor: we're going to hopefully go load Clayton's files.

1951
02:03:22.700 --> 02:03:24.430
Anthony Taylor: Did you already load them up there, Buddy?

1952
02:03:26.150 --> 02:03:27.970
Anthony Taylor: Oh, I see him. I see him.

1953
02:03:28.160 --> 02:03:30.000
Anthony Taylor: Yeah.

1954
02:03:30.540 --> 02:03:33.440
Anthony Taylor: So everybody go download those 2 files.

1955
02:03:34.510 --> 02:03:36.110
Anthony Taylor: And

1956
02:03:37.720 --> 02:03:42.080
Anthony Taylor: I'm just gonna go. I'm just gonna put this in the root with my notebook.

1957
02:03:42.750 --> 02:03:44.709
Anthony Taylor: So I don't even have to worry about.

1958
02:03:55.320 --> 02:03:59.740
Anthony Taylor: I've downloaded these like from 3 different sources today.

1959
02:04:01.250 --> 02:04:02.620
Anthony Taylor: Hi, baby girl.

1960
02:04:03.830 --> 02:04:04.680
Anthony Taylor: that's all.

1961
02:04:05.020 --> 02:04:06.979
Anthony Taylor: Oh, you got something in your mouth.

1962
02:04:07.440 --> 02:04:09.299
Anthony Taylor: crazy dog. Okay.

1963
02:04:09.700 --> 02:04:16.140
Anthony Taylor: alright. Once you have those insert in there, go ahead. And this

1964
02:04:16.420 --> 02:04:19.539
Anthony Taylor: run generate text model.

1965
02:04:19.640 --> 02:04:23.340
Anthony Taylor: Oh, wait. So let's go through this before we get to the load?

1966
02:04:26.430 --> 02:04:29.560
Anthony Taylor: so this function does a whole bunch of stuff. Okay.

1967
02:04:30.020 --> 02:04:31.739
Anthony Taylor: keep in mind.

1968
02:04:31.770 --> 02:04:45.430
Anthony Taylor: We encoded the data on the way in. Whenever we trained it. We encoded it. We had to. We did our tokenizer. We did the labeling photo. We did everything right. So we have to do that

1969
02:04:46.326 --> 02:04:47.500
Anthony Taylor: every time.

1970
02:04:47.770 --> 02:04:49.759
Anthony Taylor: So here we have.

1971
02:04:50.860 --> 02:04:55.570
Anthony Taylor: We're we're encoding the text. So whatever we pass in

1972
02:04:56.190 --> 02:05:10.640
Anthony Taylor: the model, the Tokenizer, the length, the seed, and the number of generated words. So we're gonna say, okay. So we want to get this many words. So the encoded text comes in, which is what we are trying to predict from.

1973
02:05:10.790 --> 02:05:15.179
Anthony Taylor: Alright, we're gonna pad it to make sure it's at least 25

1974
02:05:15.220 --> 02:05:16.390
Anthony Taylor: characters.

1975
02:05:16.810 --> 02:05:19.609
Anthony Taylor: Then we're going to run model, predict.

1976
02:05:20.740 --> 02:05:22.310
Anthony Taylor: predict the word.

1977
02:05:22.350 --> 02:05:24.760
Anthony Taylor: Okay, get the Max values

1978
02:05:25.150 --> 02:05:29.280
Anthony Taylor: of that. So find the index of the word with the highest probability.

1979
02:05:29.410 --> 02:05:35.680
Anthony Taylor: Using our Max, we're going to look up the actual word from the tokens index to word mapping.

1980
02:05:36.060 --> 02:05:38.400
Anthony Taylor: Okay, so remember, we're going to get an index.

1981
02:05:39.200 --> 02:05:42.690
Anthony Taylor: So we think this word's going to be number 428.

1982
02:05:42.810 --> 02:05:44.880
Anthony Taylor: So we need to go find that word

1983
02:05:45.020 --> 02:05:46.639
Anthony Taylor: and then return it

1984
02:05:46.680 --> 02:05:48.070
Anthony Taylor: back to

1985
02:05:48.720 --> 02:05:54.080
Anthony Taylor: our our calling function. Okay, make sure. I set that

1986
02:05:54.450 --> 02:05:56.999
Anthony Taylor: alright. Let's do random.

1987
02:05:58.023 --> 02:06:03.120
Anthony Taylor: Pick a random sequence of. So we're just going to grab 26 fake words at this point.

1988
02:06:03.300 --> 02:06:05.429
Anthony Taylor: man who pour their money to lava.

1989
02:06:05.500 --> 02:06:08.980
Anthony Taylor: Alright. Let's see if this load works. Come on work.

1990
02:06:11.180 --> 02:06:12.260
Anthony Taylor: Yes.

1991
02:06:12.700 --> 02:06:15.500
Anthony Taylor: Clayton, you're the savior of the day, Buddy.

1992
02:06:16.020 --> 02:06:16.970
Anthony Taylor: Alright!

1993
02:06:17.220 --> 02:06:24.960
Anthony Taylor: I just wish I would done it earlier. I honest to God, figured I could use theirs wrong. Okay. So now that we have our models loaded

1994
02:06:25.970 --> 02:06:34.749
Anthony Taylor: right, we can now run that generate text, passing the model that we just loaded the tokenizer that we got from.

1995
02:06:34.760 --> 02:06:36.090
Anthony Taylor: They're also

1996
02:06:36.170 --> 02:06:39.269
Anthony Taylor: the sequence length, which was 25,

1997
02:06:39.400 --> 02:06:41.719
Anthony Taylor: right? The seed text.

1998
02:06:41.870 --> 02:06:43.620
Anthony Taylor: okay, so this is

1999
02:06:44.360 --> 02:06:47.929
Anthony Taylor: the text that we're that this crazy text right here.

2000
02:06:47.970 --> 02:06:51.459
Anthony Taylor: Okay? And then the number of words that we used was 25.

2001
02:06:51.630 --> 02:06:53.460
Anthony Taylor: Alright. So we could run that.

2002
02:06:54.140 --> 02:07:00.440
Anthony Taylor: and it should run, and within the villainous green goggling glasses deceitfully tabored forth blah blah blah

2003
02:07:00.590 --> 02:07:01.740
Anthony Taylor: goblets.

2004
02:07:04.650 --> 02:07:07.560
Anthony Taylor: I know it's such. So non-finactive.

2005
02:07:07.570 --> 02:07:10.080
Anthony Taylor: So let's try this with something a little more logical.

2006
02:07:10.530 --> 02:07:21.720
Anthony Taylor: So here's 25 words. Seeing now that there were no curtains to the window, and that the street being very narrow. The house opposite commanded a plain view into the room, and

2007
02:07:23.420 --> 02:07:26.270
Anthony Taylor: I felt like I should have had an English accent while doing that.

2008
02:07:28.490 --> 02:07:30.990
Anthony Taylor: Okay, so here's our seed text.

2009
02:07:31.250 --> 02:07:33.599
Anthony Taylor: So we're going to separate the punctuation.

2010
02:07:33.810 --> 02:07:38.450
Anthony Taylor: We're going to print the tokens. And then we're going to save it to see text.

2011
02:07:39.100 --> 02:07:40.839
Anthony Taylor: So this is what we end up with.

2012
02:07:41.490 --> 02:07:43.540
Anthony Taylor: And now we're going to use our generate.

2013
02:07:46.220 --> 02:07:48.630
Anthony Taylor: And then now we should see

2014
02:07:51.730 --> 02:07:53.630
Anthony Taylor: room and

2015
02:07:56.710 --> 02:07:59.190
Anthony Taylor: observing more and more good sportsmanship thing

2016
02:07:59.680 --> 02:08:00.800
Anthony Taylor: whatever.

2017
02:08:01.170 --> 02:08:03.300
Anthony Taylor: Okay? And then that's

2018
02:08:04.440 --> 02:08:07.320
Anthony Taylor: what it came up with. Then here's

2019
02:08:07.720 --> 02:08:08.590
Anthony Taylor: there you go.

2020
02:08:09.960 --> 02:08:10.940
Anthony Taylor: So

2021
02:08:11.370 --> 02:08:13.300
Anthony Taylor: in the actual text.

2022
02:08:13.350 --> 02:08:14.879
Anthony Taylor: this is what it says.

2023
02:08:15.130 --> 02:08:16.250
Anthony Taylor: and

2024
02:08:17.640 --> 02:08:18.510
Anthony Taylor: it did it.

2025
02:08:20.110 --> 02:08:24.209
Anthony Taylor: You see how I did this? So this is what it says in the text. This is what we sent in.

2026
02:08:24.450 --> 02:08:26.160
Anthony Taylor: and this is what it came back

2027
02:08:27.130 --> 02:08:28.740
Anthony Taylor: more or less, did it not.

2028
02:08:28.940 --> 02:08:32.709
Baro, Sonja: I I can't read it myself. I don't know if anybody else can

2029
02:08:33.140 --> 02:08:34.320
Baro, Sonja: in blue.

2030
02:08:35.390 --> 02:08:39.619
Anthony Taylor: It says, observing more and more the into Chris figure that

2031
02:08:40.280 --> 02:08:41.600
Anthony Taylor: Queen Quig

2032
02:08:42.340 --> 02:08:46.750
Anthony Taylor: made stabbing about with little else but his hat and boots on.

2033
02:08:46.810 --> 02:08:50.979
Anthony Taylor: I begged him, as well as I could, to accelerate his toilet somewhat.

2034
02:08:51.010 --> 02:08:54.769
Anthony Taylor: and particularly to get into the pantaloons as soon as possible.

2035
02:08:55.320 --> 02:08:56.950
Anthony Taylor: Why would they pick that

2036
02:08:57.330 --> 02:08:59.289
Anthony Taylor: excerpt. They're so weird.

2037
02:09:02.070 --> 02:09:02.980
Anthony Taylor: But yeah.

2038
02:09:03.600 --> 02:09:09.739
Anthony Taylor: so how could we do better? We could like, if we wanted the next 50 words, you could pass this in

2039
02:09:11.020 --> 02:09:11.920
Anthony Taylor: we could.

2040
02:09:12.160 --> 02:09:17.689
Anthony Taylor: We could do all kinds of things. So it's just talk about, how could we do this differently? But we could train it in different ways.

2041
02:09:18.080 --> 02:09:21.090
Anthony Taylor: Okay, tell it to use less words, more words.

2042
02:09:21.570 --> 02:09:22.600
Anthony Taylor: whichever.

2043
02:09:23.890 --> 02:09:24.770
Anthony Taylor: So

2044
02:09:25.870 --> 02:09:27.550
Anthony Taylor: to summarize.

2045
02:09:28.759 --> 02:09:33.550
Anthony Taylor: There is another activity. If you guys want to do it, I'll put South in tonight.

2046
02:09:34.140 --> 02:09:38.059
Anthony Taylor: you will have to let it train for like the full 60 min

2047
02:09:38.140 --> 02:09:42.680
Anthony Taylor: to get it to work, because the one that they gave you will have the same problem.

2048
02:09:47.080 --> 02:09:49.859
Anthony Taylor: this is the old way of doing it.

2049
02:09:54.140 --> 02:09:56.020
Anthony Taylor: It's good to know.

2050
02:09:56.110 --> 02:09:58.719
Anthony Taylor: Remember, 2,007.

2051
02:09:59.510 --> 02:10:02.390
Anthony Taylor: What's the date? 2,024

2052
02:10:02.630 --> 02:10:04.550
Anthony Taylor: long time ago.

2053
02:10:06.750 --> 02:10:10.780
Anthony Taylor: I mean, was any of you not born in 2,007, curry

2054
02:10:12.600 --> 02:10:13.320
Anthony Taylor: back?

2055
02:10:14.400 --> 02:10:15.469
Anthony Taylor: Steve's a buddy.

2056
02:10:15.620 --> 02:10:16.950
Curry Gardner: No, I was alive.

2057
02:10:17.550 --> 02:10:17.900
Anthony Taylor: Oh!

2058
02:10:17.900 --> 02:10:19.360
Curry Gardner: Over. I'm not that young.

2059
02:10:21.920 --> 02:10:26.969
Anthony Taylor: So. But the point is, that was a long time ago, and that's where we are in the timeline.

2060
02:10:27.430 --> 02:10:33.560
Anthony Taylor: Okay, starting next week, we are going to jump to 2 or starting Wednesday, we're going to jump to 2,020.

2061
02:10:34.390 --> 02:10:38.079
Anthony Taylor: Okay. And things are, gonna get a little more interesting.

2062
02:10:38.090 --> 02:10:41.299
Anthony Taylor: And I'm going to give you one last wonderful

2063
02:10:41.620 --> 02:10:42.620
Anthony Taylor: statement.

2064
02:10:43.210 --> 02:10:45.210
Anthony Taylor: And you're gonna love me for this.

2065
02:10:45.930 --> 02:10:48.160
Anthony Taylor: It gets way easier, too.

2066
02:10:49.630 --> 02:10:50.740
Anthony Taylor: Okay.

2067
02:10:50.820 --> 02:10:55.840
Anthony Taylor: to use the ll ends and to do a lot of this stuff is so much easier

2068
02:10:55.910 --> 02:10:58.269
Anthony Taylor: than what you guys are used to working with now.

2069
02:10:58.710 --> 02:11:01.789
Anthony Taylor: So the next 2 weeks before project

2070
02:11:02.750 --> 02:11:06.399
Anthony Taylor: getting time and learning some fun stuff.

2071
02:11:06.890 --> 02:11:07.720
Anthony Taylor: Aye.

2072
02:11:08.170 --> 02:11:12.729
Anthony Taylor: so I got you guys do remember I'm not here Thursday. I do not know who you subscribe.

2073
02:11:13.930 --> 02:11:15.820
Anthony Taylor: Okay, so

2074
02:11:16.430 --> 02:11:19.270
Anthony Taylor: I don't know. Maybe we'll have Matt do it just for fun.

2075
02:11:23.930 --> 02:11:25.720
Anthony Taylor: Matter, Jennifer.

2076
02:11:27.270 --> 02:11:29.430
Anthony Taylor: but we could really have fun. Have plate

2077
02:11:31.590 --> 02:11:32.730
Anthony Taylor: that could be fun

2078
02:11:33.160 --> 02:11:34.650
Anthony Taylor: just here, cling.

2079
02:11:34.650 --> 02:11:35.780
Mason, Natalie: Group, teach.

2080
02:11:36.840 --> 02:11:40.279
Anthony Taylor: There you go, anyway, I'm sure you'll have a wonderful instructor.

2081
02:11:42.040 --> 02:11:47.280
Anthony Taylor: I will see you Wednesday, though, to start transformers. I'm super excited. Have a great Tuesday.

2082
02:11:47.640 --> 02:11:48.870
Anthony Taylor: Later on

2083
02:11:49.150 --> 02:11:49.820
Anthony Taylor: we'll be here.

