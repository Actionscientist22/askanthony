WEBVTT

1
00:00:05.310 --> 00:00:06.970
Anthony Taylor: Old class today.

2
00:00:08.650 --> 00:00:13.570
Anthony Taylor: Nonlinear classification. What does that tell us? Well, we did logistic regression

3
00:00:13.800 --> 00:00:19.250
Anthony Taylor: right? Which use that sigmoid curve to give us

4
00:00:19.320 --> 00:00:22.419
Anthony Taylor: binary but

5
00:00:22.430 --> 00:00:27.180
Anthony Taylor: one of the fun things. And when we did, Sbm, we talked about

6
00:00:27.330 --> 00:00:31.140
Anthony Taylor: that. You know. It drew a line and it created

7
00:00:31.200 --> 00:00:37.760
Anthony Taylor: the boundaries there, and and and it would it could do that. Okay, I will tell you.

8
00:00:37.890 --> 00:00:49.949
Anthony Taylor: In addition to those type things it is possible to do nonlinear svns. Now this goes back to that kernel. Remember the Colonel. not the one with the chicken.

9
00:00:50.900 --> 00:00:53.780
Anthony Taylor: Okay, the kernel like a popcorn, Colonel.

10
00:00:53.990 --> 00:01:04.289
Anthony Taylor: Right? You can select different kernels and get a different result.  so you can do something like this. Is it great at it? Yeah.

11
00:01:04.400 --> 00:01:07.899
Anthony Taylor: it's okay. But here's the secret.

12
00:01:09.050 --> 00:01:13.120
Anthony Taylor: This is in 2 dimensions.

13
00:01:13.880 --> 00:01:17.550
Anthony Taylor: All right. If you break this into 3 dimensions.

14
00:01:18.250 --> 00:01:19.540
Anthony Taylor: perhaps

15
00:01:19.920 --> 00:01:23.620
Anthony Taylor: a plane could be drawn in between these 2,

16
00:01:24.240 --> 00:01:31.149
Anthony Taylor: you got it. This doesn't always work out this way. But this is the thing that Svm. Would be very good at

17
00:01:31.670 --> 00:01:35.330
Anthony Taylor: versus this. Not good. This

18
00:01:35.830 --> 00:01:36.810
Anthony Taylor: spectac.

19
00:01:37.870 --> 00:01:39.560
Anthony Taylor: Does that make sense. Yeah, Ron.

20
00:01:40.630 --> 00:01:43.769
Masarirambi, Rodney: okay? And that first one's just taking the piss. Now.

21
00:01:43.900 --> 00:01:45.440
Masarirambi, Rodney: this one.

22
00:01:45.760 --> 00:01:49.510
Anthony Taylor: yeah, I'm gonna tell you a secret.

23
00:01:49.550 --> 00:01:59.880
Anthony Taylor: I'm gonna tell you a secret. By the time you guys are done you will be able to model this in the machine learning model. not with Svm. but you could do this. And Sv and me.

24
00:02:00.670 --> 00:02:12.739
Anthony Taylor: Okay, cause it's messing with you. Alright, And and here's the different kernels and how they work. And yeah, you can get some curves, and you can get some other fun stuff.

25
00:02:12.800 --> 00:02:14.950
Anthony Taylor: it's pretty cool. Okay.

26
00:02:15.180 --> 00:02:16.670
honestly, guys.

27
00:02:17.300 --> 00:02:19.310
Anthony Taylor: remember, it's a progression.

28
00:02:19.870 --> 00:02:28.379
Anthony Taylor: Okay, it's probably not linear regression that one you can usually eliminate right away. But if it's binary you're going to throw logistic regression at it every single time.

29
00:02:28.600 --> 00:02:31.540
Anthony Taylor: If it's good enough you're done, stop there.

30
00:02:32.210 --> 00:02:44.329
Anthony Taylor: If it's not good enough, you're going to go to the next more complicated one, which would be Sbc. okay. so that would be a little more complicated. But still so mathematically simple.

31
00:02:44.400 --> 00:02:50.719
Anthony Taylor: Then it's going to be really fast. And now we're going to start building into

32
00:02:50.770 --> 00:02:59.749
Anthony Taylor: the next level model and the next level model. the the the best modeling that you guys are going to find. We're going to learn right after Project 2.

33
00:03:00.760 --> 00:03:02.289
Anthony Taylor: It's fantastic.

34
00:03:03.410 --> 00:03:09.970
Anthony Taylor: It is incredibly compute expensive fact, we can't even do. We're gonna have to go back to Google.

35
00:03:10.300 --> 00:03:14.720
Anthony Taylor:  colab

36
00:03:14.970 --> 00:03:20.059
Anthony Taylor: to actually use it, because it's just too much for most of our laptops.

37
00:03:20.730 --> 00:03:27.040
Anthony Taylor: Okay, speaking of too much for most of our laptops. At 1 point today, there is a graphical

38
00:03:27.910 --> 00:03:33.850
Anthony Taylor: plot that is really cool. The good news is. There are images in your

39
00:03:34.110 --> 00:03:39.559
Anthony Taylor: in your folders, in your, in your folders. We're not going to generate that plot. Sorry

40
00:03:39.690 --> 00:03:41.950
Anthony Taylor: I would have loved to, but

41
00:03:41.980 --> 00:03:50.959
Anthony Taylor: in the past. It's just too hard to get it installed on everybody's computer. So rather than waste that time, we're gonna move on by, if you really, really, really

42
00:03:51.350 --> 00:03:54.569
Anthony Taylor: what this installed, we can

43
00:03:54.740 --> 00:03:56.880
Anthony Taylor: maybe look into it. Okay.

44
00:03:57.490 --> 00:03:59.080
officeups office.

45
00:03:59.980 --> 00:04:01.760
Anthony Taylor: So

46
00:04:03.470 --> 00:04:05.379
Anthony Taylor: model number 3, 4,

47
00:04:05.730 --> 00:04:08.580
Anthony Taylor: linear regression. logistic regression.

48
00:04:09.650 --> 00:04:11.520
Anthony Taylor: Sb ends.

49
00:04:12.350 --> 00:04:24.089
Anthony Taylor: k in it like not even using. This is all supervised. So km, nearest neighbor, it's super popular. the logic behind. Km, it's so

50
00:04:24.130 --> 00:04:31.680
Anthony Taylor: easy to understand how it works. Okay? And it's not a whole lot different

51
00:04:31.800 --> 00:04:33.810
Anthony Taylor: then, K-means.

52
00:04:34.030 --> 00:04:44.320
Anthony Taylor: But you'll see. So what does it do? Well, it compares the known data points to determine the classification of a novel data. I hate that. They use words like that. But here we go.

53
00:04:45.060 --> 00:04:47.990
Anthony Taylor: It says, I have these

54
00:04:48.070 --> 00:04:51.509
Anthony Taylor: classified. So remember, these are classified already. They're labeled.

55
00:04:52.540 --> 00:04:56.550
Anthony Taylor: Okay, so these are blue squares. That's the label blue square.

56
00:04:57.190 --> 00:05:01.019
Anthony Taylor: And these are yellow triangles. That's the label yellow triangle.

57
00:05:01.080 --> 00:05:02.909
Anthony Taylor: So what is that dot right there.

58
00:05:04.880 --> 00:05:10.449
Anthony Taylor: Well, depends on what number we pass in to K. And N.

59
00:05:10.560 --> 00:05:15.270
Anthony Taylor: We're going to say. I want you to compare this value to the

60
00:05:15.400 --> 00:05:17.339
Anthony Taylor: 3 nearest neighbors.

61
00:05:20.440 --> 00:05:22.049
Anthony Taylor: and then give me the answer.

62
00:05:22.570 --> 00:05:29.369
Anthony Taylor: Well, in this example. What are the 3 nearest neighbors? Triangle, triangle squared? So what is the answer to triangle.

63
00:05:31.090 --> 00:05:33.879
Anthony Taylor: Now, that's wonderful, except

64
00:05:34.300 --> 00:05:35.720
Anthony Taylor: it can change.

65
00:05:37.720 --> 00:05:40.300
Anthony Taylor: So here we do. K equals one

66
00:05:40.580 --> 00:05:44.420
Anthony Taylor: still a triangle. But now we did. K equals 3. And look what happened.

67
00:05:48.030 --> 00:05:53.619
Anthony Taylor: Okay, so this is another thing similar to the clustering exercise that we have.

68
00:05:53.860 --> 00:05:56.539
Anthony Taylor: that we have to look at it and go.

69
00:05:59.200 --> 00:06:01.430
Anthony Taylor: You know there must be the right number.

70
00:06:02.800 --> 00:06:12.239
Anthony Taylor: right, that we must be able to pass it. The right value to get this model to be accurate more often than not.

71
00:06:13.020 --> 00:06:14.690
Anthony Taylor: and we will do.

72
00:06:15.330 --> 00:06:17.680
Anthony Taylor: Okay. Oh, here's Kate 7.

73
00:06:18.350 --> 00:06:26.749
Anthony Taylor: So we went from K equals one. It was Triangle. Now it's a square. Now it's a triangle again. I do want you to know

74
00:06:27.350 --> 00:06:29.980
Anthony Taylor: we do not do even numbers.

75
00:06:32.210 --> 00:06:35.199
Anthony Taylor: Okay, can you understand why we wouldn't do even numbers?

76
00:06:36.360 --> 00:06:41.370
Anthony Taylor: We would have a time ties, not good. Okay?

77
00:06:41.650 --> 00:06:45.939
Anthony Taylor: So this should look very familiar to all of you.

78
00:06:46.440 --> 00:06:47.680
Anthony Taylor: doesn't it? Now.

79
00:06:47.870 --> 00:06:52.210
Anthony Taylor: didn't we do this with with K-means like over and over and over and over again.

80
00:06:52.410 --> 00:06:53.410
Anthony Taylor: Same thing.

81
00:06:53.870 --> 00:06:59.169
Anthony Taylor: We're going to pass in. We're going to run a whole bunch of models. We're going to get the output

82
00:06:59.500 --> 00:07:03.100
Anthony Taylor: and now I'm going to show you what that's gonna look like.

83
00:07:05.100 --> 00:07:08.560
Anthony Taylor: So look like that. But let's go to the top.

84
00:07:09.230 --> 00:07:12.100
Anthony Taylor: Okay, so we're gonna bring in

85
00:07:12.150 --> 00:07:16.149
Anthony Taylor: K. Neighbor classifier from Sk. Learn neighbors.

86
00:07:16.950 --> 00:07:19.449
Anthony Taylor: The rest of these you've seen before.

87
00:07:21.390 --> 00:07:22.270
Anthony Taylor: Alright.

88
00:07:24.650 --> 00:07:33.389
Anthony Taylor: we have this cool data set. It's research conducted the test rule-based system, Beagle to determine whether glass was of type, float

89
00:07:33.500 --> 00:07:36.770
Anthony Taylor: glass or not. 6 types of glass were defined.

90
00:07:36.890 --> 00:07:38.119
Anthony Taylor: So that's kind of cool.

91
00:07:38.150 --> 00:07:39.930
Anthony Taylor: Okay, this is, I don't know

92
00:07:39.950 --> 00:07:43.550
Anthony Taylor: we have any like glass specialists or geologists in here.

93
00:07:45.170 --> 00:07:46.600
Anthony Taylor: No, alright.

94
00:07:47.870 --> 00:07:51.960
Anthony Taylor: So here we're gonna bring in this data and see what it is. Bar glasses.

95
00:07:52.740 --> 00:07:57.790
Anthony Taylor: bar glass. Mike's an expert at bar glasses. Pretty sure that's this.

96
00:07:59.570 --> 00:08:09.129
Anthony Taylor: anyway. And we're going to be looking at that variable, the glass variable. So we're gonna drop that to create our X axis, our feature set.

97
00:08:09.170 --> 00:08:14.470
Anthony Taylor: And we're going to add that to our way of people. We'll do train, test, split

98
00:08:14.720 --> 00:08:20.630
Anthony Taylor: guys. It all looks the same, doesn't it? It's like it's the same damn thing. Every day. Anthony teaches something new.

99
00:08:21.440 --> 00:08:22.420
Anthony Taylor: Okay.

100
00:08:22.710 --> 00:08:29.319
Anthony Taylor: we're going to standard scale our training data. Notice. We're no longer doing fit transform. We're fitting it.

101
00:08:29.390 --> 00:08:31.660
Anthony Taylor: And then we're transforming it

102
00:08:31.790 --> 00:08:35.750
Anthony Taylor: to both our train and our tests, which is what we learned the other day.

103
00:08:35.870 --> 00:08:37.620
Anthony Taylor: This is the proper way to do.

104
00:08:38.679 --> 00:08:48.009
Anthony Taylor: Okay. Now, this should look remarkably similar to our K-mean stuff. We're going to have a list.

105
00:08:48.330 --> 00:08:51.880
Anthony Taylor: This one's gonna hold scores. We're gonna say.

106
00:08:52.300 --> 00:08:55.280
Anthony Taylor: model with whatever number we're on.

107
00:08:56.060 --> 00:08:58.740
Anthony Taylor: Train it, score it.

108
00:08:58.770 --> 00:08:59.909
Anthony Taylor: append it.

109
00:09:00.030 --> 00:09:02.140
Anthony Taylor: print it, do it again

110
00:09:02.900 --> 00:09:04.169
Anthony Taylor: when you're done.

111
00:09:04.550 --> 00:09:06.640
Anthony Taylor: Give me a plot.

112
00:09:09.920 --> 00:09:11.370
Anthony Taylor: And it's done.

113
00:09:11.490 --> 00:09:13.480
Anthony Taylor: Okay? So

114
00:09:13.670 --> 00:09:19.819
Anthony Taylor: what we're looking for here is this kind of crossover. Okay, we're looking to see

115
00:09:20.980 --> 00:09:24.060
Anthony Taylor: basically where the points

116
00:09:24.370 --> 00:09:29.610
Anthony Taylor: are crossed over so you could go here. You could go here.

117
00:09:30.990 --> 00:09:32.669
Anthony Taylor: Yes, Meredith, sorry.

118
00:09:33.150 --> 00:09:42.719
Meredith McCanse (she/her): No, it's okay. Quick question. Up above in the where you had 4 K in range 1, 20, and then 2, was the 2 telling it to do every other number.

119
00:09:44.240 --> 00:09:46.609
Anthony Taylor: the 2 telling it to do every other number.

120
00:09:47.740 --> 00:09:51.119
Meredith McCanse (she/her): But here. Yes, it was giving us odd numbers.

121
00:09:51.400 --> 00:09:56.589
Meredith McCanse (she/her): So it said, like, start at one, and then do every 2 numbers

122
00:09:56.710 --> 00:10:08.940
Anthony Taylor: basically correct. So 1, 3, 5, 7, yes, 100. And then you could see it right here if you want to see it coming out. That was a great question. Thank you, Mary.

123
00:10:09.980 --> 00:10:23.369
Anthony Taylor: Okay, and so basically, what you're looking for is where these guys start to overlap and and and level out kind of like the although

124
00:10:23.590 --> 00:10:31.650
Anthony Taylor: it's another one of those at well, isn't that, you know? So we look at this guy, we say, well, those are pretty close together.

125
00:10:32.990 --> 00:10:34.050
Anthony Taylor: right?

126
00:10:34.110 --> 00:10:41.410
Anthony Taylor: These guys are really close together. But notice, since the blue is a little higher than the orange, we're going to go to the next one.

127
00:10:42.470 --> 00:10:45.369
Anthony Taylor: Okay, it's just that's just how we do it

128
00:10:45.710 --> 00:10:51.169
Anthony Taylor: alright, so you could run like a so like a 7 or 9,

129
00:10:51.570 --> 00:10:53.490
Anthony Taylor: and I think you would be in great shape.

130
00:10:53.750 --> 00:11:02.419
Anthony Taylor: But in this case they decided on 9. We run it. We got the score. So K, 9, test at 72. Let's see, what 7 would it be?

131
00:11:02.670 --> 00:11:04.100
Anthony Taylor: Just out of curiosity?

132
00:11:04.280 --> 00:11:06.019
Anthony Taylor: Yeah, 9 was better.

133
00:11:07.190 --> 00:11:09.479
Anthony Taylor: Okay, we can even go up one

134
00:11:11.520 --> 00:11:13.320
Anthony Taylor: same as same as not.

135
00:11:13.960 --> 00:11:16.900
Anthony Taylor: So 9 was our best prediction.

136
00:11:18.370 --> 00:11:24.790
Anthony Taylor: Okay? And that's how it works. That's it. I mean, this should feel remarkably similar

137
00:11:24.810 --> 00:11:28.170
Anthony Taylor: to K-means. It's almost the exact vote.

138
00:11:29.090 --> 00:11:34.650
Anthony Taylor: The only difference is the model that you're bringing in. And this is labeled data.

139
00:11:36.860 --> 00:11:39.740
Anthony Taylor: Okay? Any questions

140
00:11:41.420 --> 00:11:53.050
Meredith McCanse (she/her): predicting, again, did you? Is it the? It's the the glass. So is it either would be one or 0 one. It is glass 0. It's not glass, probably. But here we can look at.

141
00:11:53.110 --> 00:11:54.489
Anthony Taylor: We can look at more of it.

142
00:11:55.720 --> 00:12:00.080
Anthony Taylor: Let's see what

143
00:12:00.110 --> 00:12:07.880
Meredith McCanse (she/her): it said. There's 6 types. So maybe it's there you go, one but one through 6 types of glass. So

144
00:12:08.130 --> 00:12:10.449
Anthony Taylor: probably 1, 2, 3, 4, 5, 6, 7.

145
00:12:12.210 --> 00:12:16.849
Meredith McCanse (she/her): So that's 7 sites, though. So maybe there's another one. There's a missing. But we can do a value. Count.

146
00:12:17.460 --> 00:12:20.789
Anthony Taylor: Yeah. Oh, here, let's do another.

147
00:12:21.560 --> 00:12:25.529
Anthony Taylor: Actually, somebody here, how do I do a value counts on glass.

148
00:12:28.210 --> 00:12:29.530
Meredith McCanse (she/her): That's east.

149
00:12:29.680 --> 00:12:31.999
Meredith McCanse (she/her): Would it be DF. Square brackets.

150
00:12:32.030 --> 00:12:34.890
Meredith McCanse (she/her): quotes glass dot

151
00:12:36.430 --> 00:12:40.570
Meredith McCanse (she/her): value counts with the parentheses.

152
00:12:40.840 --> 00:12:43.470
Anthony Taylor: So we have 1, 2, 3, we have no. 4.

153
00:12:43.600 --> 00:12:44.960
Meredith McCanse (she/her): Hmm, okay.

154
00:12:46.320 --> 00:12:47.480
Anthony Taylor: So there's your.

155
00:12:47.970 --> 00:12:55.610
Meredith McCanse (she/her): so the prediction. So the model is, gonna predict what type of glass it is based on all the other qualities

156
00:12:56.210 --> 00:13:05.290
Anthony Taylor: absolutely. Now, here, we didn't do like the output the predictions and put it in a data frame like we did yesterday or Monday. Okay? But you may

157
00:13:05.810 --> 00:13:11.879
Anthony Taylor: right cause all you have to do. Now that we have our model, you could do code and predict on the test set.

158
00:13:12.110 --> 00:13:15.800
Anthony Taylor: and you would have your your test stuff, your your test stuff.

159
00:13:16.370 --> 00:13:17.430
Meredith McCanse (she/her): Okay?

160
00:13:18.470 --> 00:13:21.230
Anthony Taylor: I love that excellent questions.

161
00:13:22.500 --> 00:13:25.149
Anthony Taylor: Okay. alright. Let's see what we got

162
00:13:26.520 --> 00:13:37.579
Anthony Taylor: users. Starter file for activity calculate. It's basically telling, you do exactly what we just so let's look at what they give you. They're gonna give you the imports.

163
00:13:37.650 --> 00:13:39.010
Anthony Taylor: Some data

164
00:13:40.410 --> 00:13:45.889
Anthony Taylor: copy train test split. And then, yeah, all you actually got to do is that

165
00:13:46.000 --> 00:13:47.110
Anthony Taylor: that for loop?

166
00:13:51.010 --> 00:13:54.260
Anthony Taylor: They even tell you which k to use? Huh?

167
00:13:55.010 --> 00:13:57.709
Anthony Taylor: So this is like 8 lines of coke

168
00:13:58.550 --> 00:14:03.199
Anthony Taylor:  but you have 15 min to do it.

169
00:14:03.890 --> 00:14:05.709
Anthony Taylor: You should be able to knock that out.

170
00:14:06.260 --> 00:14:09.349
Anthony Taylor: Okay, let's get everybody in play.

171
00:14:12.030 --> 00:14:17.700
Anthony Taylor: Welcome back, everybody. So I'm guessing that one was pretty easy.

172
00:14:18.900 --> 00:14:21.629
Anthony Taylor: I had people back in like 30 s.

173
00:14:23.350 --> 00:14:30.500
Anthony Taylor: I did get some more information on that student, and I got her permission to talk about it. So I'll just tell you guys because it's so cool. Before we go into this.

174
00:14:31.320 --> 00:14:38.420
Anthony Taylor: I told you that she was trying to work a capital group. Right? They did. They put her on a data rotation program after the boot camp.

175
00:14:38.490 --> 00:14:45.070
Anthony Taylor: She has no degree, not even an associate's degree. She was just a receptionist, so they would not promote her.

176
00:14:45.910 --> 00:14:50.920
Anthony Taylor: goes back to what you were talking about. They would not promote her to a data position.

177
00:14:52.010 --> 00:14:59.819
Anthony Taylor: So she started applying around and she got the job at Meta and at Meta. She's working on AI models

178
00:15:01.680 --> 00:15:03.600
Anthony Taylor: for Facebook

179
00:15:04.240 --> 00:15:05.290
Anthony Taylor: crazy.

180
00:15:07.920 --> 00:15:10.460
Anthony Taylor: And she didn't know anybody there just for the day.

181
00:15:10.980 --> 00:15:20.040
Anthony Taylor:  okay. So I thought, that's a great story. I asked her if I could share with you guys. I hope that inspires some of you to realize

182
00:15:20.220 --> 00:15:20.990
Anthony Taylor: that

183
00:15:21.140 --> 00:15:27.709
Anthony Taylor: I mean, anything can happen. And most of you guys have at least previous experience that can help you get a good job.

184
00:15:28.850 --> 00:15:33.680
Anthony Taylor: Okay, that young lady, I mean. Stop, she answered. Phones. And that was it.

185
00:15:34.580 --> 00:15:35.350
Anthony Taylor: Set up

186
00:15:35.500 --> 00:15:38.789
Anthony Taylor: pretty cool, pretty amazing, all right.

187
00:15:38.930 --> 00:15:53.139
Anthony Taylor: So you got this given to you load the data. And, by the way, guys, I know I burn through the stuff they already give you, but if you have a question about it, feel free to ask or slow me down, I'm happy to tell you all about it. I just zoom

188
00:15:53.500 --> 00:16:02.049
Anthony Taylor: that since most of this is exact copies of what we've been doing every day for last weeks. that you guys are comfortable with it. If you're not

189
00:16:02.670 --> 00:16:03.840
Anthony Taylor: feel free to ask

190
00:16:04.070 --> 00:16:06.689
Meredith McCanse (she/her): couple of questions.

191
00:16:07.330 --> 00:16:08.670
Anthony Taylor: Go, Meredith.

192
00:16:08.820 --> 00:16:14.380
Meredith McCanse (she/her): Okay, on the what you have visible on your screen right here.

193
00:16:14.610 --> 00:16:30.420
Meredith McCanse (she/her): We noticed that like on Monday we saw this syntax a little bit as well with access equals one, and the in place equals true. and we were just trying to understand the vert why we have to cause. If we don't have those 2, the access one and the in place in there, it gets an error.

194
00:16:30.460 --> 00:16:42.480
Meredith McCanse (she/her): We were able, Gabe pointed out. If we don't do. I don't know. I don't remember, but gave pointed out that if you do in place false, it'll keep that results column.

195
00:16:42.520 --> 00:16:47.900
Meredith McCanse (she/her): but we couldn't figure out what the like. Why do we have to say? Access equals one. What is that accomplishing there?

196
00:16:48.190 --> 00:16:52.810
Anthony Taylor: Well, remember that the axis thing has to do with this. You got to

197
00:16:53.670 --> 00:16:54.770
Anthony Taylor: darn it.

198
00:16:58.310 --> 00:17:03.250
Anthony Taylor: Oh, there we go. The access thing has to do with rows or columns.

199
00:17:04.920 --> 00:17:10.020
Anthony Taylor: Okay, so when we do axes and trying to find a

200
00:17:10.210 --> 00:17:12.810
Anthony Taylor: I was hoping the thing would pop up for you guys.

201
00:17:13.430 --> 00:17:15.529
Anthony Taylor: it's not gonna pop up for us.

202
00:17:15.839 --> 00:17:21.560
Anthony Taylor: So let's just actually see if this helps

203
00:17:23.859 --> 00:17:30.519
Anthony Taylor: the axis one. Here comes. I'm trying to get you guys like the official definition.

204
00:17:30.560 --> 00:17:33.430
Anthony Taylor: But Axis one has to do with, are you doing a row or a column?

205
00:17:34.110 --> 00:17:46.220
Anthony Taylor: Alright, I could tell you that here we go. Second item specifies whether to drop labels from index or columns. One here. X, one means we want to drop a column. Not a row.

206
00:17:47.900 --> 00:17:49.219
Anthony Taylor: Does that make sense?

207
00:17:49.290 --> 00:17:55.339
Meredith McCanse (she/her): Okay? So we're telling it to drop. And we're dropping a column. We're not dropping a row.

208
00:17:56.040 --> 00:18:00.280
Meredith McCanse (she/her): but didn't we tell it already? Cause results? Is the name of a column?

209
00:18:00.470 --> 00:18:04.949
Meredith McCanse (she/her): It's not the name correct, but it would have looked for it as a filter in a row

210
00:18:05.960 --> 00:18:07.899
Anthony Taylor: if you didn't put one.

211
00:18:08.730 --> 00:18:12.290
Anthony Taylor: Okay, so it would be a cross instead of verbal

212
00:18:12.730 --> 00:18:29.160
Anthony Taylor: like when we do drop in a stuff. The reason we don't have to put access because that's automatically looking across rows for null values is just generally a bad function. But yeah.

213
00:18:29.830 --> 00:18:30.680
Anthony Taylor: alright.

214
00:18:30.840 --> 00:18:33.500
Anthony Taylor: okay. But I love the question.

215
00:18:33.660 --> 00:18:45.919
Anthony Taylor: Excellent. I'm glad you guys looked into it, Gabe. Great answer. The in place thing is correct. If you do not put in place is true, then then you would have to.

216
00:18:46.200 --> 00:18:48.589
Anthony Taylor: You would have to create a new data frame.

217
00:18:50.930 --> 00:18:58.869
Anthony Taylor: Okay? So what I mean by that. If you don't put in places through when you look at X-hand, it's still going to be there.

218
00:19:01.030 --> 00:19:06.249
Anthony Taylor: Alright. You would have to set X equal to something else. Does that make sense?

219
00:19:08.370 --> 00:19:10.940
Meredith McCanse (she/her): Yeah. thank you.

220
00:19:11.350 --> 00:19:17.680
Anthony Taylor: Okay, everybody. Good. With that. So in place, just means you don't have to save this to a new data frame.

221
00:19:18.730 --> 00:19:22.359
Anthony Taylor: We're just gonna do it in the existing data frame that you're calling from.

222
00:19:23.090 --> 00:19:25.890
Meredith McCanse (she/her): Okay? Alright. thank you.

223
00:19:26.190 --> 00:19:29.909
Anthony Taylor: You're very welcome. Okay. Now, how do I get rid of this stupid thing?

224
00:19:30.600 --> 00:19:31.730
There we go.

225
00:19:32.010 --> 00:19:32.880
Anthony Taylor: Okay.

226
00:19:33.870 --> 00:19:49.859
Anthony Taylor: I found a useful thing for co-pilot. I really like it better when it just tells me when it does the pop up. But it's not so. Okay, so and then here, we're only going to select the result column and put it into a new

227
00:19:50.220 --> 00:19:51.260
Anthony Taylor: variable.

228
00:19:52.680 --> 00:19:56.980
Anthony Taylor: We're gonna do our train test split with our feature set

229
00:19:57.080 --> 00:20:04.230
Anthony Taylor: and our new target variable. We're going to train our standard scalar

230
00:20:04.250 --> 00:20:05.819
Anthony Taylor: on the training data

231
00:20:06.210 --> 00:20:14.569
Anthony Taylor: we're going to apply. Or, if you prefer, we're going to transform our training data and transform our testing data.

232
00:20:16.520 --> 00:20:29.170
Anthony Taylor: And now, here's what they asked you to code alright. So you're gonna have 2 lists, one for transcares, one for test. one to 20, skipping every other one. So you get all odd numbers.

233
00:20:29.890 --> 00:20:32.590
Anthony Taylor: initiate the model with K value.

234
00:20:33.550 --> 00:20:40.390
Anthony Taylor: train the model on the training data, score the model on both the training and the testing data.

235
00:20:40.740 --> 00:20:45.010
Anthony Taylor: and then add those scores to your empty list.

236
00:20:45.580 --> 00:20:47.419
Anthony Taylor: Print them out just for giggles.

237
00:20:47.540 --> 00:20:53.179
Anthony Taylor: When you're done we're going to plot our training scores and our test scores

238
00:20:53.380 --> 00:20:57.459
Anthony Taylor: so that we can get a good idea of where they cross.

239
00:21:09.490 --> 00:21:14.090
Anthony Taylor: So in this case, you can see.

240
00:21:14.300 --> 00:21:25.220
Anthony Taylor: See, I would I me personally, if I was starting this, I would probably have grant one here first. because, as you can see, the the score goes below

241
00:21:25.540 --> 00:21:33.949
Anthony Taylor: right so often. That's what you're gonna look at I know that 9 is gonna be better because we've done this already. But

242
00:21:34.270 --> 00:21:45.030
Anthony Taylor: I would have probably at least tested this one out also. Okay. but you're looking for that crossover. And after a crisis, you want to look at the next one. Yeah, man.

243
00:21:46.420 --> 00:21:50.210
Dipinto, Matt: question. So it

244
00:21:50.860 --> 00:21:57.870
Dipinto, Matt: with the last example. We did. We, you know, saw the crossover, and it really it made sense because the testing scores were also increasing.

245
00:21:57.890 --> 00:22:02.829
Dipinto, Matt: But with this one I mean and acknowledge that the answer is probably

246
00:22:02.900 --> 00:22:04.150
Dipinto, Matt: Well, yeah. But

247
00:22:04.720 --> 00:22:19.379
Dipinto, Matt: if we go from, you know, 3 to 7 where they cross. both the testing and training scores are lower. And is that just to avoid having an over fit model that we try and like, you know, make it to that level.

248
00:22:19.860 --> 00:22:22.260
Anthony Taylor: Yeah. Well, so look at like

249
00:22:23.020 --> 00:22:27.610
Anthony Taylor: what what you're really looking for in this case is like the really close similarity.

250
00:22:27.730 --> 00:22:40.080
Anthony Taylor: But we want our our training score and our testing score to be close to equal. So yeah, so like this first one is, well, it's just crap, right? I mean, it's no good.

251
00:22:40.430 --> 00:22:45.379
Anthony Taylor: you know. And as you start to see this pretty much between you guys

252
00:22:45.440 --> 00:22:49.950
Anthony Taylor: you could play with, I would say the score probably going to stay the same through the rest of this

253
00:22:50.540 --> 00:22:54.410
Anthony Taylor: or be very, very similar. Right?

254
00:22:54.560 --> 00:22:58.250
Anthony Taylor: The yeah, it's just

255
00:23:01.710 --> 00:23:09.690
Anthony Taylor: this is one of those things where it's like, you know, through trial and error. I've tested this and seen this, and it just works out this way.

256
00:23:09.710 --> 00:23:17.709
Anthony Taylor: that this is the best choice you can do this, and sometimes you'll get a fine model. But to get the best score

257
00:23:18.330 --> 00:23:22.169
Anthony Taylor: for both training and test, we typically look at this overlap right?

258
00:23:22.800 --> 00:23:30.089
Anthony Taylor: Right? And the most consistent. As you add more data. I agree with you. It doesn't always look that way.

259
00:23:30.190 --> 00:23:34.059
Anthony Taylor: But that's just because it's it's just crazy.

260
00:23:34.210 --> 00:23:36.990
Anthony Taylor: Actually, yeah, 98, 96,

261
00:23:37.460 --> 00:23:40.380
Anthony Taylor: 96, 9, 96, one

262
00:23:40.590 --> 00:23:45.150
Anthony Taylor: 95. Cause. Your training score is steadily going down any

263
00:23:47.130 --> 00:23:50.140
Anthony Taylor: as we get more and more neighbors.

264
00:23:50.670 --> 00:23:53.050
Anthony Taylor: Okay, but this is what we see is the best.

265
00:23:53.750 --> 00:23:59.959
Anthony Taylor: and the the main reason for that is, think about what it's doing. Remember the dots. Remember

266
00:24:03.730 --> 00:24:04.690
Anthony Taylor: this

267
00:24:05.340 --> 00:24:09.299
Anthony Taylor: right, these 3 things right? I mean, this looks fine.

268
00:24:09.740 --> 00:24:13.260
Anthony Taylor: right? And it might be right a lot of the time. Probably not.

269
00:24:13.580 --> 00:24:22.359
Anthony Taylor: This could also be perfectly wonderful. You know. And then, you know, we just have to keep going until

270
00:24:22.600 --> 00:24:31.729
Anthony Taylor: the labels in our test data are just closer to right. What we have found is when they cross over tends to be the most accurate overall

271
00:24:32.300 --> 00:24:33.170
Anthony Taylor: overall.

272
00:24:33.290 --> 00:24:38.620
Anthony Taylor: But I agree it's it's hard to see that whenever it looks like it's going down

273
00:24:38.710 --> 00:24:40.879
Anthony Taylor: because the training score is going down

274
00:24:42.090 --> 00:24:44.550
Anthony Taylor: alright. But yeah, this

275
00:24:44.660 --> 00:24:48.699
Anthony Taylor: also will help with overfitting you don't see overfitting as much in

276
00:24:48.710 --> 00:24:53.309
Anthony Taylor: K. And and K. And is, I guess, why I originally kind of didn't go. Yeah.

277
00:24:53.910 --> 00:24:58.330
Anthony Taylor: I don't see it as often again, because, as you can see, it starts to split again.

278
00:24:58.940 --> 00:25:00.950
Anthony Taylor: So you end up going the other direction.

279
00:25:02.530 --> 00:25:08.529
Anthony Taylor: Anyway, paying is a little different, anyway. So here's 9.

280
00:25:08.870 --> 00:25:19.449
Anthony Taylor: Yeah. Go for. Oh, I'm sorry, Meredith. I did see your hand. I just spent so long answering the question.

281
00:25:19.880 --> 00:25:28.310
Meredith McCanse (she/her): Christine remembered you saying something about it when it crosses over. Is it that you want it where the

282
00:25:28.480 --> 00:25:32.380
Meredith McCanse (she/her): you want it, where the line is below the orange line.

283
00:25:32.960 --> 00:25:34.109
Meredith McCanse (she/her): Say it again.

284
00:25:34.290 --> 00:25:44.180
Anthony Taylor: So a rule of thumb. It's not always right again. We're gonna look at like, probably both of these. right when the blue line, when the training score

285
00:25:44.790 --> 00:25:49.880
Anthony Taylor: crosses the testing score, you're typically gonna take the next number

286
00:25:50.240 --> 00:25:51.210
Anthony Taylor: typical.

287
00:25:51.720 --> 00:25:54.030
Anthony Taylor: But that's that's just like.

288
00:25:54.790 --> 00:25:57.950
Anthony Taylor: you know, that's again me. Personally.

289
00:25:57.990 --> 00:26:01.499
Anthony Taylor: I would take this one and this one and see what I get

290
00:26:03.020 --> 00:26:11.959
Anthony Taylor: right. So where they cross, and the next one, because these are just like dead on right. And then actually, if you look up here, they really are dental.

291
00:26:12.490 --> 00:26:13.470
Meredith McCanse (she/her): Yeah.

292
00:26:14.030 --> 00:26:18.440
Anthony Taylor: So so we could run this, we got 96. Let's run it with 7.

293
00:26:21.930 --> 00:26:24.889
Anthony Taylor: It's a little lower. right? It's not terrible.

294
00:26:24.950 --> 00:26:26.819
Meredith McCanse (she/her): Seven's bigger, actually.

295
00:26:27.540 --> 00:26:33.920
Anthony Taylor: yeah, see? So I would say, I would me, I would take 7 to production.

296
00:26:33.930 --> 00:26:34.980
Meredith McCanse (she/her): Okay.

297
00:26:35.070 --> 00:26:36.290
Anthony Taylor: right now.

298
00:26:36.540 --> 00:26:40.729
Anthony Taylor: keep in mind. I mean, I could have looked at this and said, Yeah, that's right.

299
00:26:40.750 --> 00:26:43.790
Anthony Taylor: Right? Because you could argue well, wouldn't this be higher?

300
00:26:43.910 --> 00:26:45.650
Anthony Taylor: Right?

301
00:26:46.530 --> 00:26:57.090
Anthony Taylor: what you will find if this is not right is once we start adding new data. Okay. you'll see this number start to drop.

302
00:26:58.300 --> 00:27:01.909
Anthony Taylor: And that means that we've we've just we didn't generalize. Well.

303
00:27:02.500 --> 00:27:05.089
Anthony Taylor: okay, but

304
00:27:05.140 --> 00:27:11.820
Anthony Taylor: I still say 7 or 9 would be a good choice here. I wouldn't go up to 5 or 3.

305
00:27:12.540 --> 00:27:16.849
Anthony Taylor: In fact, I'm curious what like 13 would give us. I'll bet you 13.

306
00:27:17.060 --> 00:27:26.089
Anthony Taylor: Well, we know from up above what it's gonna give us. But yeah, it's really close. So this is just good data to look at, to be honest with

307
00:27:27.100 --> 00:27:28.220
Anthony Taylor: alright.

308
00:27:28.840 --> 00:27:29.910
Oh.

309
00:27:31.420 --> 00:27:32.890
Anthony Taylor: back to the slideshow.

310
00:27:36.480 --> 00:27:38.320
Anthony Taylor: Okay. so

311
00:27:38.510 --> 00:27:45.120
Anthony Taylor: that's all we're gonna talk about with K. It's great. You saw how you needed to do very similar to K-means.

312
00:27:45.180 --> 00:27:47.430
Anthony Taylor: But again, it's model fit. Predict.

313
00:27:48.450 --> 00:27:56.569
Anthony Taylor: The only thing you're really doing that little loop for is to figure out what the best nearest neighbor is, could you do it without that? Heck? Yeah.

314
00:27:57.330 --> 00:27:58.240
Anthony Taylor: okay.

315
00:27:58.510 --> 00:28:02.390
Anthony Taylor: you could do that through data analysis. You could do that to just plain old guessing

316
00:28:02.510 --> 00:28:07.619
Anthony Taylor: and then seeing what numbers you get okay, and then just doing more testing

317
00:28:08.080 --> 00:28:12.629
Anthony Taylor:  next thing. Now, this is the one I'm going to tell you guys.

318
00:28:13.300 --> 00:28:15.220
Anthony Taylor: there is a plot

319
00:28:16.100 --> 00:28:24.729
Anthony Taylor: that is broken. It's not broken. It's just a pain in the butt to install on macs and windows. They're totally different.

320
00:28:24.860 --> 00:28:29.360
Anthony Taylor:  so if you want to install it, feel free.

321
00:28:30.650 --> 00:28:33.409
Anthony Taylor: But you don't have to. You're going to get the picture, anyway.

322
00:28:33.860 --> 00:28:37.890
Anthony Taylor: Okay, so what is a decision tree. A decision tree.

323
00:28:39.120 --> 00:28:40.940
Anthony Taylor: Well, this is a decision.

324
00:28:42.030 --> 00:28:48.420
Anthony Taylor: The pet Picker decision tree. Very simple. Do you travel? Yes.

325
00:28:48.740 --> 00:28:53.080
Anthony Taylor: Are you gone more than a week per month. Yes, get a rock.

326
00:28:53.320 --> 00:28:54.000
Kanouff, Christine: Yeah.

327
00:28:55.320 --> 00:28:56.530
Anthony Taylor: Okay.

328
00:28:56.540 --> 00:29:03.710
Anthony Taylor: If you're gone less than week per month, it fit. You don't travel. Get a dog or cat.

329
00:29:04.890 --> 00:29:08.239
Anthony Taylor: Okay, based on? Do you like to dress up your pets?

330
00:29:08.470 --> 00:29:10.600
Anthony Taylor: Cats don't like them?

331
00:29:11.690 --> 00:29:12.690
Anthony Taylor: Okay.

332
00:29:13.340 --> 00:29:18.450
Anthony Taylor: so this is basically decision tree. Is this a simple decision tree?

333
00:29:18.920 --> 00:29:26.309
Anthony Taylor: Okay, that's what it is. Now is this what happens when we do it in a machine learning algorithm?

334
00:29:26.380 --> 00:29:29.540
Anthony Taylor: Not exactly. Okay.

335
00:29:29.640 --> 00:29:31.820
Anthony Taylor: This one.

336
00:29:34.400 --> 00:29:42.369
Anthony Taylor: so a couple of cool things about. So well, let's let's get through this. So we start with a root. In this case it's Pet Picker. It's the beginning.

337
00:29:43.020 --> 00:29:50.119
Anthony Taylor: And then we present a question now, not really a question. See? Does this tell us?

338
00:29:50.950 --> 00:29:51.810
Anthony Taylor: Yeah.

339
00:29:54.300 --> 00:30:02.430
Anthony Taylor: yeah, I'm trying to find a good example. So it's not really a question as much as it is weights, a probability.

340
00:30:03.720 --> 00:30:16.999
Anthony Taylor: Okay, so we have this this data. And we say, Hey, these 4 columns, if they, if this one equals one, and this one's greater than 5. And this one equals Bob.

341
00:30:18.510 --> 00:30:19.760
Anthony Taylor: That's a yes.

342
00:30:21.040 --> 00:30:24.249
Anthony Taylor: if any of those things aren't true, that's no

343
00:30:25.700 --> 00:30:28.019
Anthony Taylor: okay, and it goes to the next level.

344
00:30:28.060 --> 00:30:37.000
Anthony Taylor: and it measures all of the values again, and it comes up with the what it needs to determine. Yes or no on the next branch.

345
00:30:38.020 --> 00:30:39.910
Anthony Taylor: Now, at some point

346
00:30:40.050 --> 00:30:46.169
Anthony Taylor: it has enough information where it knows the answer, and those are the leaves of the tree.

347
00:30:47.320 --> 00:30:58.289
Anthony Taylor: So if this was a tell me if it's a cat or a dog. Okay. it would come up with something, does it have fur? Does it have ears? Does it have a wet nose.

348
00:30:59.680 --> 00:31:08.560
Anthony Taylor: Okay? And that would answer a question. and it would determine yes or no. So it goes over here.

349
00:31:08.640 --> 00:31:14.260
Anthony Taylor: and then it asks more questions, or it looks at more numbers, and then it comes up. It's a dog. It's cat.

350
00:31:16.940 --> 00:31:21.609
Anthony Taylor: Maybe it didn't have all the information it needed in this first question. So it went? No.

351
00:31:22.630 --> 00:31:31.699
Anthony Taylor: and it asked a couple more questions or looked at more data. Value. came up with a Yes or no. Still not enough information. Well, then does it, meow?

352
00:31:32.020 --> 00:31:33.510
Anthony Taylor: Yes, it's cat.

353
00:31:34.320 --> 00:31:39.300
Anthony Taylor: No, it stopped. Okay. it just depends.

354
00:31:40.340 --> 00:31:44.680
Anthony Taylor:  so each of these things. So this is how the tree looks.

355
00:31:44.740 --> 00:31:47.099
Anthony Taylor: And this is what gets generated in the background.

356
00:31:48.010 --> 00:31:51.330
Anthony Taylor:  they're really

357
00:31:51.530 --> 00:31:57.020
Anthony Taylor: us. Okay. And I mean, this is the same thing as I just showed you. So

358
00:31:57.320 --> 00:32:02.689
Anthony Taylor: tree the the coolest thing about trees and forest which we're going to talk about.

359
00:32:04.070 --> 00:32:05.979
Anthony Taylor: You don't have to make them all numbers.

360
00:32:07.050 --> 00:32:08.240
Anthony Taylor: It doesn't care.

361
00:32:09.070 --> 00:32:13.080
Anthony Taylor: You can leave categorical variables in there. It doesn't care.

362
00:32:14.250 --> 00:32:17.690
Anthony Taylor: It is tremendously accurate.

363
00:32:18.090 --> 00:32:20.100
Anthony Taylor: It doesn't care.

364
00:32:21.570 --> 00:32:24.599
Anthony Taylor: So why doesn't everybody just use trees?

365
00:32:26.630 --> 00:32:29.570
Anthony Taylor: They're computationally expensive.

366
00:32:30.020 --> 00:32:32.890
Anthony Taylor: Okay, they're not as bad as tenser

367
00:32:33.040 --> 00:32:36.660
Anthony Taylor: flow, which we'll get to later. But they're

368
00:32:36.740 --> 00:32:46.330
Anthony Taylor: kind of expensive to use. but they are awesome. and they're gonna give us some additional advantages that you guys are. Gonna see before today is over.

369
00:32:46.900 --> 00:32:52.670
Anthony Taylor: Okay, decision tree terms the root node. This is basically the top

370
00:32:52.740 --> 00:32:55.830
Anthony Taylor: of the tree. The parent. This

371
00:32:55.850 --> 00:33:03.070
Anthony Taylor: could be any node that splits into multiple nodes. Try and tile nodes or nodes that come off of the parents.

372
00:33:03.680 --> 00:33:10.970
Anthony Taylor: Decision nodes. Here, let's go back and look at a picture as we talk about this decision nodes. It's kind of funny cause.

373
00:33:11.410 --> 00:33:13.580
Anthony Taylor: Isn't that the same thing?

374
00:33:14.120 --> 00:33:17.880
Anthony Taylor: They're also they're similar to parent nodes.

375
00:33:18.100 --> 00:33:25.830
Anthony Taylor: Okay. believe or terminal note. That's where we have an answer. It doesn't split any further

376
00:33:27.050 --> 00:33:35.340
Anthony Taylor: branch that's on the tree splitting. That's the act of the parent or the decision node splitting into multiple

377
00:33:35.780 --> 00:33:38.120
Anthony Taylor: whatever leaves or branches.

378
00:33:38.430 --> 00:33:39.920
Anthony Taylor: Pruning.

379
00:33:40.190 --> 00:33:46.280
Anthony Taylor: it's literally what it means when it comes to trees. We're gonna pull off a branch that we decide doesn't make sense anymore.

380
00:33:47.260 --> 00:33:55.910
Anthony Taylor: Okay? And then tree step, how far will we let it go? What does that mean well, here, this one is 3 levels deep.

381
00:33:57.960 --> 00:34:00.429
Anthony Taylor: This is not a realistic example.

382
00:34:04.460 --> 00:34:05.390
Anthony Taylor: this

383
00:34:05.680 --> 00:34:11.429
Anthony Taylor: no. Oh, these are those slides are blocked out. This is a realistic example

384
00:34:14.219 --> 00:34:17.399
Anthony Taylor: of a single decision tree.

385
00:34:19.260 --> 00:34:28.639
Anthony Taylor: You guys can kinda see all of the nodes right? See the pair? You can see the root. You can see the different parents. You can see the child down here at the bottom you can see the leaves.

386
00:34:29.120 --> 00:34:33.049
Anthony Taylor: That is a decision tree. This is what they look like. Unfortunately.

387
00:34:34.570 --> 00:34:41.309
Anthony Taylor: I always wonder now it's not gonna let me do it. If you zoom into this and I will show you what you can zoom into.

388
00:34:41.370 --> 00:34:47.070
Anthony Taylor: you would actually see the criteria for yes or no.

389
00:34:47.940 --> 00:34:55.829
Anthony Taylor: It's gonna have, like a bunch of numbers. And very like, if this equals this and this equals this. And this is greater than this.

390
00:34:56.170 --> 00:35:01.139
Anthony Taylor: Yeah, that's true. Go this way. And and in the visual, it's to the left.

391
00:35:01.920 --> 00:35:04.290
Anthony Taylor: Okay? Otherwise, Google.

392
00:35:06.050 --> 00:35:08.479
Anthony Taylor: Alright. alright. Let's go look at the

393
00:35:10.430 --> 00:35:14.049
Anthony Taylor: so n this instructor one

394
00:35:14.220 --> 00:35:22.379
Anthony Taylor:  there is a P and G file. Well, let's don't look at that just yet. Hold off on it. Let's go through the code first.

395
00:35:23.390 --> 00:35:28.470
Anthony Taylor: cause you guys are gonna love it don't need. Don't do this. Just don't need worry about it.

396
00:35:29.160 --> 00:35:40.290
Anthony Taylor: Well, yeah, you might have to install this. You don't really need it. You can comment these lines out. But if you want to run this without changing the code

397
00:35:41.360 --> 00:35:44.939
Anthony Taylor: you have to install ido, Ti dot plus.

398
00:35:45.900 --> 00:35:47.830
Anthony Taylor: Okay, it's up to you if you want to do it.

399
00:35:49.790 --> 00:35:55.090
Anthony Taylor: So we're gonna import. The only thing we're really changing is we're going to import tree.

400
00:35:56.710 --> 00:36:05.469
Anthony Taylor: All the rest of this stuff is what we've been doing all along. We're not gonna worry about this like I said, this is a thing that's kind of a thing that install

401
00:36:07.130 --> 00:36:11.310
Anthony Taylor: installing. This is not hard, but you have to have another external

402
00:36:11.600 --> 00:36:14.809
Anthony Taylor: piece of software that you have to like. Put in your app

403
00:36:14.830 --> 00:36:16.270
and all of this kind of stuff

404
00:36:16.400 --> 00:36:17.200
Anthony Taylor: it's

405
00:36:18.090 --> 00:36:21.740
Anthony Taylor: don't worry about, anyway. Let's continue forward. So

406
00:36:22.050 --> 00:36:26.670
Anthony Taylor:  here's the data crowdfunding data.

407
00:36:27.490 --> 00:36:29.009
Anthony Taylor: Okay, pretty cool.

408
00:36:29.180 --> 00:36:32.150
Anthony Taylor: We're going to get rid of outcome

409
00:36:32.160 --> 00:36:34.040
Anthony Taylor: and put that in the features.

410
00:36:34.060 --> 00:36:37.260
Anthony Taylor: Deep outcome. Put it into our y variable

411
00:36:37.460 --> 00:36:42.129
Anthony Taylor: gonna do train test split because we want to be able to see how our oh, I am.

412
00:36:44.980 --> 00:36:50.660
Mason, Natalie: I just tried to run the first cell, and it's saying, Import pi dot plus

413
00:36:50.740 --> 00:36:54.729
Mason, Natalie: is not working for me. Oh, Pip installed. You said that.

414
00:36:55.210 --> 00:37:03.609
Anthony Taylor: Sorry if you don't need python, plus, you could just comment it out, or you can install cause we're not gonna run pied up.

415
00:37:03.830 --> 00:37:09.469
Anthony Taylor: Okay. So here we got our data, we did our Y variable. We're going to do our train test split.

416
00:37:09.990 --> 00:37:11.769
Anthony Taylor: We're going to do our scaling

417
00:37:11.790 --> 00:37:14.100
Anthony Taylor: gonna fit to our training data

418
00:37:14.130 --> 00:37:20.480
Anthony Taylor: and transform our training test. Everything's the same. Nothing changed. Okay.

419
00:37:21.490 --> 00:37:24.110
Anthony Taylor:  now.

420
00:37:24.300 --> 00:37:36.720
Anthony Taylor: we're going to run a decision tree classifier from our tree import. That's our model. What do we do after we model? We fit.

421
00:37:38.340 --> 00:37:39.400
Anthony Taylor: And it's done.

422
00:37:40.350 --> 00:37:43.580
Anthony Taylor: Now we can run a predict.

423
00:37:45.750 --> 00:37:49.339
Anthony Taylor: And now that we have the predict, we can, we can also score it.

424
00:37:50.760 --> 00:37:52.620
Anthony Taylor: And we got a 96

425
00:37:52.750 --> 00:37:54.340
Anthony Taylor: percent. Pretty good.

426
00:37:54.440 --> 00:38:02.659
Anthony Taylor: Okay. Now, I will tell you this is this code down here. This is the one I'm telling you. You have to have a special install, you'll see it'll fail on mine, too.

427
00:38:02.890 --> 00:38:06.239
Anthony Taylor: But this is what it generates.

428
00:38:07.180 --> 00:38:13.080
Anthony Taylor: So if you look over to the left, we've already given you this output. But here, you can see.

429
00:38:14.300 --> 00:38:17.720
Anthony Taylor: Actually, I think I have to actually know.

430
00:38:19.900 --> 00:38:31.580
Anthony Taylor: I think if I open this with a tool. yeah. Okay, so if you open this normally. you can actually zoom in and see what the decision tree's doing.

431
00:38:33.330 --> 00:38:38.859
Anthony Taylor: Okay? So you could see it says, alright for this to be true. Days active has to be less than

432
00:38:38.880 --> 00:38:45.199
Anthony Taylor: negative point 8 6 5 6 values between our one of these 2

433
00:38:45.490 --> 00:38:49.879
Anthony Taylor: and then class equals 0. If that's true. There it is. We're done.

434
00:38:50.310 --> 00:38:52.240
Anthony Taylor: that's the end. That's the least.

435
00:38:52.630 --> 00:39:00.609
Anthony Taylor: It's not true. Go here, check in values, if that's true, go here, and so on, and so on, and so on.

436
00:39:02.300 --> 00:39:05.379
Anthony Taylor: Yeah, see how that works. That's kind of cool, huh?

437
00:39:05.860 --> 00:39:13.149
Meredith McCanse (she/her): So you would do. We import this tree with all of at the beginning of the

438
00:39:14.650 --> 00:39:16.450
Meredith McCanse (she/her): like, at what point did we

439
00:39:17.660 --> 00:39:22.730
Meredith McCanse (she/her): pull this in? Was it one of the got it?

440
00:39:23.200 --> 00:39:27.570
Anthony Taylor: Yeah. So that's just a visual of how the model trains.

441
00:39:28.480 --> 00:39:36.420
Anthony Taylor: That's it. You don't need that. I? Outside of this classroom. I've never used this ever. Okay,

442
00:39:36.620 --> 00:39:44.259
Anthony Taylor: it's still very cool. I think I think it's very cool to see this, and and it might be worth, if anybody was interested

443
00:39:44.310 --> 00:39:50.689
Anthony Taylor: to install it. You basically just have to install an executable and find the app. If that sounds complicated. don't even worry about

444
00:39:50.850 --> 00:39:54.090
Anthony Taylor: you. Don't need this. This is just kind of and thing to look at.

445
00:39:54.630 --> 00:40:04.740
Anthony Taylor: Decision tree. Like, if you're going to use a decision tree, don't you have to build the tree unique to whatever situation you're in like. Absolutely. That's why we trained it.

446
00:40:06.580 --> 00:40:10.940
Anthony Taylor: That's what we did right here. but not there. Sorry right here.

447
00:40:13.760 --> 00:40:18.429
Meredith McCanse (she/her): So you could use that tree for any set of data, even if I had like.

448
00:40:18.620 --> 00:40:26.770
Meredith McCanse (she/her): like, regardless of context for the type of data, and it would get and and the point of it at the end of it, it gives you either classification of one or 0.

449
00:40:27.150 --> 00:40:33.180
Anthony Taylor: I I'm hesitant to say, regardless of any type. But I will tell you it works with most type.

450
00:40:34.300 --> 00:40:39.529
Meredith McCanse (she/her): Yeah, it's very good. And and and here's the good news. This isn't even the good one

451
00:40:39.870 --> 00:40:43.700
Anthony Taylor: we got another one coming up. That's better than this. That's just as easy to use.

452
00:40:44.710 --> 00:40:50.689
Anthony Taylor: Okay, but this is the first step. right? And actually, you can already see it on the screen. See that one down there.

453
00:40:50.720 --> 00:40:52.100
Anthony Taylor: Random forest.

454
00:40:52.190 --> 00:40:56.690
Anthony Taylor: We're going to take a whole bunch of trees and do even better. So, anyway.

455
00:40:56.710 --> 00:41:00.130
Anthony Taylor: So this does it. We got a 96

456
00:41:00.740 --> 00:41:09.100
Anthony Taylor: like, I said, if you really want to do this, you have to install this graph is executable. Put it in your path

457
00:41:09.270 --> 00:41:12.870
Anthony Taylor: where digital studio can find it, and it'll create this

458
00:41:13.310 --> 00:41:25.140
Anthony Taylor: this thing here.  I wouldn't. I do not. Do not get hung up on this. If you just really wanna do it. we'll we'll do it during office hours or something for those that are really interested. Okay.

459
00:41:25.310 --> 00:41:27.760
Anthony Taylor: alright.

460
00:41:28.670 --> 00:41:36.750
Anthony Taylor: And that's it. I mean, guys. I wish I could tell you there's more to this. but it's model fit. Predict that's it.

461
00:41:39.510 --> 00:41:43.130
Anthony Taylor: You pre-processed. How do we preprocess? Well, we're going to scale it.

462
00:41:43.490 --> 00:41:47.829
Anthony Taylor: We're going to put our Creator X and our Y, we're going to scale it.

463
00:41:48.840 --> 00:41:50.560
Anthony Taylor: And then we're gonna model fit. Predict?

464
00:41:51.830 --> 00:41:52.700
Anthony Taylor: That's it.

465
00:41:54.890 --> 00:41:59.350
Anthony Taylor: Honest to God. You guys are all like there's no way. It's that easy. I swear to you it's that easy

466
00:42:00.520 --> 00:42:07.130
Masarirambi, Rodney: we walked with data cleaning so that we can run here.

467
00:42:07.320 --> 00:42:08.539
Masarirambi, Rodney: That's what it is.

468
00:42:10.170 --> 00:42:11.240
Anthony Taylor: love that

469
00:42:11.570 --> 00:42:16.300
Anthony Taylor: that's it, everything we have done. And I, you know what I will tell you guys.

470
00:42:16.450 --> 00:42:21.640
Anthony Taylor: I say this to my data science classes whenever I have them. Everything we've done

471
00:42:21.660 --> 00:42:26.799
Anthony Taylor: up until machine learning was to prepare you to make this easier.

472
00:42:27.500 --> 00:42:41.319
Anthony Taylor: because this stuff is not simple. But once you've done everything else. This is like this is so easy. right? Because it's basically the same thing over and over and over again.

473
00:42:41.890 --> 00:42:46.699
Anthony Taylor: I love that. That's a great Rodney, I'm gonna use that. And

474
00:42:47.310 --> 00:42:53.219
Anthony Taylor: okay. So let's look at what you guys are gonna do. So you're gonna create a single tree.

475
00:42:53.750 --> 00:42:56.460
Anthony Taylor: Using the app data again

476
00:42:56.960 --> 00:43:03.900
Anthony Taylor: it gives you a lot of it, gives you your X and Y gives you your train test split and your scaling. All you gotta do is

477
00:43:04.060 --> 00:43:06.389
Anthony Taylor: so silly is these

478
00:43:06.540 --> 00:43:12.520
Anthony Taylor: like 4 or 5, and there's the actual visual, and it is also

479
00:43:13.000 --> 00:43:15.419
Anthony Taylor: it'll be in the cell when I give it to you.

480
00:43:15.450 --> 00:43:20.459
Anthony Taylor: Just don't worry about to sell right now. Let's just wanna try it yourself. We got 15 min.

481
00:43:20.580 --> 00:43:22.750
Anthony Taylor: Some of you guys might want to give it a try.

482
00:43:23.040 --> 00:43:30.040
Anthony Taylor:  yeah, like, I said, if you just have to install graphed and put it in your path

483
00:43:30.190 --> 00:43:32.190
Anthony Taylor: and it will work.

484
00:43:32.680 --> 00:43:33.390
Anthony Taylor: But

485
00:43:33.570 --> 00:43:37.000
Anthony Taylor: I've tried to do this in classes before and

486
00:43:38.230 --> 00:43:44.250
Anthony Taylor: between the Macs and the Pcs. And it's just it's just not what. Okay?

487
00:43:44.380 --> 00:43:46.800
Anthony Taylor: All right. Questions.

488
00:43:51.690 --> 00:43:52.350
Yep.

489
00:43:54.830 --> 00:43:56.710
Anthony Taylor: alright. How'd we do with that?

490
00:43:57.090 --> 00:44:00.370
Anthony Taylor: Any struggles? Fairly straightforward? Yeah.

491
00:44:01.400 --> 00:44:17.440
Anthony Taylor: mostly. Did anybody get grafted working? Besides. I know one group. Did anybody else even try? It's okay, if you didn't, it's not necessary. But if you Google that error, if you run it and you get that error, it tells you exactly how to do it.

492
00:44:17.630 --> 00:44:20.050
Anthony Taylor:  I

493
00:44:20.300 --> 00:44:23.140
Anthony Taylor: like, I said to me, it doesn't really matter. but

494
00:44:23.970 --> 00:44:26.480
Clayton Graves: chat, gpt! I'll tell you what to do, too.

495
00:44:26.660 --> 00:44:28.750
Anthony Taylor: There you go, chat cheap your tea?

496
00:44:28.890 --> 00:44:30.510
Anthony Taylor: Yeah.

497
00:44:32.010 --> 00:44:35.960
Anthony Taylor: Okay. So it gave you this all the imports.

498
00:44:37.290 --> 00:44:40.460
Anthony Taylor: and it gave you the loading of the data.

499
00:44:43.150 --> 00:44:46.109
Same thing as before. We're gonna drop results.

500
00:44:46.830 --> 00:44:51.339
Anthony Taylor: We're going to put it into Y, we're going to train, test, split.

501
00:44:52.390 --> 00:44:58.400
Anthony Taylor: We're gonna in this instantiate our scalar and then train it

502
00:44:59.500 --> 00:45:11.220
Anthony Taylor: and then transform our training and testing data now and bring in our decision tree classifier. We're going to fit it.

503
00:45:13.130 --> 00:45:15.300
Anthony Taylor: We're going to rather predict.

504
00:45:16.890 --> 00:45:20.550
Anthony Taylor: And then we're going to get our accuracy score.

505
00:45:21.710 --> 00:45:22.670
Anthony Taylor: There you go.

506
00:45:25.980 --> 00:45:31.069
Anthony Taylor: The if you want to look at this guy.

507
00:45:34.260 --> 00:45:38.240
Clayton Graves: The the graph that I ended up with was too large

508
00:45:38.710 --> 00:45:42.430
Clayton Graves: for the renderer bit maps. So it's scaled. It

509
00:45:43.580 --> 00:45:47.569
Clayton Graves: made it awful. Yeah, but you can still zoom into it.

510
00:45:48.030 --> 00:45:49.510
Anthony Taylor: Yeah, I mean.

511
00:45:49.980 --> 00:45:58.269
Anthony Taylor: so the Pd plot and all that stuff. It is very cool for kind of giving you this, this, these little simple things here.

512
00:45:59.750 --> 00:46:13.439
Anthony Taylor: it's you know. It's good. It's it's not like you're gonna be able to mathematically figure this out. But it gives you an idea of what's important, which is going to be really important in a few minutes after break.

513
00:46:13.460 --> 00:46:22.239
Anthony Taylor: What does the Jeanie? The GINI. In that

514
00:46:22.590 --> 00:46:29.789
Anthony Taylor: I looked it up before. Hold on, let me see. Well, let's ask

515
00:46:32.190 --> 00:46:35.490
Anthony Taylor: TINI, n. Decision

516
00:46:36.250 --> 00:46:37.460
3.

517
00:46:38.900 --> 00:46:46.659
Anthony Taylor: It is the G index is the additional approach to dividing decision tree. So it's an index based on the word on stuff above.

518
00:46:47.660 --> 00:46:48.800
Meredith McCanse (she/her): Okay.

519
00:46:49.110 --> 00:46:49.930
Anthony Taylor: yeah.

520
00:46:50.080 --> 00:46:55.429
Anthony Taylor: it's II honestly like, I said, I don't use these treats like this.

521
00:46:55.620 --> 00:46:59.120
Anthony Taylor: I mean, we use random forest. I've used random forest quite a bit.

522
00:46:59.200 --> 00:47:04.279
Anthony Taylor: But I don't usually do this visualization. It's cool, but it is just cool.

523
00:47:05.040 --> 00:47:07.769
Anthony Taylor: There's no actual value

524
00:47:07.780 --> 00:47:09.630
Anthony Taylor: in this outsider.

525
00:47:09.810 --> 00:47:11.430
Anthony Taylor: It's really cool to look at.

526
00:47:12.770 --> 00:47:18.620
Anthony Taylor: Okay. cool. absolutely alright. So

527
00:47:23.050 --> 00:47:24.100
Anthony Taylor: is that it?

528
00:47:25.890 --> 00:47:31.950
Anthony Taylor: Where'd my slideshow go there it is. Alright. So we looked at that. Any questions

529
00:47:34.690 --> 00:47:43.089
Anthony Taylor: break time, so come back at quarter after the hour, and then we will come back and do overfitting.

530
00:47:43.580 --> 00:47:47.059
Anthony Taylor: How exciting is that? Have a nice break.

531
00:47:49.580 --> 00:47:53.379
Anthony Taylor: So now we have talked about. We've talked about

532
00:47:53.980 --> 00:47:56.770
Anthony Taylor: decision trees we've talked about

533
00:47:58.140 --> 00:48:00.360
Anthony Taylor: Knn, Svn.

534
00:48:00.760 --> 00:48:03.730
Anthony Taylor: we've talked about logistic regression.

535
00:48:04.370 --> 00:48:13.819
Anthony Taylor: You've heard me mention a lot about overfitting. So we're gonna get a little more specific. Okay, about overfitting.

536
00:48:14.030 --> 00:48:15.120
Anthony Taylor: And

537
00:48:15.430 --> 00:48:17.310
Anthony Taylor: there you go. So

538
00:48:18.300 --> 00:48:22.370
Anthony Taylor: in in in this image, you could see this classification line. This dotted line.

539
00:48:22.710 --> 00:48:28.730
Anthony Taylor: Okay, it correctly identifies everything. It's quite Max. Okay,

540
00:48:29.740 --> 00:48:37.109
Anthony Taylor: but well, what are they saying here? The model accurately predicts training data points, but misses significant number of testing data

541
00:48:37.220 --> 00:48:42.469
Anthony Taylor: points over. So that goes back to what I would say if your training data score is high

542
00:48:42.640 --> 00:48:46.269
Anthony Taylor: and your testing data testing data score is low.

543
00:48:46.940 --> 00:48:54.460
Anthony Taylor: Then you are probably overfitting. And in this example they're saying that look in the training data, we only have

544
00:48:54.500 --> 00:48:58.940
Anthony Taylor: this light blue and this dark blue. But look what happens when we put in the testing data.

545
00:48:59.160 --> 00:49:02.699
Anthony Taylor: holy Moly, it's mixed up like all over the place.

546
00:49:03.900 --> 00:49:06.769
Anthony Taylor: Okay. So this tells us that we have

547
00:49:07.280 --> 00:49:13.080
Anthony Taylor: done something that has allowed her model to correctly fit

548
00:49:13.110 --> 00:49:18.139
Anthony Taylor: our training data, but has not allowed it to generalize enough

549
00:49:18.200 --> 00:49:20.300
Anthony Taylor: to fit our testing date.

550
00:49:20.770 --> 00:49:24.720
Anthony Taylor: Okay, I love that. That. That was a big, long lecture, wasn't it?

551
00:49:24.840 --> 00:49:28.390
Anthony Taylor:  decision. Trees

552
00:49:28.420 --> 00:49:33.320
Anthony Taylor: can do this really fast.

553
00:49:34.710 --> 00:49:41.629
Anthony Taylor: Okay, a decision tree. If you give it enough branches. Which is just one of the hyper parameters

554
00:49:42.160 --> 00:49:47.440
Anthony Taylor: it can. It can get every possible combination you can imagine.

555
00:49:49.140 --> 00:49:52.709
Anthony Taylor: and therefore overfits your data. Will it be right? Oh, yeah.

556
00:49:52.870 --> 00:50:01.860
Anthony Taylor: it'll be right all the time until some new data comes in that it's never seen before. And then it's gonna be like, Oh, well, wait. That's that's not what I've seen. I don't know what I'm doing.

557
00:50:03.420 --> 00:50:10.140
Anthony Taylor: Okay. And this goes back to what I said before, if I have data about you know what which sneaker this is.

558
00:50:10.510 --> 00:50:11.570
Anthony Taylor: and I have

559
00:50:11.660 --> 00:50:17.339
Anthony Taylor: trained it to know every possible sneaker on the planet, what happens when a new sneaker shows up

560
00:50:18.150 --> 00:50:23.760
Anthony Taylor: with some feature that none of the other ones have. It's not even going to guess that it's a sneaker.

561
00:50:25.970 --> 00:50:34.190
Anthony Taylor: Okay, so that's overfitting  trying to see if they have anything new to say.

562
00:50:34.820 --> 00:50:36.760
Anthony Taylor: Okay, so

563
00:50:42.750 --> 00:50:49.849
Anthony Taylor: one of the ways to reduce overfitting is with variance and with

564
00:50:49.920 --> 00:50:51.920
Anthony Taylor: ensemble learning.

565
00:50:54.150 --> 00:50:57.510
Anthony Taylor: Okay, anybody want to guess what ensemble learning is

566
00:51:01.070 --> 00:51:03.550
Anthony Taylor: any musicians, Natalie?

567
00:51:04.410 --> 00:51:07.360
Mason, Natalie: Well, that would be a group of something.

568
00:51:07.940 --> 00:51:09.350
Anthony Taylor: Bingo.

569
00:51:10.030 --> 00:51:13.750
Anthony Taylor: that's all. It is ensemble learning is simply

570
00:51:13.960 --> 00:51:19.299
Anthony Taylor: using more than one machine learning model to come up with a better answer.

571
00:51:19.830 --> 00:51:24.669
Anthony Taylor: Okay, so the one we're gonna talk about today is one of my favorites.

572
00:51:24.860 --> 00:51:27.689
Anthony Taylor: It's called the Random Forest.

573
00:51:29.970 --> 00:51:40.139
Anthony Taylor: What's a forest made up of a number of trees? So how does it work?  we are going to

574
00:51:41.730 --> 00:51:47.559
Anthony Taylor: tell the model to train on the data with a random forest, and what it will do is come up with

575
00:51:47.610 --> 00:51:49.650
Anthony Taylor: multiple trees

576
00:51:50.530 --> 00:51:53.169
Anthony Taylor: that give it give us an answer

577
00:51:54.470 --> 00:52:00.530
Anthony Taylor: to come up with one tree, another tree, another tree, another tree, until it's done until it's like, Okay, I can't do any more.

578
00:52:00.870 --> 00:52:02.380
Anthony Taylor: When it's done.

579
00:52:02.510 --> 00:52:06.480
Anthony Taylor: It's going to then have this decision path

580
00:52:06.620 --> 00:52:16.360
Anthony Taylor: that takes us down. Let's see if they have another picture of this. They don't. They used to have a pretty good picture of this where each one of these trees will try to give you the answer.

581
00:52:17.920 --> 00:52:18.760
Anthony Taylor: Okay.

582
00:52:18.910 --> 00:52:28.470
Anthony Taylor: when it's done, there will be another algorithm. That kind of runs along the bottom here that says, well, this tree, said dark Blue. This tree said light blue, this tree, said dark Blue.

583
00:52:29.070 --> 00:52:32.799
Anthony Taylor: That's greatly simplifying it. But now the answer is dark blue.

584
00:52:34.620 --> 00:52:39.339
Anthony Taylor: Okay, it's not that simple. It's a little more complicated than that. The good news is you don't worry about.

585
00:52:39.700 --> 00:52:42.829
Anthony Taylor: It's all gonna happen in the training. You don't have to worry about.

586
00:52:43.490 --> 00:52:54.139
Anthony Taylor: Okay. So anyway, we have a couple of layers. There's some other terms where I learned bagging and boosting. The random forest is bagging.

587
00:52:54.730 --> 00:52:59.539
Anthony Taylor: This, which just means it's creating different out our different

588
00:53:00.220 --> 00:53:01.900
algorithms, if you will

589
00:53:01.970 --> 00:53:03.010
Anthony Taylor: to

590
00:53:03.240 --> 00:53:06.730
Anthony Taylor: and different predictions. And then we come up with the final predictions.

591
00:53:07.550 --> 00:53:09.130
Anthony Taylor: A

592
00:53:09.230 --> 00:53:10.570
Anthony Taylor: okay. So

593
00:53:12.290 --> 00:53:21.480
Anthony Taylor: week learners is a really cool thing. This is just terminology. It's not something you'll probably need to remember. Okay, I don't know that I've uttered these words very often.

594
00:53:21.500 --> 00:53:25.129
Anthony Taylor: but basically I have a model. It's not bad.

595
00:53:25.450 --> 00:53:27.740
Anthony Taylor: Gets it right? 50% of the time.

596
00:53:28.120 --> 00:53:31.220
Anthony Taylor: Okay, that's crap model. If that's only modeled God.

597
00:53:31.470 --> 00:53:32.290
Anthony Taylor: However.

598
00:53:32.730 --> 00:53:38.479
Anthony Taylor: that model in an ensemble, learning situation might be the deciding factor.

599
00:53:39.620 --> 00:53:41.479
Anthony Taylor: So this one

600
00:53:41.710 --> 00:53:47.340
Anthony Taylor: gets it right, like 70%. But when you combine that with this one.

601
00:53:47.700 --> 00:53:49.949
Anthony Taylor: you're getting like a 98%,

602
00:53:51.760 --> 00:53:52.930
Anthony Taylor: you understand.

603
00:53:53.470 --> 00:53:59.249
Anthony Taylor: So the cool thing about ensemble is it allows us to take models that aren't great and add to

604
00:54:00.660 --> 00:54:03.750
Anthony Taylor: okay, pretty cool situation.

605
00:54:03.800 --> 00:54:07.150
Anthony Taylor: So weak learners are a consequence of limited data. True?

606
00:54:07.340 --> 00:54:25.219
Anthony Taylor:  it may mean there's too few features. So if you don't have enough columns, you'll get weak learners a lot. We can get weak learners. With a lot of stuff. Okay, the the the bottom line is is that in this, in ensemble a weak learner

607
00:54:25.370 --> 00:54:29.870
Anthony Taylor: can turn into a valuable piece of information.

608
00:54:30.380 --> 00:54:31.240
Anthony Taylor: Alright!

609
00:54:31.820 --> 00:54:34.449
Can you guess how to make it learn more accurately?

610
00:54:34.640 --> 00:54:37.530
Anthony Taylor: Anybody want to take a guess? I think I kind of already said it.

611
00:54:42.200 --> 00:54:45.529
Anthony Taylor: More money can boost it. Oh, sorry. What was that? Like?

612
00:54:46.380 --> 00:54:47.390
michael mcpherson: More model.

613
00:54:48.130 --> 00:54:50.590
Anthony Taylor: more models, the ensemble approach.

614
00:54:51.690 --> 00:55:00.300
Anthony Taylor: Okay? So we could boost those week learners with other algorithms for an ensemble approach. The decision tree can sometimes be classified as a week learner.

615
00:55:01.330 --> 00:55:13.659
Anthony Taylor: Okay? And that's just the fact. It just can be but working together with the ensembles, we're going to improve that accuracy. We're going to combine them. And we're going to be able to define stuff

616
00:55:14.960 --> 00:55:18.439
Anthony Taylor: alright. This is. This is like such a cool graphic.

617
00:55:20.060 --> 00:55:23.110
Anthony Taylor: It's like a turtle with wheels, and

618
00:55:23.740 --> 00:55:26.609
Anthony Taylor: that's really kind of cool. It just is

619
00:55:27.070 --> 00:55:30.899
Anthony Taylor: alright. So we have a boosted tree.

620
00:55:30.980 --> 00:55:43.420
Anthony Taylor: We take the tree, or we have all these different variations. So you have a gradient boosted tree. You have an XG boost and a random forest. These are different ensemble learning algorithms. Guess what?

621
00:55:43.750 --> 00:55:45.139
Anthony Taylor: They all work the same.

622
00:55:46.120 --> 00:55:49.410
Anthony Taylor: And by the same, I mean, from your perspective.

623
00:55:50.580 --> 00:55:56.170
Anthony Taylor: you're going to instantialize the model. I want a gradient boosted treat

624
00:55:57.410 --> 00:55:58.540
Anthony Taylor: fit. Predict?

625
00:55:59.270 --> 00:56:04.830
Anthony Taylor: I want extra boost fit. Predict. I want random forest fit for dead

626
00:56:06.370 --> 00:56:07.230
Anthony Taylor: done.

627
00:56:09.490 --> 00:56:14.679
Anthony Taylor: Okay? And they have different pluses in mind. So today, we're gonna talk

628
00:56:14.890 --> 00:56:20.430
Anthony Taylor: primarily about random forest. So again, this.

629
00:56:20.550 --> 00:56:29.069
Anthony Taylor: it's funny. They show this is a random force algorithm. It's not. This is still a single tree. This is the same single tree you guys saw up above.

630
00:56:32.950 --> 00:56:35.089
Anthony Taylor: And then you can see.

631
00:56:35.530 --> 00:56:50.619
Anthony Taylor: this is how it's basically going to work. So it's going to predict it's going to put them all together and then come out with an answer. So we create simple trees by randomly. This is what it's doing in the background, randomly sampling the data and creating a decision tree for that small portion.

632
00:56:51.360 --> 00:56:58.499
Anthony Taylor: Each simple tree is a weak classifier, because it's only trained on part of the data by itself. It's no good.

633
00:56:59.070 --> 00:57:05.949
Anthony Taylor: But once we combine them. it's amazing. This is great against overfitting.

634
00:57:06.120 --> 00:57:14.440
Anthony Taylor: because all the week. Learners are trained on different pieces of data. It's very unlikely anyone is going to be able to answer every question.

635
00:57:16.670 --> 00:57:25.490
Anthony Taylor: You can rank them, and we can rank the importance of input variables. This is going to be valuable. We're gonna see this at work today can handle

636
00:57:25.830 --> 00:57:26.840
1,000

637
00:57:27.730 --> 00:57:29.470
Anthony Taylor: of input variables.

638
00:57:31.950 --> 00:57:40.780
Anthony Taylor: It's great with outliers. It's great with nonlinear data. And it's pretty efficient on very large data sets.

639
00:57:41.530 --> 00:57:43.830
Anthony Taylor: Okay. very cool.

640
00:57:44.210 --> 00:57:52.830
Anthony Taylor:  right? So, machine learning models can be confused by overabundance of features.

641
00:57:53.010 --> 00:57:59.570
Anthony Taylor: Okay, we're not gonna jump into that yet. I don't think. Okay. I don't want us to get too far ahead.

642
00:58:01.180 --> 00:58:13.799
Anthony Taylor: Are we going to show that right now we are. So remember when we did the Pca thing, and you could see like how they were affecting linear regression. Well, random Forest gives us the ability to check

643
00:58:13.970 --> 00:58:18.630
Anthony Taylor: features and see how they're doing. Okay.

644
00:58:18.850 --> 00:58:30.160
Anthony Taylor:  so we're going to be able to do that and lower the number of features based on how much they contribute to the answer.

645
00:58:30.630 --> 00:58:34.210
Anthony Taylor: Okay, so what we might do is we might create a decision tree

646
00:58:34.290 --> 00:58:48.709
Anthony Taylor: we like it. But then we go back and we look at the features and we lower it down to make the decision tree more efficient. So random forest use decision trees. How frequently a feature gets selected over the whole random forest model

647
00:58:48.730 --> 00:58:51.200
Anthony Taylor: indicates how important it is.

648
00:58:51.550 --> 00:58:56.679
Anthony Taylor: So with that we can run this feature importance algorithm.

649
00:58:56.750 --> 00:58:59.760
Anthony Taylor: and get a list of how important they are.

650
00:59:00.140 --> 00:59:02.800
Anthony Taylor: Math. let's take a look.

651
00:59:10.370 --> 00:59:14.370
Anthony Taylor: Okay. So here, only thing different.

652
00:59:14.440 --> 00:59:16.979
Anthony Taylor: Random forest classifier. That's it.

653
00:59:18.070 --> 00:59:19.480
Anthony Taylor: Everything else is the same.

654
00:59:20.110 --> 00:59:24.850
Anthony Taylor: Okay? So we're gonna run those. This is

655
00:59:26.270 --> 00:59:28.530
Anthony Taylor: pretty fun data about what

656
00:59:28.560 --> 00:59:32.859
Anthony Taylor: predicting forest cover type from cartographic variables. Only

657
00:59:33.730 --> 00:59:34.730
Anthony Taylor: kind of cool.

658
00:59:35.580 --> 00:59:37.270
Here's our data.

659
00:59:38.750 --> 00:59:52.700
Anthony Taylor: So we can see we got a bunch of stuff here. It's going to say, here's the cover. and that's going to be our predictive variable. So we'll get X and Y, and we're gonna do train, test, split and scale and transform.

660
00:59:52.980 --> 00:59:57.400
Anthony Taylor: We're starting to make this truthfully. All of this could have been one cell, and you're done.

661
00:59:58.050 --> 01:00:02.800
Anthony Taylor: There's no reason to break them all up. But you know we're starting to get more comfortable with it.

662
01:00:03.580 --> 01:00:12.750
Anthony Taylor: Alright. So here you go. Random forest classifier, random state one estimators. This is basically just to give a limit.

663
01:00:12.870 --> 01:00:15.640
Anthony Taylor: The how many branches it's going to make.

664
01:00:16.930 --> 01:00:21.890
Anthony Taylor: Okay, cause you can. I mean, it can go a long time. We're gonna say, you know, let's stop at 5.

665
01:00:22.210 --> 01:00:23.719
Anthony Taylor: This is tunable.

666
01:00:24.970 --> 01:00:27.420
Anthony Taylor: If you're not getting good results. Try a thousand.

667
01:00:28.130 --> 01:00:30.859
Anthony Taylor: or sometimes the less.

668
01:00:32.340 --> 01:00:36.709
Anthony Taylor: Okay. So we're gonna pass in our training data. And then we're gonna score it

669
01:00:54.760 --> 01:01:01.110
Clayton Graves: about 47 s. So just a little bit. Thank you, Clayton, and your computer's faster than mine, I think.

670
01:01:05.030 --> 01:01:16.780
Anthony Taylor: other than those notes. That's it.

671
01:01:18.180 --> 01:01:20.950
James Torres: I think it just repeats itself

672
01:01:21.590 --> 01:01:27.470
Anthony Taylor: is over and over again

673
01:01:28.510 --> 01:01:32.200
Anthony Taylor: we could do the jeopardy tune. da da

674
01:01:33.400 --> 01:01:34.220
wouldn't.

675
01:01:34.620 --> 01:01:37.019
Anthony Taylor: Okay? Yay.

676
01:01:37.290 --> 01:01:41.839
Anthony Taylor: So it's pretty high. Not that high.

677
01:01:42.240 --> 01:01:47.389
Anthony Taylor: Okay, this isn't uncommon with random forest, it might be overfit.

678
01:01:48.120 --> 01:01:49.080
Anthony Taylor: It might not.

679
01:01:49.510 --> 01:01:59.240
Anthony Taylor: Okay, we have to. Now, we have to examine, because this isn't. If this was like 70 or 60, I'd be really well. okay, 90. Yeah, we'll see.

680
01:01:59.420 --> 01:02:05.529
Anthony Taylor: So to see the feature importances, we're going to call clf. Remember, that's what we called our model.

681
01:02:05.910 --> 01:02:09.430
Anthony Taylor: And the feature, importance, property.

682
01:02:09.950 --> 01:02:13.789
Anthony Taylor: which is an array of features. We're going to sort them

683
01:02:14.090 --> 01:02:16.640
Anthony Taylor: and output them.

684
01:02:17.370 --> 01:02:20.010
Anthony Taylor: So there's our top 10. So

685
01:02:20.550 --> 01:02:29.070
Anthony Taylor: these are the things and the level of importance they are to our model. How many columns were there?

686
01:02:29.330 --> 01:02:32.060
Anthony Taylor: There's only 12. Why wouldn't they just show all of them?

687
01:02:33.190 --> 01:02:34.270
Anthony Taylor: That's so lame.

688
01:02:37.390 --> 01:02:43.570
Anthony Taylor: Okay? So you can see, like wilderness area. It has, like almost no bearing on the result.

689
01:02:45.400 --> 01:02:50.400
Anthony Taylor: Alright, while elevation distance from road

690
01:02:50.560 --> 01:02:54.500
Anthony Taylor: whatever that is just inspire. Those are a little more important.

691
01:02:55.050 --> 01:02:59.370
Anthony Taylor: Okay? So we can plot these to show

692
01:03:01.960 --> 01:03:05.769
Anthony Taylor: you could clearly see, elevation just rules the roost on this.

693
01:03:06.280 --> 01:03:16.650
Anthony Taylor: Alright. So this is a really cool thing about it's like A. A. I let me give you an example. I have used Random Forest just to get this information.

694
01:03:20.040 --> 01:03:22.429
Anthony Taylor: Okay. And why would I do that? Well.

695
01:03:23.520 --> 01:03:31.070
Anthony Taylor: but and I've told students to do this as well. and that is. I want you to.

696
01:03:31.270 --> 01:03:43.170
Anthony Taylor:  I want you to do this so that you can understand what factors are causing that to happen. So say, you want to look at crime statistics.

697
01:03:44.180 --> 01:03:47.300
Anthony Taylor: Okay? And you get a great prediction

698
01:03:47.390 --> 01:03:49.660
Anthony Taylor: on these crime statistics.

699
01:03:49.900 --> 01:03:54.370
Anthony Taylor: Right? Well, then, I'm like, Okay, but why? But how can you explain that?

700
01:03:55.670 --> 01:04:00.990
Anthony Taylor: So they go in here and they do this, and then they look at all of this, and they go. Oh, my God! Look at that!

701
01:04:01.580 --> 01:04:11.649
Anthony Taylor: I thought it was because of poverty. or I thought it was because of a demographic. But it turns out that you know it's some other reason in your date.

702
01:04:13.330 --> 01:04:14.300
Anthony Taylor: Okay?

703
01:04:14.590 --> 01:04:20.090
Anthony Taylor: And this is a great way to find it. It's very, very cool. Okay, so

704
01:04:20.410 --> 01:04:21.639
Anthony Taylor: just quickly.

705
01:04:22.800 --> 01:04:26.490
Anthony Taylor: we did X and Y scale

706
01:04:26.580 --> 01:04:30.500
Anthony Taylor: random forest classifier. Nothing to worry about here. If you want.

707
01:04:30.840 --> 01:04:32.740
Anthony Taylor: you can change that number.

708
01:04:32.770 --> 01:04:38.169
Anthony Taylor: We did a fit in the middle of it. You you could have done Cllf fit if you prefer.

709
01:04:38.940 --> 01:04:47.110
Anthony Taylor: Okay? And then we printed our training scores. And then we did the feature importance and sorted it out. That's it.

710
01:04:48.700 --> 01:04:53.829
Anthony Taylor: Okay, use this same lying. And it'll be nice. And like this?

711
01:04:54.860 --> 01:04:55.650
Anthony Taylor: Okay?

712
01:04:57.710 --> 01:05:03.600
Anthony Taylor: Questions. Brandon Forest superstar rocks.

713
01:05:04.340 --> 01:05:08.670
Anthony Taylor: Okay? So you guys have a quick activity with this.

714
01:05:09.200 --> 01:05:12.029
Anthony Taylor: it's got to be very similar to the previous one.

715
01:05:13.120 --> 01:05:16.480
You're doing looks like applications again. Yep.

716
01:05:18.760 --> 01:05:30.950
Anthony Taylor: yeah. So all you gotta do it even tells you, random state 78 estimators, 128. Okay. Trey, are instantiate it, fit it. make predictions.

717
01:05:31.150 --> 01:05:38.039
Anthony Taylor: Calculate your so model score or accuracy score display the result, and then do your feature importance.

718
01:05:39.490 --> 01:05:45.340
Anthony Taylor: Okay? That's it. Yes, question look like they scaled.

719
01:05:45.510 --> 01:05:51.349
Raugewitz, Tania: They ran the scalar on this. Correct. Remember this one's just zeros, and what? So

720
01:05:51.370 --> 01:05:54.269
Raugewitz, Tania: the the good thing, so that the short answer is

721
01:05:54.900 --> 01:06:03.129
Anthony Taylor: always feel free to scale. You're fine. Do you need to? In this case this data doesn't really require it. It's all 0. And what

722
01:06:03.580 --> 01:06:05.680
Anthony Taylor:  But.

723
01:06:06.450 --> 01:06:11.360
Anthony Taylor: like, I said. you feel free to do it if you like, it will not change the result.

724
01:06:13.060 --> 01:06:17.010
Anthony Taylor: Okay, I love that you saw that time right away. That's fantastic.

725
01:06:18.300 --> 01:06:20.610
Anthony Taylor: Okay, alright gay.

726
01:06:21.880 --> 01:06:23.560
Anthony Taylor: So for this one

727
01:06:24.880 --> 01:06:26.720
Anthony Taylor: 15 min, look at that.

728
01:06:27.860 --> 01:06:29.670
Anthony Taylor: Have fun.

729
01:06:33.510 --> 01:06:35.180
Anthony Taylor: Yeah.

730
01:06:36.560 --> 01:06:41.740
Anthony Taylor: So how'd you guys like that? Random trees pretty cool.

731
01:06:41.950 --> 01:06:45.759
Anthony Taylor: It's a did. I tell you guys.

732
01:06:46.410 --> 01:06:49.479
Anthony Taylor: weeks ago, when we get to Ml.

733
01:06:49.780 --> 01:06:53.000
Anthony Taylor: What it was going to be like? Model fit predict

734
01:06:56.260 --> 01:06:59.039
Anthony Taylor: pretty much. That's it. Model fit predicts.

735
01:06:59.650 --> 01:07:14.300
Anthony Taylor: Obviously, there's some are. And it's funny. I, Brendan Brandon. I'm not sure why I put the Cv stuff in there. We are going to cover that eventually, but we're not doing it for tuning that way yet. but that is something we'll also do. So we'll make it more complex as we go.

736
01:07:14.630 --> 01:07:16.189
Anthony Taylor: But for the moment

737
01:07:16.900 --> 01:07:24.829
Anthony Taylor: this is how it works. Okay, so let's run through this. They gave you this.

738
01:07:25.310 --> 01:07:30.559
Anthony Taylor: They gave you the same one we've been using all day. By the way, for your student activities.

739
01:07:31.150 --> 01:07:34.109
Anthony Taylor: So all of this should look familiar

740
01:07:35.130 --> 01:07:38.060
Anthony Taylor: again. Stop me if you have any questions on this part.

741
01:07:38.920 --> 01:07:46.359
Anthony Taylor: Okay, now, we're going to start doing our random forest. It told us how many estimators to use. This is one of those things that you can tune.

742
01:07:47.000 --> 01:07:49.119
Anthony Taylor: Okay? And do more. You could do less

743
01:07:49.170 --> 01:07:51.720
Anthony Taylor: and try it out. See what the results are.

744
01:07:51.870 --> 01:07:56.279
Anthony Taylor: Some of the artwork or art artistry of data. Science?

745
01:07:56.730 --> 01:07:59.850
Anthony Taylor:  yes, Matt.

746
01:08:00.800 --> 01:08:05.880
Dipinto, Matt: is the number of estimators, the number of trees, or is it something else?

747
01:08:05.960 --> 01:08:12.950
Anthony Taylor: It is. I wanna say, it's the number of branches. But now you got me wondering if I'm gonna say that wrong. So

748
01:08:13.340 --> 01:08:22.519
Anthony Taylor: let's ask our little thing here. I wanna make sure it's if it's branches or trees.

749
01:08:26.700 --> 01:08:27.910
Anthony Taylor: here comes

750
01:08:28.760 --> 01:08:32.809
Anthony Taylor: estimators parameter specified the number of trees in the forest.

751
01:08:33.600 --> 01:08:35.930
Anthony Taylor: Okay? So the default is a hundred

752
01:08:37.460 --> 01:08:39.470
Anthony Taylor: good job. Good job.

753
01:08:39.970 --> 01:08:45.949
Anthony Taylor: Okay. So this is, gonna tell us the number of trees

754
01:08:46.240 --> 01:08:47.960
Anthony Taylor: that we're going to use

755
01:08:48.100 --> 01:08:52.529
Anthony Taylor: again. Customizable. You can edit it. You can do whichever direction you want.

756
01:08:52.609 --> 01:08:54.880
Anthony Taylor: Then we're going to fit it. Who?

757
01:08:55.630 --> 01:08:58.000
Anthony Taylor: This probably takes a minute? Oh, that wouldn't take long at all.

758
01:08:58.160 --> 01:09:02.560
Anthony Taylor: probably because it's zeros and ones. It's a really easy data set.

759
01:09:02.670 --> 01:09:06.270
Anthony Taylor: We can do our predictions, and then we can do our score.

760
01:09:06.460 --> 01:09:14.060
Anthony Taylor: Now it's having you do this instead of model dot score. Because we've given this. We've done this on everyone you guys have done today.

761
01:09:14.300 --> 01:09:23.489
Anthony Taylor:  so so this, as it turns out, is marginally better than the other ones today for the same data.

762
01:09:23.649 --> 01:09:29.660
Anthony Taylor:  is it worth all of the extra load that you're putting on your system? Yeah, maybe not.

763
01:09:30.000 --> 01:09:31.419
Anthony Taylor: But it is better.

764
01:09:31.720 --> 01:09:37.860
Anthony Taylor: Okay? So for feature importance, we can run the code that this is code can be used every time.

765
01:09:38.160 --> 01:09:46.030
Anthony Taylor: Notice, there's no column names. There's nothing in here. right? So you could take this, run it anytime you want anywhere you want.

766
01:09:46.319 --> 01:09:56.709
Anthony Taylor: And then we can kind of see. So the read phone states the receive. There's different things that are important there. says, would you trust this model?

767
01:09:59.440 --> 01:10:00.240
Anthony Taylor: Yeah.

768
01:10:01.140 --> 01:10:04.129
Anthony Taylor: okay, so this is detecting malware. Look at

769
01:10:04.550 --> 01:10:16.990
Anthony Taylor: what the first thing that it found to be consistent in malware. can read your phone state. So this is a funny story for you. and

770
01:10:17.930 --> 01:10:24.440
Anthony Taylor: well, I don't know if we still do it. We used to do a model where we had phone state data.

771
01:10:25.610 --> 01:10:27.819
Anthony Taylor: and we could tell what you were doing.

772
01:10:30.780 --> 01:10:32.649
Anthony Taylor: Like, where you walk.

773
01:10:32.740 --> 01:10:38.380
Anthony Taylor: where you standing. Were you sitting? Were you jogging? Were you exercising?

774
01:10:39.790 --> 01:10:43.899
Anthony Taylor: We could tell what you were doing by the phone state?

775
01:10:45.530 --> 01:10:48.300
Anthony Taylor: Okay? Which is kind of interesting when you think about it?

776
01:10:48.980 --> 01:10:59.460
Anthony Taylor: But yeah. So anyway, that's what the malware I mean. That's why this was such a big one. Because you can just really do a lot of stuff. So yeah, I would trust you. 97.

777
01:10:59.700 --> 01:11:05.989
Anthony Taylor: And then this just says which one was best. I already mentioned this, that this one is just slightly better than all of the others.

778
01:11:06.880 --> 01:11:08.130
Anthony Taylor: Pretty cool, right?

779
01:11:09.430 --> 01:11:10.530
Anthony Taylor: Questions.

780
01:11:13.310 --> 01:11:16.560
Anthony Taylor: Okay? So one more

781
01:11:17.640 --> 01:11:22.359
Anthony Taylor: extremely random trees.

782
01:11:22.840 --> 01:11:30.890
Anthony Taylor: So in random forests, we talked about the fact that the each tree would be created from a subset of the data.

783
01:11:31.840 --> 01:11:32.920
Anthony Taylor: Okay.

784
01:11:33.720 --> 01:11:42.050
Anthony Taylor: in extremely random. It no longer does that. It literally uses the entire set over and over and over again

785
01:11:42.530 --> 01:11:44.709
Anthony Taylor: to come up with something.

786
01:11:44.950 --> 01:11:52.060
Anthony Taylor: So extremely random features of the entire sample picks at random the optimal split point.

787
01:11:52.480 --> 01:11:54.880
Anthony Taylor: Okay, so it's not actually

788
01:11:55.340 --> 01:12:02.319
Anthony Taylor: training at like a regular random forest. It's actually just randomly creating split points.

789
01:12:02.680 --> 01:12:10.079
Anthony Taylor: Which is way faster than trying to figure out the optimal split point cumin, and it increases bias and decreases variance

790
01:12:10.420 --> 01:12:16.549
Anthony Taylor: while random forest chooses the optimal resamples the data for each new decision tree.

791
01:12:16.840 --> 01:12:20.559
Anthony Taylor: Okay, as in grabs a sample of the data.

792
01:12:20.780 --> 01:12:25.460
Anthony Taylor: Okay? So this is awesome in terms of accuracy.

793
01:12:25.910 --> 01:12:32.269
Anthony Taylor: It does take longer to fit kind of obvious when you think about. It's redoing the entire data set every time.

794
01:12:32.800 --> 01:12:34.090
Anthony Taylor: But

795
01:12:34.950 --> 01:12:42.479
Anthony Taylor: as with many things, if it gives us a better result. it might be worth it. We have to weigh the cost to

796
01:12:42.660 --> 01:12:44.680
Anthony Taylor: what we have. So

797
01:12:44.840 --> 01:12:48.199
Anthony Taylor: boosting. So that was so with boosting.

798
01:12:48.330 --> 01:12:57.070
Anthony Taylor: we're basically going to take individual week learners and boost them if they are contributing to the correct solution.

799
01:12:57.390 --> 01:13:05.190
Anthony Taylor: But their value to the overall algorithm. it's lowered if we determine that that

800
01:13:05.490 --> 01:13:20.729
Anthony Taylor: weak learner is really just not helping. And when you think about it, man, does that make sense? I've got all these decision trees in this forest, and I've got this one over here, it contributes practically nothing to the result.

801
01:13:20.750 --> 01:13:29.359
Anthony Taylor: So I'm just gonna just yeah, you're not worth much. So give you 5% of the decision. But this guy.

802
01:13:29.450 --> 01:13:33.170
Anthony Taylor: This guy is like he's involved in every single answer.

803
01:13:33.440 --> 01:13:39.629
Anthony Taylor: So this guy's got to get, you know, 60% of the strength of the of the weight.

804
01:13:39.990 --> 01:13:43.389
Anthony Taylor: I mean, that's extreme. But you get the point. You get the point.

805
01:13:43.750 --> 01:13:52.170
Anthony Taylor: Okay, so anyway, boosting is awesome with ensemble learning because it allows us to basically get rid, get to

806
01:13:52.500 --> 01:13:58.720
Anthony Taylor: take out of the picture stuff that's not really benefiting the overall model. Okay.

807
01:14:01.000 --> 01:14:09.189
Anthony Taylor: so let's see how this is coded. I bet you're wondering how this is coded and it couldn't possibly be

808
01:14:10.540 --> 01:14:14.279
Anthony Taylor: test model fit, predict right the guesswork

809
01:14:14.630 --> 01:14:15.610
to test file.

810
01:14:17.270 --> 01:14:24.370
Anthony Taylor: So here we have both sent. This is the Forest one again, I'm pretty sure. Yep. a

811
01:14:24.930 --> 01:14:30.469
Anthony Taylor: all of the. Now, this one's interesting. We're we're going to create target names here.

812
01:14:30.720 --> 01:14:35.299
Anthony Taylor: So this is coming from this right here.

813
01:14:37.370 --> 01:14:39.439
Anthony Taylor: and I will explain why.

814
01:14:39.520 --> 01:14:45.880
Anthony Taylor: But they're telling you there's 2 values, one and 2. One is spruce fur and 2 is lodge opine.

815
01:14:46.790 --> 01:14:50.579
Anthony Taylor: Okay, so we're going to create this little list with those 2 values.

816
01:14:51.390 --> 01:14:56.029
Anthony Taylor: we're going to train, test, scale and transform all of one cell. Yay.

817
01:14:58.190 --> 01:15:02.710
Anthony Taylor: okay. Now, here it is. Extra trees. Classifier.

818
01:15:03.990 --> 01:15:05.299
Anthony Taylor: There's your model

819
01:15:06.440 --> 01:15:10.290
Anthony Taylor: extra trees classifier dot fit.

820
01:15:10.970 --> 01:15:12.590
Anthony Taylor: There's your training.

821
01:15:14.430 --> 01:15:15.770
Anthony Taylor: This one might take a minute.

822
01:15:17.310 --> 01:15:19.880
Anthony Taylor: Nope, not too bad. Okay?

823
01:15:20.190 --> 01:15:23.820
Anthony Taylor: And now that we have that, that's so. That's the end of that. That's it.

824
01:15:25.250 --> 01:15:26.620
Anthony Taylor: Extra tree classified.

825
01:15:27.380 --> 01:15:28.740
Anthony Taylor: Okay, now.

826
01:15:28.880 --> 01:15:32.300
Anthony Taylor: let's do another gradient boosting classifier

827
01:15:36.270 --> 01:15:44.100
Anthony Taylor: is this tough? I think it's tough. Do you guys see what that was? Model fit score?

828
01:15:45.130 --> 01:15:45.960
Anthony Taylor: Okay?

829
01:15:47.020 --> 01:15:48.549
Anthony Taylor: And then we have

830
01:15:48.660 --> 01:15:50.639
Anthony Taylor: Ada Boost classifier

831
01:15:53.550 --> 01:15:56.580
Anthony Taylor: model fit predict

832
01:15:58.810 --> 01:16:08.110
Anthony Taylor: just like that. So right there in that one notebook, we just did 3 separate models.

833
01:16:08.230 --> 01:16:10.610
Clayton Graves: Boosters didn't seem to do very much.

834
01:16:10.710 --> 01:16:13.399
Anthony Taylor: Yeah. Didn't do too much in this particular case, did they?

835
01:16:13.770 --> 01:16:20.719
Anthony Taylor: But this guy did you know what's funny? And we didn't use this? So what happens is, is, if you do like a feature importance.

836
01:16:20.780 --> 01:16:22.780
Anthony Taylor: Okay?

837
01:16:23.050 --> 01:16:24.809
Anthony Taylor: I'm not a feature port

838
01:16:26.080 --> 01:16:34.150
Anthony Taylor: there. We will do this later, and you'll see this come back again. But since the target was one or 2. If you're like

839
01:16:34.600 --> 01:16:44.810
Anthony Taylor: outputting like a chart or something, you can use this to output the actual value instead of one or 2. That's we're not doing that here. I'm not sure why they must have cut something off

840
01:16:44.940 --> 01:16:46.899
Anthony Taylor: to not do it. But

841
01:16:47.060 --> 01:16:57.260
Anthony Taylor: yeah, so. But but the guys, it's a bit. I mean, I'm I'm not. I'm going to tell you right now at work. When we do this kind of stuff.

842
01:16:57.610 --> 01:17:01.650
Anthony Taylor: We cycle through model after model after model

843
01:17:01.970 --> 01:17:04.379
Anthony Taylor: with a small subset of the data

844
01:17:04.740 --> 01:17:14.700
Anthony Taylor: to look at these kind of scores. just exactly what you see. Now, I have functions and loops and all kinds of stuff so that we don't do it. One notebook at a time.

845
01:17:15.150 --> 01:17:15.970
Anthony Taylor: But

846
01:17:16.420 --> 01:17:28.860
Anthony Taylor: the point is is this is what the data scientists are doing. They. They analyze the data to come up with the best feature set even. And that's before they start modeling features.

847
01:17:29.320 --> 01:17:32.030
Anthony Taylor: Okay, they prepped the data.

848
01:17:32.780 --> 01:17:34.270
Anthony Taylor: fixing those.

849
01:17:34.300 --> 01:17:37.960
Anthony Taylor: making sure. You know, we've got good, clean data.

850
01:17:38.080 --> 01:17:45.670
Anthony Taylor: you know, dealing with, there's there's a lot of steps of reprocessing. We've been pretty consistent with ours.

851
01:17:46.230 --> 01:18:00.300
Anthony Taylor: Okay. we scale. That's part of preprocessing, usually. And then we just start fitting different mops. We just start trying it out. Let's see how it looks and see how it looks.

852
01:18:00.580 --> 01:18:11.769
Anthony Taylor: Okay, now. what we're looking for like in this case we would brought, we would certainly have these 3. This would be the one we would use. Now, what would we do with this? Well, at this point

853
01:18:12.120 --> 01:18:15.119
Anthony Taylor: this isn't bad. but could I do better?

854
01:18:17.060 --> 01:18:21.590
Anthony Taylor: And how would we know? Well, what you guys, probably tomorrow.

855
01:18:21.970 --> 01:18:24.570
Anthony Taylor: So I think I can go. Look, hold on. Let me see, I think

856
01:18:25.600 --> 01:18:33.670
Anthony Taylor: this is the end. Yeah, okay, so I wanna make sure if tomorrow's the day we do this before. I tell you

857
01:18:35.710 --> 01:18:37.550
Anthony Taylor: now. So

858
01:18:38.110 --> 01:18:39.350
Anthony Taylor: and

859
01:18:42.240 --> 01:18:51.679
Anthony Taylor: oh, next week we're going to start doing something called email optimization. So what that means is at that point, we're gonna start

860
01:18:51.940 --> 01:18:54.880
Anthony Taylor: tuning. All of these models were learned.

861
01:18:56.370 --> 01:19:00.089
Anthony Taylor: Okay? And this is where the data scientist earns their money

862
01:19:01.200 --> 01:19:05.090
Anthony Taylor: is their ability to tune these models to be as

863
01:19:05.170 --> 01:19:10.880
Anthony Taylor: happy. It's possible, with great recall we haven't talked about. Recall. Don't worry about that yet.

864
01:19:11.270 --> 01:19:14.200
Anthony Taylor: And low CPU!

865
01:19:14.480 --> 01:19:26.820
Clayton Graves: Help me help me understand we've got. We've got a model right? We figured out which features are. There are the the have the most weight, and we've tuned the model and everything else.

866
01:19:26.980 --> 01:19:29.680
Clayton Graves: What is this model? Now, what do we do with it?

867
01:19:30.440 --> 01:19:34.919
Clayton Graves: Well, okay. So if we decided this was good enough.

868
01:19:35.930 --> 01:19:39.849
Anthony Taylor: Okay? And like, I said, I'm telling you right now, we can do this a lot more.

869
01:19:40.230 --> 01:19:48.509
Anthony Taylor: I don't know that we're gonna get a lot higher score. But we could. There are a lot of steps we could do to see if we can get a better tuned model.

870
01:19:48.810 --> 01:19:54.100
Anthony Taylor: When we are done, and we are satisfied. That model is as good as it's gonna get

871
01:19:54.560 --> 01:19:56.230
Anthony Taylor: what we will then do.

872
01:19:56.640 --> 01:20:02.610
Anthony Taylor: Well, you have. There's 2 things that you will see people do with the models. And Tanya, I do see you, I promise. Hold up

873
01:20:02.720 --> 01:20:17.679
Anthony Taylor: one will do a batch. We'll use it for batch processing. which what that means is you've got some data and it comes in and you run it at you. You basically run the trained model

874
01:20:17.830 --> 01:20:22.670
Anthony Taylor: with it. Like, it's testing data. It's not testing data because there's no answer.

875
01:20:22.850 --> 01:20:26.050
Anthony Taylor: right? But you'll run it against the new data

876
01:20:26.110 --> 01:20:37.060
Anthony Taylor: and apply the prediction or the label to that new data. and then that new data either gets written back or to a report, or wherever it needs to go.

877
01:20:37.560 --> 01:20:43.669
Anthony Taylor: Okay, the other option. And and hopefully, I'll get to show you this

878
01:20:44.020 --> 01:20:46.600
Anthony Taylor: is, you would create an Api.

879
01:20:47.990 --> 01:20:51.110
Anthony Taylor: Okay, now we've created Apis in this class.

880
01:20:51.870 --> 01:20:57.300
Anthony Taylor: So all you have to do is save the final model, the the trained model.

881
01:20:57.490 --> 01:21:01.670
Anthony Taylor: as an individual variable. And then

882
01:21:02.090 --> 01:21:06.909
Anthony Taylor: with your Api, they pass in data needed for a prediction so like

883
01:21:07.160 --> 01:21:12.390
Anthony Taylor: in this case. all of these columns right here. Okay.

884
01:21:12.680 --> 01:21:18.220
Anthony Taylor: they pass in the actual values, and it will send back. Is it a one or a 2.

885
01:21:20.500 --> 01:21:24.530
Anthony Taylor: And that's the main way these things get used those 2 ways.

886
01:21:25.380 --> 01:21:27.630
Clayton Graves: So branch or classification.

887
01:21:28.450 --> 01:21:40.899
Anthony Taylor: Oh, yeah, well, I mean, that's what we're doing is classification. But yes, absolutely. Either you're classifying a bulk of data which you can just use this model right here, or you have like an application that interacts with.

888
01:21:41.230 --> 01:21:47.040
Anthony Taylor: and that's where you would create an Api. And I have all that stuff done for you, in fact.

889
01:21:48.280 --> 01:21:52.980
Anthony Taylor: The other day I was talking about it that I think, Natalie.

890
01:21:53.490 --> 01:21:59.759
Anthony Taylor: about where the the I have Github repositories. And of all this information in

891
01:22:00.250 --> 01:22:01.339
Anthony Taylor: and how to do that.

892
01:22:01.460 --> 01:22:03.320
Anthony Taylor: Okay, time question.

893
01:22:03.580 --> 01:22:11.539
Raugewitz, Tania: So I was just gonna comment that I'm I'm glad that you mentioned tuning, and that we'll get into that cause. You mentioned

894
01:22:11.670 --> 01:22:26.470
Raugewitz, Tania: that we can do this again and and improve our tuning. But I'm looking forward to understanding kind of really what that means, and and how to tell if you've tuned it correctly. So I was just looking forward to understanding that better.

895
01:22:27.290 --> 01:22:32.059
Anthony Taylor: I love that. That's excellent. And and just just to give you guys, since we're really early.

896
01:22:32.300 --> 01:22:35.620
Anthony Taylor: I will show you guys something before I get to Mike's question.

897
01:22:36.920 --> 01:22:44.400
Anthony Taylor: So as you saw, I just grabbed extra classifier and I want to go look at the documentation.

898
01:22:44.760 --> 01:22:50.290
Anthony Taylor: So when we talk about team. all of these parameters right here.

899
01:22:56.620 --> 01:23:00.789
Anthony Taylor: there. Okay, every one of them

900
01:23:01.610 --> 01:23:05.030
Anthony Taylor: have an effect on the output of this model.

901
01:23:06.280 --> 01:23:10.699
Anthony Taylor: every one of them. and every model we've talked about thus far

902
01:23:11.620 --> 01:23:14.780
Anthony Taylor: has parameters, and they're not the same every time.

903
01:23:16.230 --> 01:23:21.769
Anthony Taylor: Okay? So when we get into tuning. What we're gonna do is we're gonna start

904
01:23:21.830 --> 01:23:24.730
Anthony Taylor: tweaking these parameters.

905
01:23:26.530 --> 01:23:29.489
Anthony Taylor: And that's what tuning is.

906
01:23:29.810 --> 01:23:32.440
Anthony Taylor: There's there. You can do what you can with the data.

907
01:23:32.790 --> 01:23:45.289
Anthony Taylor: Okay, that's the preprocessing step. But when we start tuning, all we're gonna do is all of these parameters that are available to us. We're gonna start tweaking and seeing, hey? Maybe if we flip this one, we get

908
01:23:45.610 --> 01:23:47.159
Anthony Taylor: 10% better school

909
01:23:47.420 --> 01:23:48.990
Anthony Taylor: or 10% that

910
01:23:49.020 --> 01:23:51.650
Anthony Taylor: right? And so. And and the good news here is.

911
01:23:51.970 --> 01:24:00.400
Anthony Taylor: And and and Brandon Brandon previewed it for us in his chat. Comment. right? We're going to be able to do this in an automated way.

912
01:24:01.780 --> 01:24:08.249
Anthony Taylor: Okay, you're not gonna have to manually come in here and grab every one of these. Okay, we're gonna have an automated way to do that.

913
01:24:08.980 --> 01:24:09.650
Okay

914
01:24:09.950 --> 01:24:12.089
Anthony Taylor: to. Yes, Mike.

915
01:24:13.330 --> 01:24:23.030
michael mcpherson: when you were talking about the passing everything thing through an Api. Were you? Were you saying it was in a done in a function like we did in the Mini project

916
01:24:24.690 --> 01:24:31.300
Anthony Taylor: sort of, I mean. So you remember when we made Apis in class. did we make Apis in this class?

917
01:24:31.710 --> 01:24:33.100
michael mcpherson: We did right? Okay, good.

918
01:24:33.720 --> 01:24:36.839
Anthony Taylor: Well, I know we used them. Didn't we? Also make them?

919
01:24:37.890 --> 01:24:39.130
Anthony Taylor: Jennifer nodded.

920
01:24:39.360 --> 01:24:43.980
Anthony Taylor: No, okay. Well, maybe that'll be an extra review.

921
01:24:44.140 --> 01:24:52.650
Anthony Taylor: You gotta remember the Api was the part. It was the one assignment that the absolutely destroyed.

922
01:24:52.790 --> 01:24:55.110
Anthony Taylor: Oh. no, the

923
01:24:55.280 --> 01:25:02.429
Anthony Taylor: so make creating an Api. Again, I have a lot of samples of this in my Github Repository.

924
01:25:02.640 --> 01:25:06.120
Anthony Taylor: But you basically are going to create a web.

925
01:25:07.110 --> 01:25:07.800
and

926
01:25:08.190 --> 01:25:09.020
Anthony Taylor: that

927
01:25:09.230 --> 01:25:14.600
Anthony Taylor: will run python and output what you tell it to. So what you would do

928
01:25:14.630 --> 01:25:17.630
Anthony Taylor: is you would create a web form

929
01:25:17.860 --> 01:25:25.019
Anthony Taylor: and or just an Api where they pass it, the the fields it would execute your model

930
01:25:25.710 --> 01:25:32.170
Anthony Taylor: and then return the answer. It's it's it's not very much at all. It's 15 lights goat

931
01:25:32.480 --> 01:25:38.290
Anthony Taylor: and then again, this definitely in my Github Repository.

932
01:25:38.370 --> 01:25:45.630
Anthony Taylor: You can host that like on your Aw ads, Google, cloud Heroku, whatever you feel like.

933
01:25:45.720 --> 01:25:51.119
Anthony Taylor: And and you could call it from me from a phone app from another computer, from

934
01:25:51.360 --> 01:25:53.490
Anthony Taylor: another application. Any

935
01:25:54.010 --> 01:25:59.760
Anthony Taylor: alright. And I can show you all of this stuff. I didn't think about fact that you guys learn how to make Api's

936
01:26:00.950 --> 01:26:03.919
Anthony Taylor: think about that. But yeah,

937
01:26:04.870 --> 01:26:12.750
Anthony Taylor: I will do, I promise. In fact, you guys can hold me to it. I didn't want to do it next, but maybe I will.

938
01:26:13.180 --> 01:26:17.490
Anthony Taylor: I'll do a review and kind of give you guys a little bit of it. It's not that hard

939
01:26:17.880 --> 01:26:19.680
Anthony Taylor: to do

940
01:26:19.750 --> 01:26:22.919
Anthony Taylor: so. I think we could do it in. In one or 2 reviews.

941
01:26:23.900 --> 01:26:26.009
Anthony Taylor: Okay, so we can do that.

942
01:26:26.390 --> 01:26:31.279
Anthony Taylor: Probably we'll try to get done before next project that way. You guys can use it

943
01:26:33.120 --> 01:26:34.180
Anthony Taylor: sound fine.

944
01:26:34.210 --> 01:26:36.860
Raugewitz, Tania: Yeah. Any HTML people in here?

945
01:26:38.100 --> 01:26:48.550
Anthony Taylor: Not since I will say there's some Javas. If you want to build a web interface like an actual interface.

946
01:26:48.650 --> 01:26:59.330
Anthony Taylor: to enter the values, to go to your model. II have an example of one that you can tweak, but you gotta kinda know Javascript. so everybody might try to grab Braid Gabe.

947
01:26:59.740 --> 01:27:02.930
Anthony Taylor: Anybody else that does Javascript and bug them for help.

948
01:27:03.300 --> 01:27:08.999
Raugewitz, Tania: He's busy.

949
01:27:09.180 --> 01:27:10.659
Anthony Taylor: Meredith, you're up?

950
01:27:12.100 --> 01:27:21.370
Meredith McCanse (she/her): I have a question about the ensemble nature, so we call so we tried 3 different models.

951
01:27:21.710 --> 01:27:31.089
Meredith McCanse (she/her): are we? D do? Is there some step where you then combine them to use them in ensemble? Or did the ensemble?

952
01:27:31.460 --> 01:27:32.560
Meredith McCanse (she/her): Okay.

953
01:27:32.600 --> 01:27:41.540
Anthony Taylor: different versions of it. Yeah. So extra tree. Remember, it's like random forest, except for instead of sampling, it does the whole thing

954
01:27:41.700 --> 01:27:49.730
Anthony Taylor: and then these other ones are just boosted. So what they do is these are the ones that, like the non important are the the

955
01:27:49.750 --> 01:28:01.109
Anthony Taylor: decision trees that aren't adding to the results. They get less important, and so on, and so on. So no, each one of these are an ensemble method. They don't work together.

956
01:28:01.420 --> 01:28:09.760
Anthony Taylor: Yeah, but no, that's a great question, because I don't know. That's clear. I think we clear that up nice? Yeah, so yeah, time.

957
01:28:11.810 --> 01:28:15.410
Raugewitz, Tania: Yes. So you noticed

958
01:28:15.430 --> 01:28:17.570
Raugewitz, Tania: in the instructor

959
01:28:18.170 --> 01:28:29.920
Raugewitz, Tania: one? There was a bar chart. And you know that was very interesting to see how that all played out was. I don't know if that was in the bag and boost if that was in the random forest.

960
01:28:30.370 --> 01:28:31.849
Anthony Taylor: Oh, this one here?

961
01:28:32.000 --> 01:28:44.130
Raugewitz, Tania: Yeah, yeah, yeah. Yeah.

962
01:28:44.330 --> 01:28:56.649
Raugewitz, Tania: Bar chart, because there's a lot of columns. So in order to to con. can I just share my screen. So

963
01:28:58.270 --> 01:29:00.369
Anthony Taylor: oh, I have to stop sharing my second.

964
01:29:01.980 --> 01:29:02.929
Anthony Taylor: There you go.

965
01:29:04.230 --> 01:29:08.670
Raugewitz, Tania: So my question is here.

966
01:29:10.370 --> 01:29:11.280
So if

967
01:29:11.640 --> 01:29:16.950
Raugewitz, Tania: pretty decent, right? So we? We sliced it? Basically.

968
01:29:16.980 --> 01:29:19.500
Raugewitz, Tania:  But

969
01:29:20.080 --> 01:29:28.950
Raugewitz, Tania: so here's my question, how do you know where to slice it at? Because if I if we did 20 then we didn't get the

970
01:29:29.090 --> 01:29:34.240
Raugewitz, Tania: the real culprit of as well up for second

971
01:29:36.280 --> 01:29:37.170
Anthony Taylor: little more

972
01:29:37.740 --> 01:29:42.730
Anthony Taylor: there. So you see, I mean, so what I would do is probably not slice this

973
01:29:43.070 --> 01:29:54.059
Anthony Taylor: right, and you can see where so point 0 one. I mean, you would just come up with a threshold. And I'm sorry. Let me show you what I'm like. I'm I'm pointing at my screen like you can see

974
01:29:54.280 --> 01:29:55.290
Anthony Taylor: this.

975
01:29:56.170 --> 01:30:00.130
Anthony Taylor: Where'd you go? Where'd you go?

976
01:30:00.560 --> 01:30:03.360
Raugewitz, Tania: I don't know. I don't see my arrow. I don't see you.

977
01:30:03.570 --> 01:30:14.850
Anthony Taylor: I'm pointing at the cell above that. That's so weird. Why is my arrow not working?

978
01:30:15.230 --> 01:30:17.320
Anthony Taylor: Okay, that works. Okay, that's good

979
01:30:17.350 --> 01:30:26.289
Anthony Taylor:  so what I would do here if I wanted to get a better idea is not slice this

980
01:30:26.320 --> 01:30:29.240
Anthony Taylor: look at and and just come up with a cutoff

981
01:30:29.280 --> 01:30:31.120
Anthony Taylor: of what is

982
01:30:31.220 --> 01:30:32.959
Anthony Taylor: low enough that I don't care anymore.

983
01:30:33.340 --> 01:30:39.509
Anthony Taylor: So like this one is at 0 1 7, probably even right here, I'd be like. You know what? I don't care

984
01:30:39.820 --> 01:30:43.449
Raugewitz, Tania: right about these features. They're not adding enough for me to do anything.

985
01:30:43.910 --> 01:30:46.900
Anthony Taylor: so I can erase that sorry.

986
01:30:48.010 --> 01:30:56.909
Anthony Taylor: So so 12 probably isn't bad. because these just these at the bottom here, they're just not adding anything to the model.

987
01:30:57.390 --> 01:31:00.040
Anthony Taylor: But yeah, so you could slice it wherever you like.

988
01:31:00.060 --> 01:31:06.459
Anthony Taylor: but that's that's what. If I wanted to do a visual like this? I would want to show probably the top 10

989
01:31:06.660 --> 01:31:08.140
Anthony Taylor: features that matter.

990
01:31:08.190 --> 01:31:15.729
Raugewitz, Tania: Okay, so how do I get the top? 10? Well, you did 12 before. Just change it to attend this time

991
01:31:16.730 --> 01:31:22.239
Anthony Taylor: in the same place you had, I mean, where did you? Just yeah, yeah, just deleted it

992
01:31:22.480 --> 01:31:25.550
Raugewitz, Tania: right? Right? So that's just

993
01:31:25.770 --> 01:31:28.009
Dipinto, Matt: you're gonna have to define features.

994
01:31:28.730 --> 01:31:39.340
Dipinto, Matt: So if you do, you're taking the first 10 values before it's sorted up to the cell prior to that.

995
01:31:39.590 --> 01:31:45.660
Raugewitz, Tania: And do features equals instances. Sorted 2, 10. Oh, okay.

996
01:31:45.790 --> 01:31:56.150
Raugewitz, Tania: it won't have that keys thing which admittedly, I don't even know what that was doing, so make sure you run that cell up there

997
01:31:56.740 --> 01:31:57.969
Raugewitz, Tania: and then

998
01:31:59.120 --> 01:32:03.849
Raugewitz, Tania: there we go, but see that it's not pulling the number one cause.

999
01:32:04.870 --> 01:32:06.580
Dipinto, Matt: sure, Redix.

1000
01:32:06.660 --> 01:32:11.409
Dipinto, Matt: So you re-executed, with features getting redefined. So run the cell up here again

1001
01:32:11.500 --> 01:32:12.510
Raugewitz, Tania: right here.

1002
01:32:12.520 --> 01:32:16.539
Dipinto, Matt: Yep, and then go down to the next one, and before you run it, comment out the feature people.

1003
01:32:16.660 --> 01:32:19.779
Raugewitz, Tania: Oh. come out! That one

1004
01:32:20.990 --> 01:32:22.139
Dipinto, Matt: that should work.

1005
01:32:23.880 --> 01:32:25.640
Raugewitz, Tania: Oh, yes.

1006
01:32:25.760 --> 01:32:33.980
Dipinto, Matt: they got Janky because of the not having the key. I love that. You use that word. I get made fun of on my kids because I use janky.

1007
01:32:34.470 --> 01:32:35.750
Anthony Taylor: Jenkins.

1008
01:32:36.040 --> 01:32:39.260
Raugewitz, Tania: Yeah, okay, well, okay.

1009
01:32:39.750 --> 01:32:48.180
Anthony Taylor: we we yeah. The better. The easier way to go do that is just go well, because this one only has the 12

1010
01:32:50.150 --> 01:32:55.750
Anthony Taylor: features sorted feature importances. So you just have to do

1011
01:32:56.550 --> 01:33:00.909
Raugewitz, Tania: yeah. So when I did 21, when I did 22,

1012
01:33:00.950 --> 01:33:03.829
Raugewitz, Tania: then I was able to pull the top one

1013
01:33:04.270 --> 01:33:07.620
Raugewitz, Tania: the top feature, whatever, wherever that is.

1014
01:33:07.840 --> 01:33:11.439
Anthony Taylor: Well, that's isn't that nearly all? No, it's not all

1015
01:33:11.820 --> 01:33:15.240
Raugewitz, Tania: I was. I was just wasn't sure, if there's a way to

1016
01:33:16.540 --> 01:33:18.569
Raugewitz, Tania: take an active way.

1017
01:33:18.660 --> 01:33:28.280
Raugewitz, Tania: Okay? I mean, I would. So when you change that number to 12 in the where you put 22. Yeah, it. It didn't pull up the correct top.

1018
01:33:29.490 --> 01:33:32.240
Anthony Taylor: Oh, cause it's resorting. Yeah.

1019
01:33:32.790 --> 01:33:39.109
Anthony Taylor: yeah. The let's see, sorted X columns, feature importances. So what you'd want to do. Go up.

1020
01:33:40.750 --> 01:33:41.470
Anthony Taylor: Huh?

1021
01:33:44.300 --> 01:33:45.670
Anthony Taylor: She disappeared

1022
01:33:46.860 --> 01:33:50.310
Anthony Taylor: alright. Well, we'll have to give it to her later.

1023
01:33:50.770 --> 01:33:53.570
Anthony Taylor: Okay. so

1024
01:33:54.630 --> 01:33:58.710
Anthony Taylor: we did a lot we learned came nearest neighbor.

1025
01:33:59.210 --> 01:34:02.629
Anthony Taylor: We learn decision trees.

1026
01:34:02.750 --> 01:34:06.550
Anthony Taylor: random forest extra extra forest.

1027
01:34:07.750 --> 01:34:11.990
Anthony Taylor: Ada boosts gradient boosts. That's a lot

1028
01:34:12.170 --> 01:34:16.970
Anthony Taylor: in one day. But guys model fit predict

1029
01:34:18.580 --> 01:34:20.769
Anthony Taylor: they all have the same exact

1030
01:34:22.430 --> 01:34:26.730
Anthony Taylor: alright. What you need to take away from today is.

1031
01:34:27.110 --> 01:34:36.200
Anthony Taylor: when do you use each one? Now, the cool thing, random forest multi classifier, binary classifier can work for all of them.

1032
01:34:37.830 --> 01:34:40.420
Anthony Taylor: Okay, extra tree. Same thing.

1033
01:34:41.310 --> 01:34:42.270
Anthony Taylor: Okay?

1034
01:34:43.440 --> 01:34:47.360
Anthony Taylor: And yeah. any questions.

1035
01:34:50.070 --> 01:34:52.070
Anthony Taylor: So tomorrow

1036
01:34:52.560 --> 01:34:54.710
Anthony Taylor: we are

1037
01:34:57.490 --> 01:35:02.280
Anthony Taylor: doing one last run and a couple more models.

1038
01:35:05.030 --> 01:35:05.820
But

1039
01:35:09.180 --> 01:35:12.300
we're gonna do multi-class classification.

1040
01:35:13.170 --> 01:35:15.270
Anthony Taylor: Oh, my God! And another

1041
01:35:15.510 --> 01:35:17.559
Anthony Taylor: Mini project love that.

1042
01:35:18.180 --> 01:35:19.100
Anthony Taylor: So

1043
01:35:20.140 --> 01:35:25.500
Anthony Taylor: I don't know. Maybe maybe we'll see alright. So a couple more models.

1044
01:35:25.550 --> 01:35:26.829
Anthony Taylor: and that's it.

1045
01:35:27.130 --> 01:35:31.310
Anthony Taylor: And then you're going into optimization. Super exciting

1046
01:35:33.100 --> 01:35:34.330
Anthony Taylor: Tommy's back.

1047
01:35:37.080 --> 01:35:44.669
Raugewitz, Tania: But she's muted we could even see you. This is amazing.

1048
01:35:44.740 --> 01:35:50.649
Anthony Taylor: So anyway, we would just, I mean, we could. We could continue your conversation a bit. The

1049
01:35:51.350 --> 01:35:55.589
Anthony Taylor: we're all done. I just did a recap what we learned today paying in

1050
01:35:56.100 --> 01:36:03.409
Anthony Taylor: precision trees, random forest extra tree, extra classifier, gradient moose and Ada boots.

1051
01:36:03.550 --> 01:36:07.690
Anthony Taylor: Lots of models. 6 of them model fit. Predict.

1052
01:36:08.660 --> 01:36:12.430
Anthony Taylor: That's it, guys, I will see you tomorrow.

1053
01:36:12.590 --> 01:36:15.350
Anthony Taylor: and you guys get a few minutes back.

1054
01:36:16.140 --> 01:36:18.830
Anthony Taylor: Have a great Wednesday night.

1055
01:36:19.030 --> 01:36:21.159
Anthony Taylor: and we'll be here for 30 min.

1056
01:36:21.890 --> 01:36:22.870
Anthony Taylor: Bye, everybody!

1057
01:36:25.050 --> 01:36:25.720
Raugewitz, Tania: Hey, Antony.

