# Car Evaluation

1. Title: Car Evaluation Database

2. Sources:
   (a) Creator: Marko Bohanec
   (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)
               Blaz Zupan      (blaz.zupan@ijs.si)
   (c) Date: June, 1997

3. Past Usage:

   The hierarchical decision model, from which this dataset is derived, was first presented in M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for multi-attribute decision making. In 8th Intl Workshop on Expert Systems and their Applications, Avignon, France. pages 59-78, 1988.

   Within machine-learning, this dataset was used for the evaluation of HINT (Hierarchy INduction Tool), which was proved to be able to completely reconstruct the original hierarchical model. This, together with a comparison with C4.5, is presented in B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by
   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)

4. Relevant Information Paragraph:

   Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:

   ```text
   CAR                      car acceptability
   . PRICE                  overall price
   . . buying               buying price
   . . maint                price of the maintenance
   . TECH                   technical characteristics
   . . COMFORT              comfort
   . . . doors              number of doors
   . . . persons            capacity in terms of persons to carry
   . . . lug_boot           the size of luggage boot
   . . safety               estimated safety of the car
   ```

   Input attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts:  PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).

   The Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.

   Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.

5. Number of Instances: 1728
   (instances completely cover the attribute space)

6. Number of Attributes: 6

7. Attribute Values:

   ```text
   buying       v-high, high, med, low
   maint        v-high, high, med, low
   doors        2, 3, 4, 5-more
   persons      2, 4, more
   lug_boot     small, med, big
   safety       low, med, high
   ```

8. Missing Attribute Values: none

9. Class Distribution (number of instances per class)

   ```text
   class      N          N[%]
   -----------------------------
   unacc     1210     (70.023 %) 
   acc        384     (22.222 %) 
   good        69     ( 3.993 %) 
   v-good      65     ( 3.762 %) 
   ```

##--CODE--##
# Import required dependencies
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

##--CODE--##
# Import data
file_path = "https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_3/datasets/car.csv"
df = pd.read_csv(file_path)
df.head()

##--CODE--##
# Check the value_counts of the target column
df["class"].value_counts()

## Preprocess the data

##--CODE--##
# Check the data types
df.dtypes

##--CODE--##
# Get the target variable (the "class" column)
y = df["class"]
y

##--CODE--##
# Get the features (everything except the "class" column)
X = df.copy()
X = X.drop(columns="class")
X.head()

##--CODE--##
# Split data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

##--CODE--##
# Since the target column is an object, we need to convert the data to numerical classes
# Encode the y data
# Create an instance of the label encoder


# Fit and transform the y training and testing data using the label encoder


##--CODE--##
# Remember that all of the columns in the DataFrame are objects
# Use a OneHotEncoder to convert the training data to numerical values


##--CODE--##
# Encode the test data


## Model and Fit to a Logistic Regression Classifier

##--CODE--##
# Create the logistic regression classifier model with a random_state of 1


# Fit the model to the training data


##--CODE--##
# Validate the model by checking the model accuracy with model.score


## Model and Fit to a Support Vector Machine

##--CODE--##
# Create the support vector machine classifier model with a 'poly' kernel


# Fit the model to the training data


##--CODE--##
# Validate the model by checking the model accuracy with model.score


## Model and Fit to a KNN Model

##--CODE--##
# Create the KNN model with 9 neighbors


# Fit the model to the training data


##--CODE--##
# Validate the model by checking the model accuracy with model.score


## Model and Fit to a Decision Tree Classifier

##--CODE--##
# Create the decision tree classifier model


# Fit the model to the training data


##--CODE--##
# Validate the model by checking the model accuracy with model.score


## Model and Fit to a Random Forest Classifier

##--CODE--##
# Create the random forest classifier model
# with n_estimators=128 and random_state=1


# Fit the model to the training data


##--CODE--##
# Validate the model by checking the model accuracy with model.score


##--CODE--##


