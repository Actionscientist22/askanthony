##--CODE--##
# Import the modules
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

##--CODE--##
# Read in the CSV file as a Pandas DataFrame
spread_df = pd.read_csv("Resources/stock_data.csv",
    index_col="date", 
    parse_dates=True, 
    infer_datetime_format=True
)

# Review the DataFrame
spread_df.head()

##--CODE--##
# Create a a list to store inertia values
inertia = []

# Create a a list to store the values of k
k = list(range(1, 11))

##--CODE--##
# Create a for-loop where each value of k is evaluated using the K-means algorithm
# Fit the model using the spread_df DataFrame
# Append the value of the computed inertia from the `inertia_` attribute of the KMeans model instance
for i in k:
    k_model = KMeans(n_clusters=i, n_init='auto', random_state=1)
    k_model.fit(spread_df)
    inertia.append(k_model.inertia_)

##--CODE--##
# Create a Dictionary that holds the list values for k and inertia
elbow_data = {"k": k, "inertia": inertia}

# Create a DataFrame using the elbow_data Dictionary
df_elbow = pd.DataFrame(elbow_data)

# Review the DataFrame
df_elbow

##--CODE--##
# Plot the elbow curve using Pandas plot.
df_elbow.plot.line(
    x="k", 
    y= "inertia", 
    title="Elbow Curve", 
    xticks=k
)

## Perform the following tasks for each of the two most likely values of `k`:

* Define a K-means model using `k` to define the clusters, fit the model, make predictions, and add the prediction values to a copy of the scaled DataFrame and call it `spread_predictions_df`.

* Plot the clusters. The x-axis should reflect the "hi_low_spread", and the y-axis should reflect the "close" price.

##--CODE--##
# Define the model with the lower value of k clusters
# Use a random_state of 1 to generate the model
model = KMeans(n_clusters=3, n_init='auto', random_state=1)

# Fit the model
model.fit(spread_df)

# Make predictions
k_lower = model.predict(spread_df)

# Create a copy of the DataFrame and name it as spread_df_predictions
spread_df_predictions = spread_df.copy()

# Add a class column with the labels to the spread_df_predictions DataFrame
spread_df_predictions['clusters_lower'] = k_lower

##--CODE--##
spread_df_predictions

##--CODE--##
# Visualize the data
spread_df_predictions.plot.scatter(
    x="hi_low_spread",
    y="close",
    c="clusters_lower",
    colormap="winter")

##--CODE--##
# Define the model with the higher value of k clusters
# Use a random_state of 1 to generate the model
model = KMeans(n_clusters=4, n_init='auto', random_state=1)

# Fit the model
model.fit(spread_df)

# Make predictions
k_higher = model.predict(spread_df)

# Add a class column with the labels to the spread_df_predictions DataFrame
spread_df_predictions['clusters_higher'] = k_higher

##--CODE--##
# Plot the clusters
spread_df_predictions.plot.scatter(
    x="hi_low_spread",
    y="close",
    c="clusters_lower",
    colormap="winter")

## Answer the following question
---
Considering the plot, whatâ€™s the best number of clusters to choose, or value of k? 

- From the scatter plots, it's a little hard to tell given the variability and quantity of the data, but it appears that the optimal value for k, the number of clusters, is 3.

##--CODE--##


