##--CODE--##
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

##--CODE--##
# Import the data
df = pd.read_csv("https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/rent-data-label-encoded.csv")
df.head()

##--CODE--##
# Drop rows with missing values
df = df.dropna()

## Split into training and testing sets

##--CODE--##
# Make an X variable with all columns except price
X_full = df.drop(columns = ['price'])
X_full.columns

##--CODE--##
select_features = ["square_feet", "Gated", "bathrooms", "bedrooms", "has_photo", "Pool", "AC"]

# Create another variable X_sel with only the columns
# in the "select_features" list



##--CODE--##
# Set the target variable y


##--CODE--##
# Now split the data into training and testing sets


## Train the models

##--CODE--##
# Create the models


# Fit the first model to the full training data. 


# Fit the second model to the select training data.


## Evaluate the model

##--CODE--##
# Calculate the mean_squared_error and the r-squared value
# for the testing data

# Use our models to make predictions


# Score the predictions with mse and r2


print(f"All Features:")
print(f"mean squared error (MSE): {mse1}")
print(f"R-squared (R2): {r21}")
print("---------------------")
print(f"Select Features:")
print(f"mean squared error (MSE): {mse2}")
print(f"R-squared (R2): {r22}")

##--CODE--##
# Provided code to create the adjusted r-squared function
def r2_adj(x, y, model):
    r2 = model.score(x,y)
    n_cols = x.shape[1]
    return 1 - (1 - r2) * (len(y) - 1) / (len(y) - n_cols - 1)

##--CODE--##
# Calculate the adjusted r-squared value of the model


##--CODE--##
# Examine linear regression on the better training data using cross validation
from sklearn.model_selection import cross_val_score


##--CODE--##


