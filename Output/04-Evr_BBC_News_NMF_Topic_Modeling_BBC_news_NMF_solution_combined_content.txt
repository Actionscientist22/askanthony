##--CODE--##
# Import the dependencies 
import pandas as pd
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

# Set the column width to 200.
pd.set_option('max_colwidth', 200)

##--CODE--##
# Read the bbc_news_articles.csv file into a DataFrame.
news_articles_df = pd.read_csv('Resources/bbc_news_articles.csv')
# Display the first 20 rows. 
news_articles_df.head(20)

## Preprocessing

##--CODE--##
# Check for null values.
news_articles_df.info()

##--CODE--##
# Remove numbers and non-alphabetic characters from the news_summary column.
news_articles_df['news_summary'] = news_articles_df['news_summary'].apply(lambda x: re.sub(r'[^a-zA-Z\s ]', '', str(x)))
news_articles_df.head(10)

## Create a TF-IDF matrix from our documents.

##--CODE--##
# Create an instance of the TfidfVectorizer and set the max_df to 0.95 and min_df to 5, and use the English stopwords to be ignored.
tfidf = TfidfVectorizer(max_df=0.95, min_df=5, stop_words='english')
tfidf

##--CODE--##
# Transform each row from the news summary to a DTM.
dtm = tfidf.fit_transform(news_articles_df['news_summary'])
# Get the shape of the DTM.
print(dtm.shape)

## Applying NMF

##--CODE--##
# Initialize the NMF and set the number of topics to 5. 
nmf_model = NMF(n_components=5,random_state=42)
# Fit the model with our DTM data. 
nmf_model.fit(dtm)

##--CODE--##
# Check the length of the vocabulary 
len(tfidf.get_feature_names_out())

## Get the Top 15 Words Per Topic

##--CODE--##
# Print the top 15 words for each topic
for index,topic in enumerate(nmf_model.components_):
    print(f'The top 15 words for topic #{index+1}')
    print([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-15:]])
    print('\n')

### **Question:** What is the label for each topic? 
---
- TOPIC 1: Business
- TOPIC 2: Entertainment
- TOPIC 3: Politics
- TOPIC 4: Sports
- TOPIC 5: Technology

## Assign the Topics and Labels to the News Summaries

##--CODE--##
# Transform our DTM so we get an array with the (number_of_documents, number_of_topics).
topic_results = nmf_model.transform(dtm)

# Get the shape of the topic results
topic_results.shape

##--CODE--##
# Read the bbc_news_articles.csv file into a DataFrame.
news_articles_df_2 = pd.read_csv('Resources/bbc_news_articles.csv')
# Display the DataFrame. 
news_articles_df_2.head()

##--CODE--##
# Use the add_topic_labels function to add the topic and topic label to each news summary. 
# Dictionary of  topics and topic label.
topic_labels = {
    1: 'Business',
    2: 'Entertainment',
    3: 'Politics',
    4: 'Sports',
    5: 'Technology'
}

# Define the function and pass in the DataFrame, the topic_results, and topic_labels dictionary.
def add_topic_labels(df, topic_results, topic_labels):
    # Find the dominant topic for each document and add the label to a new column
    df['topic'] = topic_results.argmax(axis=1) + 1
    # Use the map function to add the topic label to the news summary based on the topic number.
    df['topic_label'] = df['topic'].map(topic_labels)


##--CODE--##
# Call the function to add topic labels to your DataFrame.
add_topic_labels(news_articles_df_2, topic_results, topic_labels)

##--CODE--##
# Display the first 10 rows of the updated DataFrame. 
news_articles_df_2.head(10)

##--CODE--##
# Display the last 10 rows of the updated DataFrame.
news_articles_df_2.tail(10)

##--CODE--##


