##--CODE--##
# Uncomment the next line if you are using Google Colab
# !pip install sentence-transformers

##--CODE--##
# Import the SentenceTransformer class and the utility function from the sentence_transformers library.
from sentence_transformers import SentenceTransformer, util
# Use the all-MiniLM-L6-v2 model.
model = SentenceTransformer('all-MiniLM-L6-v2')

##--CODE--##
# Define a list of sentences to tokenize.
sentences = ["I love my dog.", "I love my family.", "My dog is a lab."]

##--CODE--##
# Tokenize the sentences with the model.
tokenized_documents = [model.tokenizer.tokenize(sentence) for sentence in sentences]

# Get the numerical embeddings for all sentences.
embeddings = model.encode(sentences)

# Print the embeddings


##--CODE--##
# Generate the cosine similarity scores using the embeddings.


##--CODE--##
#Find the pairs with the highest cosine similarity scores


#Sort scores in decreasing order.


##--CODE--##
# Print out the pairs of sentences and their cosine similarity score.


##--CODE--##
# Create a DataFrame for the cosine similarity scores.
import pandas as pd

# Convert the cosine similarity matrix to a Pandas DataFrame.


##--CODE--##


