##--CODE--##
# Import our dependencies
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

##--CODE--##
# Import the sample data
df = pd.read_csv("https://static.bc-edx.com/ai/ail-v-1-0/m18/lesson_1/datasets/sample-data-1000.csv")

# Plot the sample data
df.plot.scatter(x="Feature 1", y="Feature 2", c="Target", colormap="winter")

##--CODE--##
# Separate the X and y
X = df.drop(columns="Target")
y = df["Target"]

# Use sklearn to split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)

##--CODE--##
# Create scaler instance
X_scaler = StandardScaler()

# Fit the scaler
X_scaler.fit(X_train)

# Scale the data
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)

##--CODE--##
# Create the Keras Sequential model


##--CODE--##
# Set input nodes to the number of features


# Add our first Dense layer, including the input layer


##--CODE--##
# Add the output layer that uses a probability activation function


##--CODE--##
# Check the structure of the Sequential model


##--CODE--##
# Compile the Sequential model together and customize metrics


# Fit the model to the training data


##--CODE--##
# Create a DataFrame containing training history


# Increase the index by 1 to match the number of epochs


# Plot the loss


##--CODE--##
# Plot the accuracy


##--CODE--##
# Evaluate the model using the test data


