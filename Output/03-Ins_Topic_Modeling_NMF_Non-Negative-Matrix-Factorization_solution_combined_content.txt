##--CODE--##
# Import the dependencies 
import pandas as pd
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

# Set the column width to 200.
pd.set_option('max_colwidth', 200)

##--CODE--##
# Load the news_articles.csv into a DataFrame.
news_articles_df = pd.read_csv('Resources/news_articles.csv')
# Display the first 20 headlines 
news_articles_df.head(10)

## Preprocess the Text

##--CODE--##
# Remove digits and non-alphabetic characters
news_articles_df['headline'] = news_articles_df['headline'].apply(lambda x: re.sub(r'[^a-zA-Z\s ]', '', str(x)))
news_articles_df.head(10)

## Create a TF-IDF matrix from our documents.

##--CODE--##
# Create an instance of the TfidfVectorizer and set the max_df to 0.95 and min_df to 10, and use the English stopwords to be ignored.
tfidf = TfidfVectorizer(max_df=0.95, min_df=10, stop_words='english')
tfidf

##--CODE--##
# Transform each row from the headlines Series to a DTM.
dtm = tfidf.fit_transform(news_articles_df["headline"])
# Get the shape of the DTM.
print(dtm.shape)

##--CODE--##
# Print the sparse matrix of the transformed data.
# We have 23,377 documents, the first number in the tuple represents the document number.
# The second number in the tuple represents the index of the word in the vocabulary created by fit_transform.
# The last number represents the value of the TF-IDF score for the vocabulary word.
print(dtm)

##--CODE--##
# Get the feature names (words) from the TfidfVectorizer
feature_names = tfidf.get_feature_names_out()

# Get all the non-zero elements from the first row.
non_zero_elements = dtm.toarray()[0]

# Get the indices for each non-zero element.
non_zero_indices = non_zero_elements.nonzero()[0]

# Print out the word and the number of times the word is in the row. 
for idx in non_zero_indices:
    print(f"Word: {feature_names[idx]} | Word index {idx} | Value = {non_zero_elements[idx]}")

## Applying NMF

##--CODE--##
# Initialize the NMF and set the number of topics to 7. 
nmf_model = NMF(n_components=7,random_state=42)
# Fit the model with our DTM data. 
nmf_model.fit(dtm)

##--CODE--##
# Get the length of the array of each topic. It should be the same as the vocabulary.
for index,topic in enumerate(nmf_model.components_):
    print(len(nmf_model.components_[index]))

##--CODE--##
# Get the array of the first topic 
first_topic = nmf_model.components_[0]
# This is the ranking of each word in the array. Lower values have less impact than higher values.
print(first_topic)

##--CODE--##
# Get the indices of the top ten words for the first topic (e.g., top 10 words for topic 0):
top_word_indices = first_topic.argsort()[-10:][::-1]
print(top_word_indices)

##--CODE--##
# Get the top ten words from the indices. 
for index in top_word_indices:
    print(tfidf.get_feature_names_out()[index])

##--CODE--##
# Print the top 20 words for each topic
for index,topic in enumerate(nmf_model.components_):
    print(f'The top 30 words for topic #{index+1}')
    print([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-30:]])
    print('\n')

### Taking our best guess at the topics.
---
- TOPIC 1: **Entertainment**
- TOPIC 2: **Technology**
- TOPIC 3: **Food and Drink**
- TOPIC 4: **Politics**
- TOPIC 5: **Business**
- TOPIC 6: **Sports**
- TOPIC 7: **Travel**

## Assigning the Topic to the Headline

##--CODE--##
# Transform our DTM so we get an array with the (number_of_documents, number_of_topics).
topic_results = nmf_model.transform(dtm)

# Get the shape of the topic results
topic_results.shape

##--CODE--##
# Get the sorted indices for each topic in the first headline.
sorted_indices = np.argsort(-topic_results[0])
# Print the ranking of topics for the headline
print("Ranking of topics for the first headline:")
for rank, topic_index in enumerate(sorted_indices):
    print(f"   Rank {rank+1}: Topic {topic_index+1}, Probability: {topic_results[0, topic_index]:.6f}")

##--CODE--##
# Read in our original news headlines. 
news_articles_df_2 = pd.read_csv('Resources/news_articles.csv')
# Combine the original data with the topic label. 
news_articles_df_2['topic'] = (topic_results.argmax(axis=1)+1)

##--CODE--##
# Get the first 10 rows. 
news_articles_df_2.head(10)

##--CODE--##
# Get the last 10 rows. 
news_articles_df_2.tail(10)

##--CODE--##


