##--CODE--##
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

##--CODE--##
# Import the data
df = pd.read_csv("https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_1/datasets/car-data-encoded.csv").dropna()
df.head()

##--CODE--##
# Get the features (everything except the "price" column)
X = df.copy().drop(columns="price")
X.head()

##--CODE--##
# Get the target column
y = df["price"].values.reshape(-1,1)
y[0:5]

##--CODE--##
# Use the Sklearn `train_test_split()` function to split the data into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

##--CODE--##
# Create a function to calculate VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor

def calc_vif(X):
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

    return(vif)

##--CODE--##
# Calculate vif for the dataframe



##--CODE--##
# Investigate the engine-location column to see why it returned a VIF of NaN


##--CODE--##
# Use value_counts to confirm


##--CODE--##
# Create another X variable by dropping engine-location 
# and the 4 columns with the highest VIF scores


# Recalculate the VIF scores


##--CODE--##
# Split the data into training and testing sets


##--CODE--##
# Train two models using the different X variables

# Create the models


# Fit the models


##--CODE--##
# Provided code to create the adjusted r-squared function
def r2_adj(x, y, model):
    r2 = model.score(x,y)
    n_cols = x.shape[1]
    return 1 - (1 - r2) * (len(y) - 1) / (len(y) - n_cols - 1)

##--CODE--##
# Compare the adjusted r-squared of the two models


##--CODE--##


