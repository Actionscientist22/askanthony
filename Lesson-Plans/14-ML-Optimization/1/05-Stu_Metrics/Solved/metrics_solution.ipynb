{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3700</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7100</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8300</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79705</td>\n",
       "      <td>1254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5320</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    goal  backers_count  outcome\n",
       "0   3700             24        0\n",
       "1   7100             31        0\n",
       "2   8300             57        0\n",
       "3  79705           1254        0\n",
       "4   5320            336        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m14/lesson_1/datasets/crowdfunding-data-imbalanced.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    565\n",
       "0    111\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the total number of positive and negative outcomes\n",
    "df['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an X and y variable\n",
    "X = df.drop(columns=['outcome'])\n",
    "y = df['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727810650887574"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression Model\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[553  12]\n",
      " [ 74  37]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = classifier.predict(X)\n",
    "\n",
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y, predictions, labels = [1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.98      0.93       565\n",
      "           0       0.76      0.33      0.46       111\n",
      "\n",
      "    accuracy                           0.87       676\n",
      "   macro avg       0.82      0.66      0.70       676\n",
      "weighted avg       0.86      0.87      0.85       676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classification report\n",
    "print(classification_report(y, predictions, labels = [1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656047197640118\n"
     ]
    }
   ],
   "source": [
    "# Calculate the balanced accuracy score\n",
    "print(balanced_accuracy_score(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1448087 , 0.8551913 ],\n",
       "       [0.1616855 , 0.8383145 ],\n",
       "       [0.1609259 , 0.8390741 ],\n",
       "       ...,\n",
       "       [0.10526033, 0.89473967],\n",
       "       [0.10196936, 0.89803064],\n",
       "       [0.10738461, 0.89261539]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict values with probabilities\n",
    "pred_probas = classifier.predict_proba(X)\n",
    "\n",
    "# Print the probabilities\n",
    "pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551912971691843,\n",
       " 0.8383144957302657,\n",
       " 0.8390741025091597,\n",
       " 0.7717647199981804,\n",
       " 0.9160796479655225]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each prediction includes a prediction for both the 0 class and the 1 class\n",
    "# We only need the predictions for the 1 class; use a list comprehension to \n",
    "# gather the second value from each list\n",
    "\n",
    "pred_probas_firsts = [prob[1] for prob in pred_probas]\n",
    "\n",
    "# Print the first 5 probabilities\n",
    "pred_probas_firsts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603364426373276\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc_auc_score\n",
    "print(roc_auc_score(y, pred_probas_firsts))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
