{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for loading PDF documents and QA chain.\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, Jane Doe's language skills include English as her native language and Spanish as conversational. Therefore, it is possible to write to her in Spanish, but it is unclear to what extent she would understand or be able to respond in Spanish. It would be best to clarify her level of proficiency in Spanish before assuming full comprehension.\n"
     ]
    }
   ],
   "source": [
    "# Create the PDF loader and load the document.\n",
    "pdf_loader = PyPDFLoader('https://static.bc-edx.com/ai/ail-v-1-0/m22/lesson_1/datasets/Resume.pdf')\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Create the QA chain using the LLM.\n",
    "chain = load_qa_chain(llm)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = 'Could I write to Jane Doe in Spanish and expect her to understand?'\n",
    "\n",
    "# Pass the documents and the query to the chain, and print the result.\n",
    "result = chain.invoke({\"input_documents\": documents, \"question\": query})\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for loading Wikipedia content and QA chain.\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonard Cohen released a total of fifteen studio albums throughout his career.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Define the wikipedia topic as a string.\n",
    "wiki_topic = \"Leonard Cohen\"\n",
    "\n",
    "# Load the wikipedia results as documents, using a max of 2.\n",
    "documents = WikipediaLoader(query=wiki_topic, load_max_docs=2, load_all_available_meta=True).load()\n",
    "\n",
    "# Create the QA chain using the LLM.\n",
    "chain = load_qa_chain(llm)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = 'How many albums has Leonard Cohen released?'\n",
    "\n",
    "# Pass the documents and the query to the chain, and print the result.\n",
    "result = chain.invoke({\"input_documents\": documents, \"question\": query})\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for API chain.\n",
    "from langchain.chains import APIChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttp://numbersapi.com/22/trivia\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m22 is the number of stars in the Paramount Films logo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "A fun fact about the number 22 is that it is the number of stars in the Paramount Films logo.\n"
     ]
    }
   ],
   "source": [
    "# Text description of API spec.\n",
    "spec = \"\"\"URL STRUCTURE\n",
    "        Just hit http://numbersapi.com/number/type to get a plain text response, where\n",
    "        type is one of trivia, math, date, or year. Defaults to trivia if omitted.\n",
    "        number is an integer, or the keyword random, for which we will try to return\n",
    "        a random available fact, or a day of year in the form month/day \n",
    "        (eg. 2/29, 1/09, 04/1), if type is date ranges of numbers\"\"\"\n",
    "\n",
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Create the API chain from the spec, using the LLM.\n",
    "chain = APIChain.from_llm_and_api_docs(\n",
    "    llm,\n",
    "    api_docs=spec,\n",
    "    verbose=True, # Caution: for APIs that require a key, this setting can display the API key in the output.\n",
    "    limit_to_domains=[\"http://numbersapi.com\"],\n",
    ")\n",
    "\n",
    "# Define a query as a dictionary.\n",
    "query = {\"question\": \"What is a fun fact about the number 22?\"}\n",
    "\n",
    "# Run the chain using the query, and print the response.\n",
    "result = chain.invoke(query)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for API chain and processing json.\n",
    "from langchain.chains import APIChain\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The headlines of three articles about Tracy Chapman since 2020 are:\n",
      "\n",
      "1. \"Our Keepers of 2023\"\n",
      "2. \"Country Musicâ€™s Outrage Head Fake\"\n",
      "3. \"The Rise of the A.I. Pop Star\"\n"
     ]
    }
   ],
   "source": [
    "# Store the API key in a variable.\n",
    "api_key = os.getenv(\"NYT_API_KEY\")\n",
    "\n",
    "# Load the spec from json file and store the API key.\n",
    "spec = requests.get(\"https://raw.githubusercontent.com/nytimes/public_api_specs/master/article_search/article_search_v2.json\").json()\n",
    "spec[\"api_key\"] = api_key\n",
    "\n",
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Create the API chain from the spec, using the LLM.\n",
    "chain = APIChain.from_llm_and_api_docs(\n",
    "    llm,\n",
    "    api_docs=json.dumps(spec),\n",
    "    verbose=False,  # Changing to True will expose user's NYT API key.\n",
    "    limit_to_domains=[\"https://api.nytimes.com/\"],\n",
    ")\n",
    "\n",
    "# Define a query as a string.\n",
    "query = {\"question\": 'What are the headlines of three articles about Tracy Chapman since 2020?'}\n",
    "\n",
    "# Run the chain using the query, and print the response.\n",
    "result = chain.invoke(query)\n",
    "print(result[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
