{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk, numpy and pandas.\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Reuters\n",
    "from nltk.corpus import reuters\n",
    "# Import CountVectorizer, TfidfVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Download the Reuters dataset if you didn't install it.\n",
    "# nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "# Get the categories\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs in the corpus: 10788\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of documents in the collection\n",
    "doc_ids = reuters.fileids()\n",
    "# Retrieve the number of documents in the corpus.\n",
    "print(f\"Total number of docs in the corpus: {len(doc_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the occurrence of each word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\n",
      "  The Ministry of International Trade and\n",
      "  Industry (MITI) will revise its long-term energy supply/demand\n",
      "  outlook by August to meet a forecast downtrend in Japanese\n",
      "  energy demand, ministry officials said.\n",
      "      MITI is expected to lower the projection for primary energy\n",
      "  supplies in the year 2000 to 550 mln kilolitres (kl) from 600\n",
      "  mln, they said.\n",
      "      The decision follows the emergence of structural changes in\n",
      "  Japanese industry following the rise in the value of the yen\n",
      "  and a decline in domestic electric power demand.\n",
      "      MITI is planning to work out a revised energy supply/demand\n",
      "  outlook through deliberations of committee meetings of the\n",
      "  Agency of Natural Resources and Energy, the officials said.\n",
      "      They said MITI will also review the breakdown of energy\n",
      "  supply sources, including oil, nuclear, coal and natural gas.\n",
      "      Nuclear energy provided the bulk of Japan's electric power\n",
      "  in the fiscal year ended March 31, supplying an estimated 27\n",
      "  pct on a kilowatt/hour basis, followed by oil (23 pct) and\n",
      "  liquefied natural gas (21 pct), they noted.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select and print a single document of text.\n",
    "doc_text = reuters.raw(doc_ids[2])\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the CountVectorizer and define the English stopwords to be ignored.\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Tokenize the text into numerical features and occurrence of each word.\n",
    "X = vectorizer.fit_transform([doc_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38)\t2\n",
      "  (0, 66)\t2\n",
      "  (0, 44)\t2\n",
      "  (0, 75)\t2\n",
      "  (0, 25)\t8\n",
      "  (0, 18)\t5\n",
      "  (0, 21)\t1\n",
      "  (0, 49)\t2\n",
      "  (0, 37)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 36)\t2\n",
      "  (0, 50)\t4\n",
      "  (0, 73)\t3\n",
      "  (0, 57)\t2\n",
      "  (0, 8)\t1\n",
      "  (0, 47)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 39)\t2\n",
      "  (0, 55)\t2\n",
      "  (0, 69)\t4\n",
      "  (0, 27)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 61)\t1\n",
      "  :\t:\n",
      "  (0, 10)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 56)\t2\n",
      "  (0, 54)\t2\n",
      "  (0, 13)\t1\n",
      "  (0, 33)\t2\n",
      "  (0, 63)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 58)\t3\n",
      "  (0, 41)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 53)\t1\n"
     ]
    }
   ],
   "source": [
    "# X contains the occurrence of each term in the document.\n",
    "# We have 1 document, the first number in the tuple represents the document number, i.e., 0.\n",
    "# The second number in the tuple represents the index of the word in the vocabulary created by fit_transform.\n",
    "# The last number represents how many times the word appears.\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000' '21' '23' '27' '31' '550' '600' 'agency' 'august' 'basis'\n",
      " 'breakdown' 'bulk' 'changes' 'coal' 'committee' 'decision' 'decline'\n",
      " 'deliberations' 'demand' 'domestic' 'downtrend' 'downwards' 'electric'\n",
      " 'emergence' 'ended' 'energy' 'estimated' 'expected' 'fiscal' 'followed'\n",
      " 'following' 'follows' 'forecast' 'gas' 'hour' 'including' 'industry'\n",
      " 'international' 'japan' 'japanese' 'kilolitres' 'kilowatt' 'kl'\n",
      " 'liquefied' 'long' 'lower' 'march' 'meet' 'meetings' 'ministry' 'miti'\n",
      " 'mln' 'natural' 'noted' 'nuclear' 'officials' 'oil' 'outlook' 'pct'\n",
      " 'planning' 'power' 'primary' 'projection' 'provided' 'resources' 'review'\n",
      " 'revise' 'revised' 'rise' 'said' 'sources' 'structural' 'supplies'\n",
      " 'supply' 'supplying' 'term' 'trade' 'value' 'work' 'year' 'yen']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve unique words list\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "energy\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the words and find a specific word or term.\n",
    "print(len(words))\n",
    "print(words[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 2 1 1 8 1 1 1 1 1 1 1 2 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 1 1 2 4 2 3 1 2 2 2 2 3 1 2 1 1 1 1 1 2 1 1 4 1 1 1 3\n",
      " 1 2 1 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Print the number of times each word appears from the document. \n",
    "occurrences = X.toarray()[0]\n",
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>21</th>\n",
       "      <th>23</th>\n",
       "      <th>27</th>\n",
       "      <th>31</th>\n",
       "      <th>550</th>\n",
       "      <th>600</th>\n",
       "      <th>agency</th>\n",
       "      <th>august</th>\n",
       "      <th>basis</th>\n",
       "      <th>breakdown</th>\n",
       "      <th>bulk</th>\n",
       "      <th>changes</th>\n",
       "      <th>coal</th>\n",
       "      <th>committee</th>\n",
       "      <th>decision</th>\n",
       "      <th>decline</th>\n",
       "      <th>deliberations</th>\n",
       "      <th>demand</th>\n",
       "      <th>domestic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2000  21  23  27  31  550  600  agency  august  basis  breakdown  bulk  \\\n",
       "0     1   1   1   1   1    1    1       1       1      1          1     1   \n",
       "\n",
       "   changes  coal  committee  decision  decline  deliberations  demand  \\\n",
       "0        1     1          1         1        1              1       5   \n",
       "\n",
       "   domestic  \n",
       "0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the sparse matrix to a DataFrame to get our Bag-of-Words for the document. \n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display some first 20 columns of the DataFrame.\n",
    "bow_df.iloc[:,0:20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Word_Counts\n",
       "0  2000            1\n",
       "1    21            1\n",
       "2    23            1\n",
       "3    27            1\n",
       "4    31            1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melt the Bag-of-Words DataFrame to convert columns into rows.\n",
    "melted_bow = bow_df.melt(var_name='Word', value_name='Word_Counts')\n",
    "melted_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demand</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miti</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supply</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Word_Counts\n",
       "0  energy            8\n",
       "1  demand            5\n",
       "2    miti            4\n",
       "3    said            4\n",
       "4  supply            3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by Word_Counts if needed\n",
    "sorted_bow = melted_bow.sort_values(by='Word_Counts', ascending=False).reset_index(drop=True)\n",
    "sorted_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demand</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miti</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supply</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Word_Count\n",
       "0  energy           8\n",
       "1  demand           5\n",
       "2    miti           4\n",
       "3    said           4\n",
       "4  supply           3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively you can do the following:\n",
    "# Create a list to hold the words using the vectorizer.get_feature_names_out()\n",
    "words = list(vectorizer.get_feature_names_out())\n",
    "# Create a list to hold the frequency using np.ravel(X.sum(axis=0))\n",
    "frequency = list(np.ravel(X.sum(axis=0)))\n",
    "\n",
    "# Create a DataFrame of the TFâ€“IDF weights for each word in the working corpus.\n",
    "words_df = pd.DataFrame({\n",
    "  \"Word\": words,\n",
    "  \"Word_Count\": frequency})\n",
    "\n",
    "# Alternatively you can use:\n",
    "# words_df = pd.DataFrame(list(zip(words, np.ravel(X.sum(axis=0)))), columns=[\"Word\", \"Word_Count\"])\n",
    "\n",
    "# Sort the DataFrame on the Word_Count in descending order and reset the index.\n",
    "sorted_words= words_df.sort_values(by=[\"Word_Count\"], ascending=False).reset_index(drop=True)\n",
    "sorted_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TF-IDF score from a Corpus of Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NICKEL PRICES UNLIKELY TO RISE MUCH - SHEARSON\n",
      "  Nickel prices are unlikely to rise\n",
      "  significantly from current levels unless further steps are\n",
      "  taken to reduce production, Shearson Lehman Brothers said in\n",
      "  its quarterly nickel market report.\n",
      "      The market had recovered slightly to around 1.72 dlrs a lb\n",
      "  yesterday from its four year low of 1.55 dlrs in early January,\n",
      "  due to the absence of Soviet nickel cathode deliveries, but\n",
      "  Shearson sees Soviet shipments soon returning to last year's\n",
      "  buoyant levels, which should ease current tightness.\n",
      "      Output reductions by producers will take effect later this\n",
      "  year but are likely to be offset by increases elsewhere.\n",
      "      Shearson said the nickel market will be virtually in\n",
      "  balance during 1987, with total non-Socialist world demand at\n",
      "  556,000 tonnes, compared with an estimated 544,000 tonnes in\n",
      "  1986, production at 505,000 tonnes (504,000) and imports from\n",
      "  Socialist countries at 47,000 tonnes (50,000).\n",
      "      It forecast prices will edge higher during the year from a\n",
      "  first quarter average of 1.67 dlrs a lb up to 1.77 dlrs in the\n",
      "  last quarter. The year's average will be around 1.72 dlrs a lb\n",
      "  compared with 1.76 dlrs in 1986, using London Metal Exchange\n",
      "  cash metal prices in dollar terms and assuming an average 1987\n",
      "  sterling exchange rate of 1.55 dlrs.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the first 1000 articles from Reuters.\n",
    "corpus_id = doc_ids[0:1000]\n",
    "corpus = [reuters.raw(doc) for doc in corpus_id]\n",
    "\n",
    "# Print sample document\n",
    "print(corpus[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TfidfVectorizer and define the English stopwords to be ignored.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "# Tokenize the 1,000 articles into numerical features.\n",
    "X_corpus = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3653)\t0.02349374154800046\n",
      "  (0, 3572)\t0.03401531227145892\n",
      "  (0, 9282)\t0.023258637913775613\n",
      "  (0, 9251)\t0.02895058701961889\n",
      "  (0, 5736)\t0.031788665087932794\n",
      "  (0, 5876)\t0.04269766365167542\n",
      "  (0, 5004)\t0.023820462234420314\n",
      "  (0, 5281)\t0.04421016230849752\n",
      "  (0, 5595)\t0.04421016230849752\n",
      "  (0, 8051)\t0.03951191235503727\n",
      "  (0, 5798)\t0.03799941369821516\n",
      "  (0, 7395)\t0.04041700708351447\n",
      "  (0, 3186)\t0.07352722462649618\n",
      "  (0, 6900)\t0.03152282152841889\n",
      "  (0, 7263)\t0.03871356222491918\n",
      "  (0, 4079)\t0.031267012229669745\n",
      "  (0, 1746)\t0.04890841226195779\n",
      "  (0, 6009)\t0.04890841226195779\n",
      "  (0, 9449)\t0.04890841226195779\n",
      "  (0, 6839)\t0.03571875713005421\n",
      "  (0, 3204)\t0.029906837778906972\n",
      "  (0, 8301)\t0.036221071481879155\n",
      "  (0, 5719)\t0.03951191235503727\n",
      "  (0, 3623)\t0.04146186226670836\n",
      "  (0, 8287)\t0.04890841226195779\n",
      "  :\t:\n",
      "  (999, 6787)\t0.1736525446693858\n",
      "  (999, 7495)\t0.23299949141320167\n",
      "  (999, 7225)\t0.11157842602334767\n",
      "  (999, 6428)\t0.09972089581992195\n",
      "  (999, 2491)\t0.36059064178695793\n",
      "  (999, 7187)\t0.0868262723346929\n",
      "  (999, 6128)\t0.21786500994836008\n",
      "  (999, 3290)\t0.09278468529974941\n",
      "  (999, 9194)\t0.2991626874597659\n",
      "  (999, 2612)\t0.06803253161109464\n",
      "  (999, 2599)\t0.06871689487013131\n",
      "  (999, 3399)\t0.07955788050295924\n",
      "  (999, 7896)\t0.21891398032127124\n",
      "  (999, 1191)\t0.07399094457615113\n",
      "  (999, 2186)\t0.06643260003988806\n",
      "  (999, 1531)\t0.0789122642594043\n",
      "  (999, 9100)\t0.07447285813485559\n",
      "  (999, 336)\t0.05850728168318139\n",
      "  (999, 4516)\t0.07176615171901617\n",
      "  (999, 7887)\t0.1457422677413932\n",
      "  (999, 6495)\t0.03859748439867078\n",
      "  (999, 8308)\t0.05397476964595436\n",
      "  (999, 5538)\t0.05501440772298913\n",
      "  (999, 3391)\t0.03399422859269563\n",
      "  (999, 7680)\t0.02586249006570441\n"
     ]
    }
   ],
   "source": [
    "# Print the sparse matrix of the transformed data.\n",
    "# We have 1,000 documents, the first number in the tuple represents the document number.\n",
    "# The second number in the tuple represents the index of the word in the vocabulary created by fit_transform.\n",
    "# The last number represents the value of the TF-IDF score for the vocabulary word.\n",
    "print(X_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (1000, 9489)\n",
      "Total number of documents: 1000\n",
      "Total number of unique words (tokens): 9489\n"
     ]
    }
   ],
   "source": [
    "# Get the matrix info.\n",
    "print(f\"Matrix shape: {X_corpus.shape}\")\n",
    "print(f\"Total number of documents: {X_corpus.shape[0]}\")\n",
    "print(f\"Total number of unique words (tokens): {X_corpus.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' ... 'zones' 'zurich' 'zy']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve words list from corpus\n",
    "words_corpus = vectorizer.get_feature_names_out()\n",
    "print(words_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs</td>\n",
       "      <td>0.079701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mln</td>\n",
       "      <td>0.061460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cts</td>\n",
       "      <td>0.051221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000</td>\n",
       "      <td>0.047185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>said</td>\n",
       "      <td>0.045466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>net</td>\n",
       "      <td>0.038892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>0.038615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pct</td>\n",
       "      <td>0.028682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shr</td>\n",
       "      <td>0.027749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lt</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word    TF-IDF\n",
       "0    vs  0.079701\n",
       "1   mln  0.061460\n",
       "2   cts  0.051221\n",
       "3   000  0.047185\n",
       "4  said  0.045466\n",
       "5   net  0.038892\n",
       "6  dlrs  0.038615\n",
       "7   pct  0.028682\n",
       "8   shr  0.027749\n",
       "9    lt  0.027100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the TF-IDF weights of each word in corpus as DataFrame\n",
    "words_corpus_df = pd.DataFrame(\n",
    "    list(zip(words_corpus, np.ravel(X_corpus.mean(axis=0)))), columns=[\"Word\", \"TF-IDF\"])\n",
    "\n",
    "# Sort the DataFrame to show the top TF-IDF values.\n",
    "sorted_words_corpus = words_corpus_df.sort_values(by=[\"TF-IDF\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Highest 10 TF-IDF scores\n",
    "sorted_words_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>denotes</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>modification</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>bulgur</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>cracked</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>019</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>302</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>893</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>927</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>076</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>rolled</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word    TF-IDF\n",
       "9479       denotes  0.000005\n",
       "9480  modification  0.000005\n",
       "9481        bulgur  0.000005\n",
       "9482       cracked  0.000005\n",
       "9483           019  0.000005\n",
       "9484           302  0.000005\n",
       "9485           893  0.000005\n",
       "9486           927  0.000005\n",
       "9487           076  0.000005\n",
       "9488        rolled  0.000005"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowest 10 TF-IDF scores\n",
    "sorted_words_corpus.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
