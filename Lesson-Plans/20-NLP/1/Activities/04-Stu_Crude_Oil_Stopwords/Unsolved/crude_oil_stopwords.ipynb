{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Reuters database from the nltk corpus \n",
    "from nltk.corpus import reuters, stopwords\n",
    "# Import tokenizers and pandas\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Import regular expressions\n",
    "import re\n",
    "\n",
    "# Import nltk and the sentence tokenizer.\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the second article from the crude category of the Reuters library and print out the article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to clean the article using stopwords and regular expressions.\n",
    "def clean_text(article):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text article by performing the following steps:\n",
    "    \n",
    "    1. Removes stopwords (common words in English language).\n",
    "    2. Uses regular expressions to remove non-alphabet characters (e.g., punctuation).\n",
    "    3. Tokenizes the cleaned text into words.\n",
    "    4. Filters out words that are in the stopwords list.\n",
    "    \n",
    "    Parameters:\n",
    "        article (str): The input text article to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of preprocessed words from the input article.\n",
    "    \"\"\"\n",
    "    # Get the stopwords\n",
    "\n",
    "    # Use regex to substitute everything that is not a letter with an empty string.\n",
    "\n",
    "    # Tokenize the words \n",
    "\n",
    "    # Retrieve only the words that aren't in the stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the article and print out the unique words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a second function that does the same as the first function, but adds custom stopwords to the NLTK stopwords.\n",
    "def clean_text_again(article):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text article by performing the following steps:\n",
    "    \n",
    "    1. Removes stopwords (common words in English language).\n",
    "    2. Creates a custom dictionary of stopwords. \n",
    "    3. Uses regular expressions to remove non-alphabet characters (e.g., punctuation).\n",
    "    4. Tokenizes the cleaned text into words.\n",
    "    5. Filters out words that are not stopwords.\n",
    "    \n",
    "    Parameters:\n",
    "        article (str): The input text article to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of preprocessed words from the input article.\n",
    "    \"\"\"\n",
    "    # Get the stopwords\n",
    "\n",
    "    # Create a custom dictionary if stopwords.\n",
    "\n",
    "    # Use regex to substitute everything that is not a letter with an empty string.\n",
    "\n",
    "    # Tokenize the words \n",
    "\n",
    "    # Retrieve only the words not in the stopwords. Create a union of the sw and sw_addons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the article and print out the unique words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
