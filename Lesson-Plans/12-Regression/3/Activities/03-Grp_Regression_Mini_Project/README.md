# Regression Mini-Project

## Introduction

You will work in small groups to explore some datasets, then use your knowledge of preprocessing and model selection to create an application that incorporates a machine learning pipeline, before returning to the whole class to discuss and share your experience.

## Instructions

### Part 1: Explore Datasets

As a group, spend some time exploring the following datasets:

* [Garment worker productivity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity.csv)

* [Pollution in Beijing](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/beijing-pm2-5.csv)

* [News popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity.csv)

View the references below to explore information about the provided datasets.

After exploring the datasets, decide which one you would like to use for your application.

### Part 2: Data Preprocessing and Model Training

Have one group member share their screen while you work together to combine your skills with data preprocessing to prepare your selected dataset and train the model. Try out different features and models to find which options produce the best results. Make sure to include the following steps at a minimum:

* Data cleaning

* Splitting into training and testing sets

* Model training

* Model validation

At the end of this section, your group should have a fully trained model for the dataset. This should be completed inside the Jupyter Notebook.

### Part 3: Write Application

Now that you've found the best steps to train a model for your data, combine the steps from Part 2 into a machine learning function that can train a new model when new data is supplied.

You may begin building this application within a Jupyter Notebook file, but once complete transfer the code to a Python script (.py) file.

### Part 4: Test Application

Depending on your dataset selection, use the links below to train several models with your application.

* Garment worker productivity

  * [Sunday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

  * [Monday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

  * [Tuesday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

  * [Wednesday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

  * [Thursday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

  * [Saturday data](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/garments-worker-productivity-Sunday.csv)

* Pollution in Beijing

  * [NE wind direction](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/beijing-pm2-5-NE.csv)

  * [NW wind direction](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/beijing-pm2-5-NW.csv)

  * [SE wind direction](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/beijing-pm2-5-SE.csv)

  * [Calm or variable wind](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/beijing-pm2-5-cv.csv)

* News popularity

  * [ABC News popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity-ABC-News.csv)

  * [Bloomberg popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity-news-popularity-Bloomberg.csv)

  * [New York Times popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity-New-York-Times.csv)

  * [Reuters popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity-Reuters.csv)

  * [The Guardian popularity](https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/news-popularity-The-Guardian.csv)

Think about the following questions:

* Does your application work?

* Were the results better or worse than running a single model on the entire dataset?

* Do you think it was better to train multiple models on the subsets of data or to train one model on the entire set?

* Would you use the utilities you built again for other machine learning projects?

* What would you change to make these utilities more broadly applicable?

* What would you add to make the utilities more powerful?

### Part 5: Discuss and Share

Return to the full class to discuss and share your experience.

### References

UC Irvine Machine Learning Repository. 2017. *Beijing PM2.5 Data* [Dataset]. Available: https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data [2023, October 23]. ([CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode))

UC Irvine Machine Learning Repository. 2018. *News Popularity in Multiple Social Media Platforms* [Dataset]. Available: https://archive.ics.uci.edu/dataset/432/news+popularity+in+multiple+social+media+platforms [2023, October 23]. ([CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode))

UC Irvine Machine Learning Repository. 2020. *Productivity Prediction of Garment Employees* [Dataset]. Available: https://archive.ics.uci.edu/dataset/597/productivity+prediction+of+garment+employees [2023, October 23]. ([CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode))

---

Â© 2023 edX Boot Camps LLC. Confidential and Proprietary. All Rights Reserved.
