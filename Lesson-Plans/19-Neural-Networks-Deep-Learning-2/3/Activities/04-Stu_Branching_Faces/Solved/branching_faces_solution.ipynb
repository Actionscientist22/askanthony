{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un6tNZhrN_3q"
      },
      "source": [
        "# 1. Import the Preprocessed Data\n",
        "Import the pickle file with the preprocessed images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSIn8ESYLpB5",
        "outputId": "9f99114a-7a4e-4a8d-d86d-36ffd67d5b14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['X_train', 'X_test', 'y_train_userid', 'y_train_pose', 'y_train_expression', 'y_train_eyes', 'y_test_userid', 'y_test_pose', 'y_test_expression', 'y_test_eyes'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "import requests\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "pickle_file = 'https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_3/datasets/pickles/preprocessed_faces_data.pkl'\n",
        "data = pickle.load(io.BytesIO(requests.get(pickle_file).content))\n",
        "data.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDFj4qXRNomz"
      },
      "outputs": [],
      "source": [
        "X_train = data['X_train']\n",
        "X_test = data['X_test']\n",
        "\n",
        "y_train_userid = data['y_train_userid']\n",
        "y_train_pose = data['y_train_pose']\n",
        "y_train_expression = data['y_train_expression']\n",
        "y_train_eyes = data['y_train_eyes']\n",
        "\n",
        "y_test_userid = data['y_test_userid']\n",
        "y_test_pose = data['y_test_pose']\n",
        "y_test_expression = data['y_test_expression']\n",
        "y_test_eyes = data['y_test_eyes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtrr4IDoUAw"
      },
      "source": [
        "# 2. Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyyus3qUnpkx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, Model\n",
        "# First we build the input layer\n",
        "input_layer = layers.Input(shape=(60, 64, 1), name='input_layer')\n",
        "\n",
        "# Shared layers (common across all tasks)\n",
        "# The second layer should be a Conv2D layer built off the input_layer\n",
        "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "\n",
        "# The third layer should be a MaxPooling2D layer built off the second layer\n",
        "maxpool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "# The fourth layer should be a Conv2D layer built off the third layer\n",
        "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool1)\n",
        "\n",
        "# The fifth layer should be a MaxPooling2D layer built off the fourth layer\n",
        "maxpool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "# The sixth layer should be a Conv2D layer built off the fifth layer\n",
        "conv3 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool2)\n",
        "\n",
        "# The seventh layer should be a Flatten layer built off the sixth layer\n",
        "flatten = layers.Flatten()(conv3)\n",
        "\n",
        "# Lastly, build one dense layer before branching to the different y branches\n",
        "dense_shared = layers.Dense(64, activation='relu')(flatten)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAEw8LXNpm-R"
      },
      "outputs": [],
      "source": [
        "# Build the branches for each of the y variables\n",
        "# Include a dense hidden layer in each along with the output layer.\n",
        "# Remember to include the correct number of nodes for the output!\n",
        "\n",
        "# userid\n",
        "userid_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
        "userid_output = layers.Dense(len(y_train_userid.columns),\n",
        "                             activation='sigmoid',\n",
        "                             name='userid_output')(userid_dense)\n",
        "\n",
        "# pose\n",
        "pose_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
        "pose_output = layers.Dense(len(y_train_pose.columns),\n",
        "                           activation='softmax',\n",
        "                             name='pose_output')(pose_dense)\n",
        "\n",
        "# expression\n",
        "expression_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
        "expression_output = layers.Dense(len(y_train_expression.columns),\n",
        "                                 activation='softmax',\n",
        "                             name='expression_output')(expression_dense)\n",
        "\n",
        "# eyes\n",
        "eyes_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
        "eyes_output = layers.Dense(len(y_train_eyes.columns),\n",
        "                           activation='sigmoid',\n",
        "                             name='eyes_output')(eyes_dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMUUccPe2LRK"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = Model(inputs=input_layer, outputs=[\n",
        "    userid_output,\n",
        "    pose_output,\n",
        "    expression_output,\n",
        "    eyes_output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'userid_output': 'categorical_crossentropy',\n",
        "                    'pose_output': 'categorical_crossentropy',\n",
        "                    'expression_output': 'categorical_crossentropy',\n",
        "                    'eyes_output': 'binary_crossentropy'},\n",
        "              metrics={'userid_output': 'accuracy',\n",
        "                       'pose_output': 'accuracy',\n",
        "                       'expression_output': 'accuracy',\n",
        "                       'eyes_output': 'accuracy'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnRnEcWB3gb2",
        "outputId": "843fddba-91d5-4af2-91b8-166423c127b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "59/59 [==============================] - 14s 188ms/step - loss: 6.3047 - userid_output_loss: 2.8927 - pose_output_loss: 1.3382 - expression_output_loss: 1.3985 - eyes_output_loss: 0.6754 - userid_output_accuracy: 0.1036 - pose_output_accuracy: 0.3456 - expression_output_accuracy: 0.2885 - eyes_output_accuracy: 0.5550 - val_loss: 5.9638 - val_userid_output_loss: 2.6376 - val_pose_output_loss: 1.2544 - val_expression_output_loss: 1.4867 - val_eyes_output_loss: 0.5850 - val_userid_output_accuracy: 0.2265 - val_pose_output_accuracy: 0.4466 - val_expression_output_accuracy: 0.2564 - val_eyes_output_accuracy: 0.7179\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 11s 180ms/step - loss: 5.1039 - userid_output_loss: 1.9416 - pose_output_loss: 1.1812 - expression_output_loss: 1.4342 - eyes_output_loss: 0.5468 - userid_output_accuracy: 0.4257 - pose_output_accuracy: 0.4717 - expression_output_accuracy: 0.2890 - eyes_output_accuracy: 0.7153 - val_loss: 4.6885 - val_userid_output_loss: 1.5451 - val_pose_output_loss: 1.1352 - val_expression_output_loss: 1.5753 - val_eyes_output_loss: 0.4329 - val_userid_output_accuracy: 0.4637 - val_pose_output_accuracy: 0.5128 - val_expression_output_accuracy: 0.2479 - val_eyes_output_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 9s 151ms/step - loss: 4.0510 - userid_output_loss: 1.1407 - pose_output_loss: 1.0618 - expression_output_loss: 1.3898 - eyes_output_loss: 0.4587 - userid_output_accuracy: 0.6234 - pose_output_accuracy: 0.5353 - expression_output_accuracy: 0.3178 - eyes_output_accuracy: 0.7575 - val_loss: 4.3135 - val_userid_output_loss: 1.2392 - val_pose_output_loss: 1.1710 - val_expression_output_loss: 1.4902 - val_eyes_output_loss: 0.4130 - val_userid_output_accuracy: 0.5598 - val_pose_output_accuracy: 0.4829 - val_expression_output_accuracy: 0.2244 - val_eyes_output_accuracy: 0.8034\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 11s 180ms/step - loss: 3.3711 - userid_output_loss: 0.7527 - pose_output_loss: 0.8894 - expression_output_loss: 1.3464 - eyes_output_loss: 0.3826 - userid_output_accuracy: 0.7516 - pose_output_accuracy: 0.6202 - expression_output_accuracy: 0.3526 - eyes_output_accuracy: 0.8157 - val_loss: 4.0291 - val_userid_output_loss: 0.9793 - val_pose_output_loss: 1.0299 - val_expression_output_loss: 1.6020 - val_eyes_output_loss: 0.4179 - val_userid_output_accuracy: 0.6709 - val_pose_output_accuracy: 0.5641 - val_expression_output_accuracy: 0.2265 - val_eyes_output_accuracy: 0.7991\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 10s 174ms/step - loss: 2.9327 - userid_output_loss: 0.5196 - pose_output_loss: 0.7901 - expression_output_loss: 1.3033 - eyes_output_loss: 0.3196 - userid_output_accuracy: 0.8328 - pose_output_accuracy: 0.6672 - expression_output_accuracy: 0.3974 - eyes_output_accuracy: 0.8622 - val_loss: 3.8290 - val_userid_output_loss: 0.8525 - val_pose_output_loss: 0.9856 - val_expression_output_loss: 1.6333 - val_eyes_output_loss: 0.3577 - val_userid_output_accuracy: 0.6966 - val_pose_output_accuracy: 0.6261 - val_expression_output_accuracy: 0.2607 - val_eyes_output_accuracy: 0.8098\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 10s 168ms/step - loss: 2.5097 - userid_output_loss: 0.3575 - pose_output_loss: 0.6332 - expression_output_loss: 1.2533 - eyes_output_loss: 0.2657 - userid_output_accuracy: 0.8884 - pose_output_accuracy: 0.7479 - expression_output_accuracy: 0.4274 - eyes_output_accuracy: 0.8825 - val_loss: 3.8420 - val_userid_output_loss: 0.7396 - val_pose_output_loss: 0.9369 - val_expression_output_loss: 1.7885 - val_eyes_output_loss: 0.3769 - val_userid_output_accuracy: 0.7521 - val_pose_output_accuracy: 0.6346 - val_expression_output_accuracy: 0.1966 - val_eyes_output_accuracy: 0.8355\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 11s 179ms/step - loss: 2.1973 - userid_output_loss: 0.2405 - pose_output_loss: 0.5346 - expression_output_loss: 1.1778 - eyes_output_loss: 0.2444 - userid_output_accuracy: 0.9252 - pose_output_accuracy: 0.7911 - expression_output_accuracy: 0.4717 - eyes_output_accuracy: 0.8894 - val_loss: 3.7620 - val_userid_output_loss: 0.6196 - val_pose_output_loss: 0.9296 - val_expression_output_loss: 1.8772 - val_eyes_output_loss: 0.3356 - val_userid_output_accuracy: 0.8226 - val_pose_output_accuracy: 0.6880 - val_expression_output_accuracy: 0.2051 - val_eyes_output_accuracy: 0.8590\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 10s 175ms/step - loss: 1.8969 - userid_output_loss: 0.1689 - pose_output_loss: 0.4113 - expression_output_loss: 1.1370 - eyes_output_loss: 0.1797 - userid_output_accuracy: 0.9471 - pose_output_accuracy: 0.8446 - expression_output_accuracy: 0.5032 - eyes_output_accuracy: 0.9247 - val_loss: 3.8839 - val_userid_output_loss: 0.6996 - val_pose_output_loss: 0.9741 - val_expression_output_loss: 1.8918 - val_eyes_output_loss: 0.3184 - val_userid_output_accuracy: 0.7863 - val_pose_output_accuracy: 0.6410 - val_expression_output_accuracy: 0.2094 - val_eyes_output_accuracy: 0.8590\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 10s 175ms/step - loss: 1.6369 - userid_output_loss: 0.1321 - pose_output_loss: 0.3331 - expression_output_loss: 1.0364 - eyes_output_loss: 0.1352 - userid_output_accuracy: 0.9567 - pose_output_accuracy: 0.8771 - expression_output_accuracy: 0.5641 - eyes_output_accuracy: 0.9455 - val_loss: 4.2019 - val_userid_output_loss: 0.5605 - val_pose_output_loss: 1.2110 - val_expression_output_loss: 2.0427 - val_eyes_output_loss: 0.3876 - val_userid_output_accuracy: 0.8269 - val_pose_output_accuracy: 0.5940 - val_expression_output_accuracy: 0.2179 - val_eyes_output_accuracy: 0.8526\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 10s 169ms/step - loss: 1.4666 - userid_output_loss: 0.1057 - pose_output_loss: 0.2633 - expression_output_loss: 0.9699 - eyes_output_loss: 0.1277 - userid_output_accuracy: 0.9653 - pose_output_accuracy: 0.9028 - expression_output_accuracy: 0.5892 - eyes_output_accuracy: 0.9466 - val_loss: 4.3466 - val_userid_output_loss: 0.6838 - val_pose_output_loss: 1.0331 - val_expression_output_loss: 2.1797 - val_eyes_output_loss: 0.4501 - val_userid_output_accuracy: 0.8056 - val_pose_output_accuracy: 0.7009 - val_expression_output_accuracy: 0.1880 - val_eyes_output_accuracy: 0.8568\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a1744063880>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model with the training data\n",
        "model.fit(\n",
        "    X_train,\n",
        "    {\n",
        "        'userid_output': y_train_userid,\n",
        "        'pose_output': y_train_pose,\n",
        "        'expression_output': y_train_expression,\n",
        "        'eyes_output': y_train_eyes\n",
        "    },\n",
        "    epochs=10,  # You can adjust the number of epochs based on your needs\n",
        "    batch_size=32,  # You can adjust the batch size based on your available memory\n",
        "    validation_split=0.2  # You can specify the validation split if you have a separate validation set\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RbD5RK-34zb",
        "outputId": "92f552f3-bb46-4d15-bc5b-f084566ecb50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 44ms/step - loss: 3.8661 - userid_output_loss: 0.1103 - pose_output_loss: 0.9064 - expression_output_loss: 2.5518 - eyes_output_loss: 0.2976 - userid_output_accuracy: 0.9679 - pose_output_accuracy: 0.7372 - expression_output_accuracy: 0.1026 - eyes_output_accuracy: 0.9103\n",
            "userid accuracy: 0.9679487347602844\n",
            "pose accuracy: 0.7371794581413269\n",
            "expression accuracy: 0.10256410390138626\n",
            "eyes accuracy: 0.9102563858032227\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "results = model.evaluate(np.array(X_test), {\n",
        "        'userid_output': y_test_userid,\n",
        "        'pose_output': y_test_pose,\n",
        "        'expression_output': y_test_expression,\n",
        "        'eyes_output': y_test_eyes\n",
        "    })\n",
        "\n",
        "# Print the accuracy for each category\n",
        "pred_categories = ['userid', 'pose', 'expression', 'eyes']\n",
        "for i, cat in enumerate(pred_categories):\n",
        "    print(f\"{cat} accuracy: {results[i+5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjYcdOabBWTQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
