{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "38VsRPnj4Riy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the preprocessed data\n",
        "X_preprocessed_url = \"https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_2/datasets/pickles/preprocessed_fungi.pkl\"\n",
        "y_url = \"https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_2/datasets/pickles/fungi_y.pkl\"\n",
        "\n",
        "X = pickle.load(io.BytesIO(requests.get(X_preprocessed_url).content))\n",
        "y = pickle.load(io.BytesIO(requests.get(y_url).content))\n",
        "\n",
        "print(X[0])\n",
        "print(y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWpxhLKL1XI1",
        "outputId": "15404319-3900-42d5-82ba-a4c9a8f963ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.5568628  0.5647059  0.56078434]\n",
            "  [0.5568628  0.5647059  0.56078434]\n",
            "  [0.5568628  0.5647059  0.56078434]\n",
            "  ...\n",
            "  [0.53333336 0.54901963 0.54509807]\n",
            "  [0.5372549  0.5529412  0.54901963]\n",
            "  [0.5372549  0.5529412  0.54901963]]\n",
            "\n",
            " [[0.54901963 0.5568628  0.5529412 ]\n",
            "  [0.54901963 0.5568628  0.5529412 ]\n",
            "  [0.5529412  0.56078434 0.5568628 ]\n",
            "  ...\n",
            "  [0.53333336 0.54901963 0.54509807]\n",
            "  [0.5372549  0.5529412  0.54901963]\n",
            "  [0.5372549  0.5529412  0.54901963]]\n",
            "\n",
            " [[0.53333336 0.5411765  0.5372549 ]\n",
            "  [0.5411765  0.54901963 0.54509807]\n",
            "  [0.54901963 0.5568628  0.5529412 ]\n",
            "  ...\n",
            "  [0.5254902  0.5411765  0.5372549 ]\n",
            "  [0.5294118  0.54509807 0.5411765 ]\n",
            "  [0.5294118  0.54509807 0.5411765 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.5529412  0.53333336 0.4509804 ]\n",
            "  [0.5529412  0.53333336 0.4509804 ]\n",
            "  [0.54901963 0.5254902  0.44705883]\n",
            "  ...\n",
            "  [0.54509807 0.5529412  0.5568628 ]\n",
            "  [0.54509807 0.5529412  0.56078434]\n",
            "  [0.54509807 0.5529412  0.56078434]]\n",
            "\n",
            " [[0.54901963 0.5254902  0.44705883]\n",
            "  [0.54901963 0.5254902  0.44705883]\n",
            "  [0.5411765  0.5176471  0.44313726]\n",
            "  ...\n",
            "  [0.5411765  0.5568628  0.56078434]\n",
            "  [0.5411765  0.5568628  0.56078434]\n",
            "  [0.5411765  0.5568628  0.56078434]]\n",
            "\n",
            " [[0.54901963 0.52156866 0.44705883]\n",
            "  [0.54901963 0.52156866 0.44705883]\n",
            "  [0.5411765  0.5176471  0.44313726]\n",
            "  ...\n",
            "  [0.5411765  0.5568628  0.56078434]\n",
            "  [0.5411765  0.5568628  0.56078434]\n",
            "  [0.5411765  0.5568628  0.56078434]]]\n",
            "0    H1\n",
            "1    H1\n",
            "2    H2\n",
            "3    H1\n",
            "4    H2\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Label encode the y data\n",
        "y_encoder = LabelEncoder().fit(y)\n",
        "y = y_encoder.transform(y)\n",
        "\n",
        "# Convert values to numpy arrays\n",
        "X = np.array(X)\n",
        "\n",
        "# Split the training dataset into training and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "uAc56Hf61he_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,      # Random rotation (degrees)\n",
        "    width_shift_range=0.1,  # Random horizontal shift\n",
        "    height_shift_range=0.1, # Random vertical shift\n",
        "    shear_range=0.2,        # Shear intensity\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Random horizontal flip\n",
        "    vertical_flip=False,    # No vertical flip for face images\n",
        "    fill_mode='nearest'     # Fill mode for handling newly created pixels\n",
        ")\n"
      ],
      "metadata": {
        "id": "1fQWn9ym6E__"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an emtpty list for X and y augmentations\n",
        "X_train_aug = []\n",
        "y_train_aug = []\n",
        "\n",
        "# Loop through the entire X_train set\n",
        "for i in range(len(X_train)):\n",
        "    # Select the original image and its y label\n",
        "    img = X_train[i]\n",
        "    label = y_train[i]\n",
        "\n",
        "    # Ensure that the input data has the correct shape\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Add 5 new images for every original\n",
        "    for j in range(5):\n",
        "        # Create and append the image\n",
        "        X_train_aug.append(datagen.flow(img, batch_size=1).next()[0])\n",
        "        # Append the original label\n",
        "        y_train_aug.append(label)\n",
        "\n",
        "# Print the length of the augmented images and the labels\n",
        "print(len(X_train_aug))\n",
        "print(len(y_train_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnTv2j_f6yZd",
        "outputId": "c206297d-6a9e-4065-f067-39eb276f4d47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our final variables to a pickle file using a dictionary\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the dictionary\n",
        "fungi_dict = {\n",
        "    'X_train': X_train_aug,\n",
        "    'X_test': X_test,\n",
        "    'y_train': y_train_aug,\n",
        "    'y_test': y_test\n",
        "}\n",
        "\n",
        "# Store the dictionary in a pickle file\n",
        "with open('/content/drive/My Drive/fungi_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(fungi_dict, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rAh8qXo2x7G",
        "outputId": "1b11d486-edd7-420e-b578-43a05c82c115"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CldIDJRM3eVe"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}